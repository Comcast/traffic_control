diff --git a/README b/README
index 78cce71..769f85a 100644
--- a/README
+++ b/README
@@ -1,5 +1,6 @@
 Apache Traffic Server
 
+
 Traffic Server is a high-performance building block for cloud services.
 It's more than just a caching proxy server; it also has support for
 plugins to build large scale web applications.
diff --git a/configure.ac b/configure.ac
index fe2af20..45c47fe 100644
--- a/configure.ac
+++ b/configure.ac
@@ -1948,6 +1948,7 @@ AS_IF([test "x$enable_experimental_plugins" = xyes], [
     plugins/experimental/background_fetch/Makefile
     plugins/experimental/balancer/Makefile
     plugins/experimental/buffer_upload/Makefile
+    plugins/experimental/cache_range_requests/Makefile
     plugins/experimental/channel_stats/Makefile
     plugins/experimental/collapsed_connection/Makefile
     plugins/experimental/custom_redirect/Makefile
diff --git a/doc/reference/api/TSHttpOverridableConfig.en.rst b/doc/reference/api/TSHttpOverridableConfig.en.rst
index 837df9f..e53d371 100644
--- a/doc/reference/api/TSHttpOverridableConfig.en.rst
+++ b/doc/reference/api/TSHttpOverridableConfig.en.rst
@@ -57,6 +57,7 @@ Configurations
 The following configurations (from ``records.config``) are overridable: ::
 
     proxy.config.url_remap.pristine_host_hdr
+    proxy.config.url_remap.remap_required
     proxy.config.http.chunking_enabled
     proxy.config.http.negative_caching_enabled
     proxy.config.http.negative_caching_lifetime
@@ -100,6 +101,7 @@ The following configurations (from ``records.config``) are overridable: ::
     proxy.config.http.keep_alive_no_activity_timeout_out
     proxy.config.http.transaction_no_activity_timeout_in
     proxy.config.http.transaction_no_activity_timeout_out
+    proxy.config.http.transaction_active_timeout_in
     proxy.config.http.transaction_active_timeout_out
     proxy.config.http.origin_max_connections
     proxy.config.http.connect_attempts_max_retries
@@ -135,7 +137,12 @@ The following configurations (from ``records.config``) are overridable: ::
     proxy.config.http.accept_encoding_filter_enabled
     proxy.config.http.cache.range.write
     proxy.config.http.global_user_agent_header
-
+    proxy.config.http.parent_proxy.per_parent_connect_attempts
+    proxy.config.http.parent_proxy.total_connect_attempts
+    proxy.config.http.parent_origin.simple_retry_enabled
+    proxy.config.http.parent_origin.simple_retry_response_codes
+    proxy.config.http.parent_origin.dead_server_retry_enabled
+    proxy.config.http.parent_origin.dead_server_retry_response_codes
 
 Examples
 ========
diff --git a/iocore/cache/Cache.cc b/iocore/cache/Cache.cc
index 2879e82..fae560d 100644
--- a/iocore/cache/Cache.cc
+++ b/iocore/cache/Cache.cc
@@ -38,6 +38,8 @@
 #include "P_CacheBC.h"
 #endif
 
+#include "hugepages.h"
+
 // Compilation Options
 #define USELESS_REENABLES // allow them for now
 // #define VERIFY_JTEST_DATA
@@ -1295,7 +1297,13 @@ Vol::init(char *s, off_t blocks, off_t dir_skip, bool clear)
 
   Debug("cache_init", "allocating %zu directory bytes for a %lld byte volume (%lf%%)", vol_dirlen(this), (long long)this->len,
         (double)vol_dirlen(this) / (double)this->len * 100.0);
-  raw_dir = (char *)ats_memalign(ats_pagesize(), vol_dirlen(this));
+
+  raw_dir = NULL;
+  if (ats_hugepage_enabled())
+    raw_dir = (char *)ats_alloc_hugepage(vol_dirlen(this));
+  if (raw_dir == NULL)
+    raw_dir = (char *)ats_memalign(ats_pagesize(), vol_dirlen(this));
+
   dir = (Dir *)(raw_dir + vol_headerlen(this));
   header = (VolHeaderFooter *)raw_dir;
   footer = (VolHeaderFooter *)(raw_dir + vol_dirlen(this) - ROUND_TO_STORE_BLOCK(sizeof(VolHeaderFooter)));
@@ -2179,7 +2187,7 @@ CacheProcessor::mark_storage_offline(CacheDisk *d ///< Target disk
     Warning("All storage devices offline, cache disabled");
     CacheProcessor::cache_ready = 0;
   } else { // check cache types specifically
-    if (theCache && !theCache->hosttable->gen_host_rec.vol_hash_table) {
+    if (theCache && !theCache->getHosttable(__func__)->gen_host_rec.vol_hash_table) {
       unsigned int caches_ready = 0;
       caches_ready = caches_ready | (1 << CACHE_FRAG_TYPE_HTTP);
       caches_ready = caches_ready | (1 << CACHE_FRAG_TYPE_NONE);
@@ -2187,7 +2195,7 @@ CacheProcessor::mark_storage_offline(CacheDisk *d ///< Target disk
       CacheProcessor::cache_ready &= caches_ready;
       Warning("all volumes for http cache are corrupt, http cache disabled");
     }
-    if (theStreamCache && !theStreamCache->hosttable->gen_host_rec.vol_hash_table) {
+    if (theStreamCache && !theStreamCache->getHosttable(__func__)->gen_host_rec.vol_hash_table) {
       unsigned int caches_ready = 0;
       caches_ready = caches_ready | (1 << CACHE_FRAG_TYPE_RTSP);
       caches_ready = ~caches_ready;
@@ -3366,9 +3374,10 @@ create_volume(int volume_number, off_t size_in_blocks, int scheme, CacheVol *cp)
 void
 rebuild_host_table(Cache *cache)
 {
-  build_vol_hash_table(&cache->hosttable->gen_host_rec);
-  if (cache->hosttable->m_numEntries != 0) {
-    CacheHostMatcher *hm = cache->hosttable->getHostMatcher();
+  CacheHostTable *hosttable = cache->getHosttable(__func__);
+  build_vol_hash_table(&hosttable->gen_host_rec);
+  if (hosttable->m_numEntries != 0) {
+    CacheHostMatcher *hm = hosttable->getHostMatcher();
     CacheHostRecord *h_rec = hm->getDataArray();
     int h_rec_len = hm->getNumElements();
     int i;
@@ -3383,8 +3392,9 @@ Vol *
 Cache::key_to_vol(CacheKey *key, char const *hostname, int host_len)
 {
   uint32_t h = (key->slice32(2) >> DIR_TAG_WIDTH) % VOL_HASH_TABLE_SIZE;
+  CacheHostTable *hosttable = getHosttable(__func__);
   unsigned short *hash_table = hosttable->gen_host_rec.vol_hash_table;
-  CacheHostRecord *host_rec = &hosttable->gen_host_rec;
+  CacheHostRecord *host_rec = &(hosttable->gen_host_rec);
 
   if (hosttable->m_numEntries > 0 && host_len) {
     CacheHostResult res;
@@ -3392,21 +3402,13 @@ Cache::key_to_vol(CacheKey *key, char const *hostname, int host_len)
     if (res.record) {
       unsigned short *host_hash_table = res.record->vol_hash_table;
       if (host_hash_table) {
-        if (is_debug_tag_set("cache_hosting")) {
-          char format_str[50];
-          snprintf(format_str, sizeof(format_str), "Volume: %%xd for host: %%.%ds", host_len);
-          Debug("cache_hosting", format_str, res.record, hostname);
-        }
+        Debug("cache_hosting", "Volume: %p for host: %.*s", res.record, host_len, hostname);
         return res.record->vols[host_hash_table[h]];
       }
     }
   }
   if (hash_table) {
-    if (is_debug_tag_set("cache_hosting")) {
-      char format_str[50];
-      snprintf(format_str, sizeof(format_str), "Generic volume: %%xd for host: %%.%ds", host_len);
-      Debug("cache_hosting", format_str, host_rec, hostname);
-    }
+    Debug("cache_hosting", "Generic volume: %p for host: %.*s", host_rec, host_len, hostname);
     return host_rec->vols[hash_table[h]];
   } else
     return host_rec->vols[0];
diff --git a/iocore/cache/CacheDir.cc b/iocore/cache/CacheDir.cc
index 779c16b..e54fbfb 100644
--- a/iocore/cache/CacheDir.cc
+++ b/iocore/cache/CacheDir.cc
@@ -24,6 +24,8 @@
 
 #include "P_Cache.h"
 
+#include "hugepages.h"
+
 // #define LOOP_CHECK_MODE 1
 #ifdef LOOP_CHECK_MODE
 #define DIR_LOOP_THRESHOLD 1000
@@ -1011,6 +1013,7 @@ sync_cache_dir_on_shutdown(void)
   Debug("cache_dir_sync", "sync started");
   char *buf = NULL;
   size_t buflen = 0;
+  bool buf_huge = false;
 
   EThread *t = (EThread *)0xdeadbeef;
   for (int i = 0; i < gnvol; i++) {
@@ -1077,10 +1080,22 @@ sync_cache_dir_on_shutdown(void)
 #endif
 
     if (buflen < dirlen) {
-      if (buf)
-        ats_memalign_free(buf);
-      buf = (char *)ats_memalign(ats_pagesize(), dirlen);
+      if (buf) {
+        if (buf_huge)
+          ats_free_hugepage(buf, buflen);
+        else
+          ats_memalign_free(buf);
+        buf = NULL;
+      }
       buflen = dirlen;
+      if (ats_hugepage_enabled()) {
+        buf = (char *)ats_alloc_hugepage(buflen);
+        buf_huge = true;
+      }
+      if (buf == NULL) {
+        buf = (char *)ats_memalign(ats_pagesize(), buflen);
+        buf_huge = false;
+      }
     }
 
     if (!d->dir_sync_in_progress) {
@@ -1104,8 +1119,13 @@ sync_cache_dir_on_shutdown(void)
     Debug("cache_dir_sync", "done syncing dir for vol %s", d->hash_text.get());
   }
   Debug("cache_dir_sync", "sync done");
-  if (buf)
-    ats_memalign_free(buf);
+  if (buf) {
+    if (buf_huge)
+      ats_free_hugepage(buf, buflen);
+    else
+      ats_memalign_free(buf);
+    buf = NULL;
+  }
 }
 
 
@@ -1120,11 +1140,6 @@ CacheSync::mainEvent(int event, Event *e)
 Lrestart:
   if (vol_idx >= gnvol) {
     vol_idx = 0;
-    if (buf) {
-      ats_memalign_free(buf);
-      buf = 0;
-      buflen = 0;
-    }
     Debug("cache_dir_sync", "sync done");
     if (event == EVENT_INTERVAL)
       trigger = e->ethread->schedule_in(this, HRTIME_SECONDS(cache_config_dir_sync_frequency));
@@ -1196,10 +1211,22 @@ Lrestart:
       Debug("cache_dir_sync", "pos: %" PRIu64 " Dir %s dirty...syncing to disk", vol->header->write_pos, vol->hash_text.get());
       vol->header->dirty = 0;
       if (buflen < dirlen) {
-        if (buf)
-          ats_memalign_free(buf);
-        buf = (char *)ats_memalign(ats_pagesize(), dirlen);
+        if (buf) {
+          if (buf_huge)
+            ats_free_hugepage(buf, buflen);
+          else
+            ats_memalign_free(buf);
+          buf = NULL;
+        }
         buflen = dirlen;
+        if (ats_hugepage_enabled()) {
+          buf = (char *)ats_alloc_hugepage(buflen);
+          buf_huge = true;
+        }
+        if (buf == NULL) {
+          buf = (char *)ats_memalign(ats_pagesize(), buflen);
+          buf_huge = false;
+        }
       }
       vol->header->sync_serial++;
       vol->footer->sync_serial = vol->header->sync_serial;
diff --git a/iocore/cache/CacheVol.cc b/iocore/cache/CacheVol.cc
index 47f5775..fb82742 100644
--- a/iocore/cache/CacheVol.cc
+++ b/iocore/cache/CacheVol.cc
@@ -57,10 +57,11 @@ CacheVC::scanVol(int /* event ATS_UNUSED */, Event * /* e ATS_UNUSED */)
   Debug("cache_scan_truss", "inside %p:scanVol", this);
   if (_action.cancelled)
     return free_CacheVC(this);
-  CacheHostRecord *rec = &theCache->hosttable->gen_host_rec;
+  CacheHostTable *hosttable = theCache->getHosttable(__func__);
+  CacheHostRecord *rec = &hosttable->gen_host_rec;
   if (host_len) {
     CacheHostResult res;
-    theCache->hosttable->Match(hostname, host_len, &res);
+    hosttable->Match(hostname, host_len, &res);
     if (res.record)
       rec = res.record;
   }
diff --git a/iocore/cache/P_CacheDir.h b/iocore/cache/P_CacheDir.h
index 0a31c32..f5c83d5 100644
--- a/iocore/cache/P_CacheDir.h
+++ b/iocore/cache/P_CacheDir.h
@@ -293,6 +293,7 @@ struct CacheSync : public Continuation {
   int vol_idx;
   char *buf;
   size_t buflen;
+  bool buf_huge;
   off_t writepos;
   AIOCallbackInternal io;
   Event *trigger;
@@ -300,7 +301,8 @@ struct CacheSync : public Continuation {
   int mainEvent(int event, Event *e);
   void aio_write(int fd, char *b, int n, off_t o);
 
-  CacheSync() : Continuation(new_ProxyMutex()), vol_idx(0), buf(0), buflen(0), writepos(0), trigger(0), start_time(0)
+  CacheSync()
+    : Continuation(new_ProxyMutex()), vol_idx(0), buf(0), buflen(0), buf_huge(false), writepos(0), trigger(0), start_time(0)
   {
     SET_HANDLER(&CacheSync::mainEvent);
   }
diff --git a/iocore/cache/P_CacheHosting.h b/iocore/cache/P_CacheHosting.h
index 21d2b1a..c874f64 100644
--- a/iocore/cache/P_CacheHosting.h
+++ b/iocore/cache/P_CacheHosting.h
@@ -163,7 +163,8 @@ struct CacheHostTableConfig : public Continuation {
     (void)e;
     (void)event;
     CacheHostTable *t = new CacheHostTable((*ppt)->cache, (*ppt)->type);
-    CacheHostTable *old = (CacheHostTable *)ink_atomic_swap(&t, *ppt);
+    CacheHostTable *old = (CacheHostTable *)ink_atomic_swap(ppt, t);
+    Debug("cache_hosting", "swapped: old=%p, new=%p", old, t);
     new_Deleter(old, CACHE_MEM_FREE_TIMEOUT);
     return EVENT_DONE;
   }
diff --git a/iocore/cache/P_CacheInternal.h b/iocore/cache/P_CacheInternal.h
index d06c8d3..d27a752 100644
--- a/iocore/cache/P_CacheInternal.h
+++ b/iocore/cache/P_CacheInternal.h
@@ -1058,6 +1058,12 @@ struct Cache {
       hosttable(NULL), total_initialized_vol(0), scheme(CACHE_NONE_TYPE)
   {
   }
+  CacheHostTable *
+  getHosttable(const char *callfunc)
+  {
+    Debug("cache_hosting", "getHosttable() from: %s", callfunc);
+    return hosttable;
+  }
 };
 
 extern Cache *theCache;
diff --git a/lib/records/RecCore.cc b/lib/records/RecCore.cc
index 5babfad..9c75006 100644
--- a/lib/records/RecCore.cc
+++ b/lib/records/RecCore.cc
@@ -789,7 +789,7 @@ RecRegisterStat(RecT rec_type, const char *name, RecDataT data_type, RecData dat
     // new default value.
     if ((r->stat_meta.persist_type == RECP_NULL || r->stat_meta.persist_type == RECP_PERSISTENT) &&
         persist_type == RECP_NON_PERSISTENT) {
-      RecDebug(DL_Debug, "resetting default value for formerly persisted stat '%s'", r->name);
+      RecDebug(DL_Debug, "resetting default value for formerly persisted stat id:%d '%s'", r->rsb_id, r->name);
       RecDataSet(r->data_type, &(r->data), &(data_default));
     }
 
@@ -955,6 +955,8 @@ RecDumpRecords(RecT rec_type, RecDumpEntryCb callback, void *edata)
 {
   int i, num_records;
 
+  ink_rwlock_rdlock(&g_records_rwlock);
+
   num_records = g_num_records;
   for (i = 0; i < num_records; i++) {
     RecRecord *r = &(g_records[i]);
@@ -964,6 +966,8 @@ RecDumpRecords(RecT rec_type, RecDumpEntryCb callback, void *edata)
       rec_mutex_release(&(r->lock));
     }
   }
+
+  ink_rwlock_unlock(&g_records_rwlock);
 }
 
 void
diff --git a/lib/records/RecProcess.cc b/lib/records/RecProcess.cc
index f0c59bb..9a44ee6 100644
--- a/lib/records/RecProcess.cc
+++ b/lib/records/RecProcess.cc
@@ -173,12 +173,18 @@ raw_stat_sync_to_global(RecRawStatBlock *rsb, int id)
     tlp = ((RecRawStat *)((char *)(eventProcessor.all_ethreads[i]) + rsb->ethr_stat_offset)) + id;
     total.sum += tlp->sum;
     total.count += tlp->count;
+    // Debug("stats","raw_stat_sync_to_global(): ethread: %d, id: %d, total.sum: %" PRId64 ", total.count: %" PRId64 ", tlp->sum: %"
+    // PRId64 ", tlp->count: %" PRId64,
+    // i, id, total.sum, total.count, tlp->sum, tlp->count);
   }
 
   for (i = 0; i < eventProcessor.n_dthreads; i++) {
     tlp = ((RecRawStat *)((char *)(eventProcessor.all_dthreads[i]) + rsb->ethr_stat_offset)) + id;
     total.sum += tlp->sum;
     total.count += tlp->count;
+    // Debug("stats","raw_stat_sync_to_global(): dthread: %d, id: %d, total.sum: %" PRId64 ", total.count: %" PRId64 ", tlp->sum: %"
+    // PRId64 ", tlp->count: %" PRId64,
+    // i, id, total.sum, total.count, tlp->sum, tlp->count);
   }
 
   if (total.sum < 0) { // Assure that we stay positive
@@ -194,9 +200,9 @@ raw_stat_sync_to_global(RecRawStatBlock *rsb, int id)
   delta.count = total.count - rsb->global[id]->last_count;
 
   // This is too verbose now, so leaving it out / leif
-  // Debug("stats", "raw_stat_sync_to_global(): rsb pointer:%p id:%d delta:%" PRId64 " total:%" PRId64 " last:%" PRId64 " global:%"
-  // PRId64 "\n",
-  // rsb, id, delta.sum, total.sum, rsb->global[id]->last_sum, rsb->global[id]->sum);
+  Debug("stats.verbose", "raw_stat_sync_to_global(): rsb pointer:%p rsb data pointer:%p id:%d delta:%" PRId64 " total:%" PRId64
+                         " last:%" PRId64 " global:%" PRId64 "\n",
+        rsb, rsb->global[id], id, delta.sum, total.sum, rsb->global[id]->last_sum, rsb->global[id]->sum);
 
   // increment the global values by the delta
   ink_atomic_increment(&(rsb->global[id]->sum), delta.sum);
@@ -540,7 +546,7 @@ int
 _RecRegisterRawStat(RecRawStatBlock *rsb, RecT rec_type, const char *name, RecDataT data_type, RecPersistT persist_type, int id,
                     RecRawStatSyncCb sync_cb)
 {
-  Debug("stats", "RecRawStatSyncCb(%s): rsb pointer:%p id:%d\n", name, rsb, id);
+  Debug("stats", "_RecRegisterRawStat(%s): rsb pointer:%p id:%d\n", name, rsb, id);
 
   // check to see if we're good to proceed
   ink_assert(id < rsb->max_stats);
@@ -556,6 +562,11 @@ _RecRegisterRawStat(RecRawStatBlock *rsb, RecT rec_type, const char *name, RecDa
     err = REC_ERR_FAIL;
     goto Ldone;
   }
+  if (r->rsb_id > 0 && r->rsb_id != id) {
+    Warning("_RecRegisterRawStat(): Created and reusing a stat with id = %d for new stat named %s", r->rsb_id, name);
+  } else {
+    Warning("_RecRegisterStat(): Stat created, name: %s, id: %d", name, id);
+  }
   r->rsb_id = id; // This is the index within the RSB raw block for this stat, used for lookups by name.
   if (i_am_the_record_owner(r->rec_type)) {
     r->sync_required = r->sync_required | REC_PEER_SYNC_REQUIRED;
@@ -570,6 +581,7 @@ _RecRegisterRawStat(RecRawStatBlock *rsb, RecT rec_type, const char *name, RecDa
 
   // setup the periodic sync callback
   RecRegisterRawStatSyncCb(name, sync_cb, rsb, id);
+  Warning("_RecRegisterRawStat(): Stat created, id:%d name:%s, data address:%p", id, name, &r->stat_meta.data_raw);
 
 Ldone:
   return err;
diff --git a/lib/ts/ConsistentHash.cc b/lib/ts/ConsistentHash.cc
index c983ccb..912bc74 100644
--- a/lib/ts/ConsistentHash.cc
+++ b/lib/ts/ConsistentHash.cc
@@ -67,13 +67,19 @@ ATSConsistentHash::insert(ATSConsistentHashNode *node, float weight, ATSHash64 *
 }
 
 ATSConsistentHashNode *
-ATSConsistentHash::lookup(const char *url, ATSConsistentHashIter *i, bool *w, ATSHash64 *h)
+ATSConsistentHash::lookup(const char *url, size_t url_len, ATSConsistentHashIter *i, bool *w, ATSHash64 *h)
 {
   uint64_t url_hash;
   ATSConsistentHashIter NodeMapIterUp, *iter;
   ATSHash64 *thash;
   bool *wptr, wrapped = false;
 
+  if (url_len <= 0 && url) {
+    url_len = strlen(url);
+  } else {
+    url_len = 0;
+  }
+
   if (h) {
     thash = h;
   } else if (hash) {
@@ -95,7 +101,7 @@ ATSConsistentHash::lookup(const char *url, ATSConsistentHashIter *i, bool *w, AT
   }
 
   if (url) {
-    thash->update(url, strlen(url));
+    thash->update(url, url_len);
     thash->final();
     url_hash = thash->get();
     thash->clear();
@@ -124,13 +130,19 @@ ATSConsistentHash::lookup(const char *url, ATSConsistentHashIter *i, bool *w, AT
 }
 
 ATSConsistentHashNode *
-ATSConsistentHash::lookup_available(const char *url, ATSConsistentHashIter *i, bool *w, ATSHash64 *h)
+ATSConsistentHash::lookup_available(const char *url, size_t url_len, ATSConsistentHashIter *i, bool *w, ATSHash64 *h)
 {
   uint64_t url_hash;
   ATSConsistentHashIter NodeMapIterUp, *iter;
   ATSHash64 *thash;
   bool *wptr, wrapped = false;
 
+  if (url_len <= 0 && url) {
+    url_len = strlen(url);
+  } else {
+    url_len = 0;
+  }
+
   if (h) {
     thash = h;
   } else if (hash) {
@@ -152,7 +164,7 @@ ATSConsistentHash::lookup_available(const char *url, ATSConsistentHashIter *i, b
   }
 
   if (url) {
-    thash->update(url, strlen(url));
+    thash->update(url, url_len);
     thash->final();
     url_hash = thash->get();
     thash->clear();
@@ -179,6 +191,34 @@ ATSConsistentHash::lookup_available(const char *url, ATSConsistentHashIter *i, b
   return (*iter)->second;
 }
 
+ATSConsistentHashNode *
+ATSConsistentHash::lookup_by_hashval(uint64_t hashval, ATSConsistentHashIter *i, bool *w)
+{
+  ATSConsistentHashIter NodeMapIterUp, *iter;
+  bool *wptr, wrapped = false;
+
+  if (w) {
+    wptr = w;
+  } else {
+    wptr = &wrapped;
+  }
+
+  if (i) {
+    iter = i;
+  } else {
+    iter = &NodeMapIterUp;
+  }
+
+  *iter = NodeMap.lower_bound(hashval);
+
+  if (*iter == NodeMap.end()) {
+    *wptr = true;
+    *iter = NodeMap.begin();
+  }
+
+  return (*iter)->second;
+}
+
 ATSConsistentHash::~ATSConsistentHash()
 {
   if (hash) {
diff --git a/lib/ts/ConsistentHash.h b/lib/ts/ConsistentHash.h
index 6406a6c6..49822ad 100644
--- a/lib/ts/ConsistentHash.h
+++ b/lib/ts/ConsistentHash.h
@@ -49,9 +49,11 @@ typedef std::map<uint64_t, ATSConsistentHashNode *>::iterator ATSConsistentHashI
 struct ATSConsistentHash {
   ATSConsistentHash(int r = 1024, ATSHash64 *h = NULL);
   void insert(ATSConsistentHashNode *node, float weight = 1.0, ATSHash64 *h = NULL);
-  ATSConsistentHashNode *lookup(const char *url = NULL, ATSConsistentHashIter *i = NULL, bool *w = NULL, ATSHash64 *h = NULL);
-  ATSConsistentHashNode *lookup_available(const char *url = NULL, ATSConsistentHashIter *i = NULL, bool *w = NULL,
-                                          ATSHash64 *h = NULL);
+  ATSConsistentHashNode *lookup(const char *url = NULL, size_t url_len = 0, ATSConsistentHashIter *i = NULL, bool *w = NULL,
+                                ATSHash64 *h = NULL);
+  ATSConsistentHashNode *lookup_available(const char *url = NULL, size_t url_len = 0, ATSConsistentHashIter *i = NULL,
+                                          bool *w = NULL, ATSHash64 *h = NULL);
+  ATSConsistentHashNode *lookup_by_hashval(uint64_t hashval, ATSConsistentHashIter *i = NULL, bool *w = NULL);
   ~ATSConsistentHash();
 
 private:
diff --git a/lib/ts/Makefile.am b/lib/ts/Makefile.am
index d5ca4ac..3f5eee5 100644
--- a/lib/ts/Makefile.am
+++ b/lib/ts/Makefile.am
@@ -107,6 +107,8 @@ libtsutil_la_SOURCES = \
   defalloc.h \
   fastlz.c \
   fastlz.h \
+  hugepages.cc \
+  hugepages.h \
   ink_aiocb.h \
   ink_align.h \
   ink_apidefs.h \
diff --git a/lib/ts/apidefs.h.in b/lib/ts/apidefs.h.in
index 04f4dd9..31cb807 100644
--- a/lib/ts/apidefs.h.in
+++ b/lib/ts/apidefs.h.in
@@ -758,6 +758,14 @@ extern "C"
     TS_CONFIG_HTTP_POST_CHECK_CONTENT_LENGTH_ENABLED,
     TS_CONFIG_HTTP_GLOBAL_USER_AGENT_HEADER,
     TS_CONFIG_HTTP_AUTH_SERVER_SESSION_PRIVATE,
+    TS_CONFIG_HTTP_TRANSACTION_ACTIVE_TIMEOUT_IN,
+    TS_CONFIG_HTTP_PER_PARENT_CONNECT_ATTEMPTS,
+    TS_CONFIG_HTTP_PARENT_TOTAL_CONNECT_ATTEMPTS,
+    TS_CONFIG_HTTP_SIMPLE_RETRY_ENABLED,
+    TS_CONFIG_HTTP_SIMPLE_RETRY_RESPONSE_CODES,
+    TS_CONFIG_HTTP_DEAD_SERVER_RETRY_ENABLED,
+    TS_CONFIG_HTTP_DEAD_SERVER_RETRY_RESPONSE_CODES,
+    TS_CONFIG_HTTP_URL_REMAP_REQUIRED,
     TS_CONFIG_LAST_ENTRY
   } TSOverridableConfigKey;
 
diff --git a/lib/ts/hugepages.cc b/lib/ts/hugepages.cc
new file mode 100644
index 0000000..d7d94a4
--- /dev/null
+++ b/lib/ts/hugepages.cc
@@ -0,0 +1,147 @@
+/** @file
+
+  @section license License
+
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+ */
+
+#include <cstdio>
+#include <sys/mman.h>
+#include "Diags.h"
+#include "ink_align.h"
+
+#define DEBUG_TAG "hugepages"
+
+#ifdef MAP_HUGETLB
+#define MEMINFO_PATH "/proc/meminfo"
+#define LINE_SIZE 256
+#define TOKEN "Hugepagesize:"
+#define TOKEN_SIZE (strlen(TOKEN))
+
+static int hugepage_size = -1;
+static bool hugepage_enabled;
+#endif
+
+size_t
+ats_hugepage_size(void)
+{
+#ifdef MAP_HUGETLB
+  return hugepage_size;
+#else
+  Debug(DEBUG_TAG, "MAP_HUGETLB not defined");
+  return 0;
+#endif
+}
+
+bool
+ats_hugepage_enabled(void)
+{
+#ifdef MAP_HUGETLB
+  return hugepage_enabled;
+#else
+  return false;
+#endif
+}
+
+void
+ats_hugepage_init(int enabled)
+{
+#ifdef MAP_HUGETLB
+  FILE *fp;
+  char line[LINE_SIZE];
+  char *p, *ep;
+
+  hugepage_size = 0;
+
+  if (!enabled) {
+    Debug(DEBUG_TAG, "hugepages not enabled");
+    return;
+  }
+
+  fp = fopen(MEMINFO_PATH, "r");
+
+  if (fp == NULL) {
+    Debug(DEBUG_TAG, "Cannot open file %s", MEMINFO_PATH);
+    return;
+  }
+
+  while (fgets(line, sizeof(line), fp)) {
+    if (strncmp(line, TOKEN, TOKEN_SIZE) == 0) {
+      p = line + TOKEN_SIZE;
+      while (*p == ' ') {
+        p++;
+      }
+      hugepage_size = strtol(p, &ep, 10);
+      // What other values can this be?
+      if (strncmp(ep, " kB", 4)) {
+        hugepage_size *= 1024;
+      }
+      break;
+    }
+  }
+
+  fclose(fp);
+
+  if (hugepage_size) {
+    hugepage_enabled = true;
+  }
+
+  Debug(DEBUG_TAG, "Hugepage size = %d", hugepage_size);
+#else
+  Debug(DEBUG_TAG, "MAP_HUGETLB not defined");
+#endif
+}
+
+void *
+ats_alloc_hugepage(size_t s)
+{
+#ifdef MAP_HUGETLB
+  size_t size;
+  void *mem;
+
+  size = INK_ALIGN(s, ats_hugepage_size());
+
+  mem = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_HUGETLB, -1, 0);
+
+  if (mem == MAP_FAILED) {
+    Debug(DEBUG_TAG, "Could not allocate hugepages size = %zu", size);
+    return NULL;
+  }
+
+  return mem;
+#else
+  (void)s;
+  Debug(DEBUG_TAG, "MAP_HUGETLB not defined");
+  return NULL;
+#endif
+}
+
+bool
+ats_free_hugepage(void *ptr, size_t s)
+{
+#ifdef MAP_HUGETLB
+  size_t size;
+
+  size = INK_ALIGN(s, ats_hugepage_size());
+  return (munmap(ptr, size) == 0);
+#else
+  (void)ptr;
+  (void)s;
+  Debug(DEBUG_TAG, "MAP_HUGETLB not defined");
+  return false;
+#endif
+}
diff --git a/lib/ts/hugepages.h b/lib/ts/hugepages.h
new file mode 100644
index 0000000..812542b
--- /dev/null
+++ b/lib/ts/hugepages.h
@@ -0,0 +1,32 @@
+/** @file
+
+  @section license License
+
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+ */
+#ifndef _hugepages_h_
+#define _hugepages_h_
+
+#include <cstring>
+
+size_t ats_hugepage_size(void);
+bool ats_hugepage_enabled(void);
+void ats_hugepage_init(int);
+void *ats_alloc_hugepage(size_t);
+bool ats_free_hugepage(void *, size_t);
+
+#endif
diff --git a/lib/ts/ink_queue.cc b/lib/ts/ink_queue.cc
index e718b3f..0f14b68 100644
--- a/lib/ts/ink_queue.cc
+++ b/lib/ts/ink_queue.cc
@@ -50,6 +50,7 @@
 #include "ink_assert.h"
 #include "ink_queue_ext.h"
 #include "ink_align.h"
+#include "hugepages.h"
 
 inkcoreapi volatile int64_t fastalloc_mem_in_use = 0;
 inkcoreapi volatile int64_t fastalloc_mem_total = 0;
@@ -100,9 +101,13 @@ ink_freelist_init(InkFreeList **fl, const char *name, uint32_t type_size, uint32
   /* quick test for power of 2 */
   ink_assert(!(alignment & (alignment - 1)));
   f->alignment = alignment;
-  f->chunk_size = chunk_size;
   // Make sure we align *all* the objects in the allocation, not just the first one
   f->type_size = INK_ALIGN(type_size, alignment);
+  if (ats_hugepage_enabled()) {
+    f->chunk_size = INK_ALIGN(chunk_size * f->type_size, ats_hugepage_size()) / f->type_size;
+  } else {
+    f->chunk_size = chunk_size;
+  }
   SET_FREELIST_POINTER_VERSION(f->head, FROM_PTR(0), 0);
 
   f->used = 0;
@@ -171,12 +176,16 @@ ink_freelist_new(InkFreeList *f)
 #ifdef DEBUG
       char *oldsbrk = (char *)sbrk(0), *newsbrk = NULL;
 #endif
-      if (f->alignment)
-        newp = ats_memalign(f->alignment, f->chunk_size * type_size);
-      else
-        newp = ats_malloc(f->chunk_size * type_size);
+      if (ats_hugepage_enabled())
+        newp = ats_alloc_hugepage(f->chunk_size * type_size);
+
+      if (newp == NULL) {
+        if (f->alignment)
+          newp = ats_memalign(f->alignment, f->chunk_size * type_size);
+        else
+          newp = ats_malloc(f->chunk_size * type_size);
+      }
       ats_madvise((caddr_t)newp, f->chunk_size * type_size, f->advice);
-
       fl_memadd(f->chunk_size * type_size);
 #ifdef DEBUG
       newsbrk = (char *)sbrk(0);
diff --git a/lib/ts/libts.h b/lib/ts/libts.h
index d244158..20f85b2 100644
--- a/lib/ts/libts.h
+++ b/lib/ts/libts.h
@@ -41,6 +41,7 @@
 #define std *** _FIXME_REMOVE_DEPENDENCY_ON_THE_STL_ ***
 */
 
+#include "hugepages.h"
 #include "ink_config.h"
 #include "ink_platform.h"
 #include "ink_align.h"
diff --git a/mgmt/RecordsConfig.cc b/mgmt/RecordsConfig.cc
index f520f4a..0e229c2 100644
--- a/mgmt/RecordsConfig.cc
+++ b/mgmt/RecordsConfig.cc
@@ -506,6 +506,17 @@ static const RecordElement RecordsConfig[] =
   ,
 
   //        ###################################
+  //        # parent origin configuration     #
+  //        ###################################
+  {RECT_CONFIG, "proxy.config.http.parent_origin.simple_retry_enabled", RECD_INT, "0", RECU_DYNAMIC, RR_NULL, RECC_INT, "[0-1]", RECA_NULL}
+  ,
+  {RECT_CONFIG, "proxy.config.http.parent_origin.simple_retry_response_codes", RECD_STRING, "404", RECU_DYNAMIC, RR_NULL, RECC_STR, "^([0-9]+,)$", RECA_NULL}
+  ,
+  {RECT_CONFIG, "proxy.config.http.parent_origin.dead_server_retry_enabled", RECD_INT, "0", RECU_DYNAMIC, RR_NULL, RECC_INT, "[0-1]", RECA_NULL}
+  ,
+  {RECT_CONFIG, "proxy.config.http.parent_origin.dead_server_retry_response_codes", RECD_STRING, "503", RECU_DYNAMIC, RR_NULL, RECC_STR, "^([0-9]+,)$", RECA_NULL}
+  ,
+  //        ###################################
   //        # NO DNS DOC IN CACHE             #
   //        ###################################
   {RECT_CONFIG, "proxy.config.http.doc_in_cache_skip_dns", RECD_INT, "1", RECU_DYNAMIC, RR_NULL, RECC_INT, "[0-1]", RECA_NULL}
@@ -647,6 +658,13 @@ static const RecordElement RecordsConfig[] =
   ,
   {RECT_CONFIG, "proxy.config.http.cache.max_open_write_retries", RECD_INT, "1", RECU_DYNAMIC, RR_NULL, RECC_NULL, NULL, RECA_NULL}
   ,
+  //       #  open_write_fail_action has 3 options:
+  //       #
+  //       #  0 - default. disable cache and goto origin
+  //       #  1 - return error if cache miss
+  //       #  2 - serve stale until proxy.config.http.cache.max_stale_age, then goto origin, if refresh_miss
+  {RECT_CONFIG, "proxy.config.http.cache.open_write_fail_action", RECD_INT, "0", RECU_DYNAMIC, RR_NULL, RECC_NULL, NULL, RECA_NULL}
+  ,
   //       #  when_to_revalidate has 4 options:
   //       #
   //       #  0 - default. use use cache directives or heuristic
@@ -2067,6 +2085,8 @@ static const RecordElement RecordsConfig[] =
   ,
   {RECT_CONFIG, "proxy.config.allocator.debug_filter", RECD_INT, "0", RECU_NULL, RR_NULL, RECC_NULL, "[0-3]", RECA_NULL}
   ,
+  {RECT_CONFIG, "proxy.config.allocator.hugepages", RECD_INT, "0", RECU_RESTART_TS, RR_NULL, RECC_NULL, "[0-1]", RECA_NULL}
+  ,
 
   //############
   //#
diff --git a/plugins/cacheurl/cacheurl.cc b/plugins/cacheurl/cacheurl.cc
index 5f03598..52565fc 100644
--- a/plugins/cacheurl/cacheurl.cc
+++ b/plugins/cacheurl/cacheurl.cc
@@ -42,6 +42,7 @@
 #define TOKENCOUNT 10
 #define OVECOUNT 30
 #define PLUGIN_NAME "cacheurl"
+#define DEFAULT_CONFIG "cacheurl.config"
 
 struct regex_info {
   pcre *re;          /* Compiled regular expression */
@@ -213,10 +214,10 @@ load_config_file(const char *config_file)
   regex_info *info = 0;
 
   if (config_file == NULL) {
-    /* Default config file of plugins/cacheurl.config */
-    path = TSPluginDirGet();
-    path += "/cacheurl.config";
-  } else if (*config_file != '/') {
+    config_file = DEFAULT_CONFIG;
+  }
+
+  if (*config_file != '/') {
     // Relative paths are relative to the config directory
     path = TSConfigDirGet();
     path += "/";
diff --git a/plugins/experimental/Makefile.am b/plugins/experimental/Makefile.am
index 2ef296c..52fef44 100644
--- a/plugins/experimental/Makefile.am
+++ b/plugins/experimental/Makefile.am
@@ -19,6 +19,7 @@ SUBDIRS = \
  background_fetch \
  balancer \
  buffer_upload \
+ cache_range_requests \
  channel_stats \
  collapsed_connection \
  custom_redirect \
diff --git a/plugins/experimental/background_fetch/background_fetch.cc b/plugins/experimental/background_fetch/background_fetch.cc
index 878183e..fd0af7a 100644
--- a/plugins/experimental/background_fetch/background_fetch.cc
+++ b/plugins/experimental/background_fetch/background_fetch.cc
@@ -84,8 +84,13 @@ read_config(char *config_file, BgFetchRuleMap *ri)
     snprintf(file_path, sizeof(file_path), "%s/%s", TSInstallDirGet(), config_file);
     file = TSfopen(file_path, "r");
     if (file == NULL) {
-      TSError("%s: invalid config file", PLUGIN_NAME);
-      return false;
+      TSDebug(PLUGIN_NAME, "Failed to open config file %s, trying config path", config_file);
+      snprintf(file_path, sizeof(file_path), "%s/%s", TSConfigDirGet(), config_file);
+      file = TSfopen(file_path, "r");
+      if (file == NULL) {
+        TSError("%s: invalid config file", PLUGIN_NAME);
+        return false;
+      }
     }
   }
 
diff --git a/plugins/experimental/cache_range_requests/Makefile.am b/plugins/experimental/cache_range_requests/Makefile.am
new file mode 100644
index 0000000..5a27cac
--- /dev/null
+++ b/plugins/experimental/cache_range_requests/Makefile.am
@@ -0,0 +1,21 @@
+#  Licensed to the Apache Software Foundation (ASF) under one
+#  or more contributor license agreements.  See the NOTICE file
+#  distributed with this work for additional information
+#  regarding copyright ownership.  The ASF licenses this file
+#  to you under the Apache License, Version 2.0 (the
+#  "License"); you may not use this file except in compliance
+#  with the License.  You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+#  See the License for the specific language governing permissions and
+#  limitations under the License.
+
+include $(top_srcdir)/build/plugins.mk
+
+pkglib_LTLIBRARIES = cache_range_requests.la
+cache_range_requests_la_SOURCES = cache_range_requests.cc
+cache_range_requests_la_LDFLAGS = $(TS_PLUGIN_LDFLAGS)
diff --git a/plugins/experimental/cache_range_requests/README b/plugins/experimental/cache_range_requests/README
new file mode 100644
index 0000000..faddeb5
--- /dev/null
+++ b/plugins/experimental/cache_range_requests/README
@@ -0,0 +1,36 @@
+
+Thousands of range requests for a very large object in the traffic server cache
+are likely to increase system load averages due to I/O wait as objects are stored
+on a single stripe or disk drive.
+
+This plugin allows you to remap individual range requests so that they are stored
+as individual objects in the ATS cache when subsequent range requests are likely
+to use the same range.  This spreads range requests over multiple stripes thereby
+reducing I/O wait and system load averages.
+
+This plugin reads the range request header byte range value and then creates a
+new cache key url using the original request url with the range value appended
+to it.  The range header is removed where appropriate from the requests and the
+origin server response code is changed from a 206 to a 200 to insure that the
+object is written to cache using the new cache key url.  The response code sent 
+to the client will be changed back to a 206 and all requests to the origin server 
+will contain the range header so that the correct response is received.
+
+Installation:
+
+    make
+    sudo make install
+
+If you don't have the traffic server binaries in your path, then you will need
+to specify the path to tsxs manually:
+
+    make TSXS=/opt/trafficserver/bin/tsxs
+    sudo make TSXS=/opt/trafficserver/bin/tsxs install
+
+Configuration:
+
+    Add @plugin=cache_range_requests.so to your remap.config rules.
+
+    Or for a global plugin where all range requests are processed,
+    Add cache_range_requests.so to the plugin.config
+
diff --git a/plugins/experimental/cache_range_requests/cache_range_requests.cc b/plugins/experimental/cache_range_requests/cache_range_requests.cc
new file mode 100644
index 0000000..8722279
--- /dev/null
+++ b/plugins/experimental/cache_range_requests/cache_range_requests.cc
@@ -0,0 +1,411 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the
+ * License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*
+ * This plugin looks for range requests and then creates a new
+ * cache key url so that each individual range requests is written
+ * to the cache as a individual object so that subsequent range
+ * requests are read accross different disk drives reducing I/O
+ * wait and load averages when there are large numbers of range
+ * requests.
+ */
+
+#include <stdio.h>
+#include <string.h>
+#include "ts/ts.h"
+#include "ts/remap.h"
+
+#define PLUGIN_NAME "cache_range_requests"
+#define DEBUG_LOG(fmt, ...) TSDebug(PLUGIN_NAME, "[%s:%d] %s(): " fmt, __FILE__, __LINE__, __func__, ##__VA_ARGS__)
+#define ERROR_LOG(fmt, ...) TSError("[%s:%d] %s(): " fmt, __FILE__, __LINE__, __func__, ##__VA_ARGS__)
+
+struct txndata {
+  char *range_value;
+};
+
+static void handle_read_request_header(TSCont, TSEvent, void *);
+static void range_header_check(TSHttpTxn txnp);
+static void handle_send_origin_request(TSCont, TSHttpTxn, struct txndata *);
+static void handle_client_send_response(TSHttpTxn, struct txndata *);
+static void handle_server_read_response(TSHttpTxn, struct txndata *);
+static int remove_header(TSMBuffer, TSMLoc, const char *, int);
+static bool set_header(TSMBuffer, TSMLoc, const char *, int, const char *, int);
+static void transaction_handler(TSCont, TSEvent, void *);
+
+/**
+ * Entry point when used as a global plugin.
+ *
+ */
+static void
+handle_read_request_header(TSCont txn_contp, TSEvent event, void *edata)
+{
+  TSHttpTxn txnp = static_cast<TSHttpTxn>(edata);
+
+  range_header_check(txnp);
+
+  TSHttpTxnReenable(txnp, TS_EVENT_HTTP_CONTINUE);
+}
+
+/**
+ * Reads the client request header and if this is a range request:
+ *
+ * 1. creates a new cache key url using the range request information.
+ * 2. Saves the range request information and then removes the range
+ *    header so that the response retrieved from the origin will
+ *    be written to cache.
+ * 3. Schedules TS_HTTP_SEND_REQUEST_HDR_HOOK, TS_HTTP_SEND_RESPONSE_HDR_HOOK,
+ *    and TS_HTTP_TXN_CLOSE_HOOK for further processing.
+ */
+static void
+range_header_check(TSHttpTxn txnp)
+{
+  char cache_key_url[8192] = {0};
+  char *req_url;
+  int length, url_length;
+  struct txndata *txn_state;
+  TSMBuffer hdr_bufp;
+  TSMLoc req_hdrs = NULL;
+  TSMLoc loc = NULL;
+  TSCont txn_contp;
+
+  if (TS_SUCCESS == TSHttpTxnClientReqGet(txnp, &hdr_bufp, &req_hdrs)) {
+    loc = TSMimeHdrFieldFind(hdr_bufp, req_hdrs, TS_MIME_FIELD_RANGE, TS_MIME_LEN_RANGE);
+    if (TS_NULL_MLOC != loc) {
+      const char *hdr_value = TSMimeHdrFieldValueStringGet(hdr_bufp, req_hdrs, loc, 0, &length);
+      if (!hdr_value || length <= 0) {
+        DEBUG_LOG("Not a range request.");
+      } else {
+        if (NULL == (txn_contp = TSContCreate((TSEventFunc)transaction_handler, NULL))) {
+          ERROR_LOG("failed to create the transaction handler continuation.");
+        } else {
+          txn_state = (struct txndata *)TSmalloc(sizeof(struct txndata));
+          txn_state->range_value = TSstrndup(hdr_value, length);
+          DEBUG_LOG("length: %d, txn_state->range_value: %s", length, txn_state->range_value);
+          txn_state->range_value[length] = '\0'; // workaround for bug in core
+
+          req_url = TSHttpTxnEffectiveUrlStringGet(txnp, &url_length);
+          snprintf(cache_key_url, 8192, "%s-%s", req_url, txn_state->range_value);
+          DEBUG_LOG("Rewriting cache URL for %s to %s", req_url, cache_key_url);
+          if (req_url != NULL)
+            TSfree(req_url);
+
+          // set the cache key.
+          if (TS_SUCCESS != TSCacheUrlSet(txnp, cache_key_url, strlen(cache_key_url))) {
+            DEBUG_LOG("failed to change the cache url to %s.", cache_key_url);
+          }
+          // remove the range request header.
+          if (remove_header(hdr_bufp, req_hdrs, TS_MIME_FIELD_RANGE, TS_MIME_LEN_RANGE) > 0) {
+            DEBUG_LOG("Removed the Range: header from the request.");
+          }
+
+          TSContDataSet(txn_contp, txn_state);
+          TSHttpTxnHookAdd(txnp, TS_HTTP_SEND_REQUEST_HDR_HOOK, txn_contp);
+          TSHttpTxnHookAdd(txnp, TS_HTTP_SEND_RESPONSE_HDR_HOOK, txn_contp);
+          TSHttpTxnHookAdd(txnp, TS_HTTP_TXN_CLOSE_HOOK, txn_contp);
+          DEBUG_LOG("Added TS_HTTP_SEND_REQUEST_HDR_HOOK, TS_HTTP_SEND_RESPONSE_HDR_HOOK, and TS_HTTP_TXN_CLOSE_HOOK");
+        }
+      }
+      TSHandleMLocRelease(hdr_bufp, req_hdrs, loc);
+    } else {
+      DEBUG_LOG("no range request header.");
+    }
+    TSHandleMLocRelease(hdr_bufp, req_hdrs, NULL);
+  } else {
+    DEBUG_LOG("failed to retrieve the server request");
+  }
+}
+
+/**
+ * Restores the range request header if the request must be
+ * satisfied from the origin and schedules the TS_READ_RESPONSE_HDR_HOOK.
+ */
+static void
+handle_send_origin_request(TSCont contp, TSHttpTxn txnp, struct txndata *txn_state)
+{
+  TSMBuffer hdr_bufp;
+  TSMLoc req_hdrs = NULL;
+
+  if (TS_SUCCESS == TSHttpTxnServerReqGet(txnp, &hdr_bufp, &req_hdrs) && txn_state->range_value != NULL) {
+    if (set_header(hdr_bufp, req_hdrs, TS_MIME_FIELD_RANGE, TS_MIME_LEN_RANGE, txn_state->range_value,
+                   strlen(txn_state->range_value))) {
+      DEBUG_LOG("Added range header: %s", txn_state->range_value);
+      TSHttpTxnHookAdd(txnp, TS_HTTP_READ_RESPONSE_HDR_HOOK, contp);
+    }
+  }
+  TSHandleMLocRelease(hdr_bufp, req_hdrs, NULL);
+}
+
+/**
+ * Changes the response code back to a 206 Partial content before
+ * replying to the client that requested a range.
+ */
+static void
+handle_client_send_response(TSHttpTxn txnp, struct txndata *txn_state)
+{
+  bool partial_content_reason = false;
+  char *p;
+  int length;
+  TSMBuffer response, hdr_bufp;
+  TSMLoc resp_hdr, req_hdrs = NULL;
+
+  TSReturnCode result = TSHttpTxnClientRespGet(txnp, &response, &resp_hdr);
+  DEBUG_LOG("result: %d", result);
+  if (TS_SUCCESS == result) {
+    TSHttpStatus status = TSHttpHdrStatusGet(response, resp_hdr);
+    // a cached result will have a TS_HTTP_OK with a 'Partial Content' reason
+    if ((p = (char *)TSHttpHdrReasonGet(response, resp_hdr, &length)) != NULL) {
+      if ((length == 15) && (0 == strncasecmp(p, "Partial Content", length))) {
+        partial_content_reason = true;
+      }
+    }
+    DEBUG_LOG("%d %.*s", status, length, p);
+    if (TS_HTTP_STATUS_OK == status && partial_content_reason) {
+      DEBUG_LOG("Got TS_HTTP_STATUS_OK.");
+      TSHttpHdrStatusSet(response, resp_hdr, TS_HTTP_STATUS_PARTIAL_CONTENT);
+      DEBUG_LOG("Set response header to TS_HTTP_STATUS_PARTIAL_CONTENT.");
+    }
+  }
+  // add the range request header back in so that range requests may be logged.
+  if (TS_SUCCESS == TSHttpTxnClientReqGet(txnp, &hdr_bufp, &req_hdrs) && txn_state->range_value != NULL) {
+    if (set_header(hdr_bufp, req_hdrs, TS_MIME_FIELD_RANGE, TS_MIME_LEN_RANGE, txn_state->range_value,
+                   strlen(txn_state->range_value))) {
+      DEBUG_LOG("added range header: %s", txn_state->range_value);
+    } else {
+      DEBUG_LOG("set_header() failed.");
+    }
+  } else {
+    DEBUG_LOG("failed to get Request Headers");
+  }
+  TSHandleMLocRelease(response, resp_hdr, NULL);
+  TSHandleMLocRelease(hdr_bufp, req_hdrs, NULL);
+}
+
+/**
+ * After receiving a range request response from the origin, change
+ * the response code from a 206 Partial content to a 200 OK so that
+ * the response will be written to cache.
+ */
+static void
+handle_server_read_response(TSHttpTxn txnp, struct txndata *txn_state)
+{
+  TSMBuffer response;
+  TSMLoc resp_hdr;
+  TSHttpStatus status;
+
+  if (TS_SUCCESS == TSHttpTxnServerRespGet(txnp, &response, &resp_hdr)) {
+    status = TSHttpHdrStatusGet(response, resp_hdr);
+    if (TS_HTTP_STATUS_PARTIAL_CONTENT == status) {
+      DEBUG_LOG("Got TS_HTTP_STATUS_PARTIAL_CONTENT.");
+      TSHttpHdrStatusSet(response, resp_hdr, TS_HTTP_STATUS_OK);
+      DEBUG_LOG("Set response header to TS_HTTP_STATUS_OK.");
+      bool cacheable = TSHttpTxnIsCacheable(txnp, NULL, response);
+      DEBUG_LOG("range is cacheable: %d", cacheable);
+    } else if (TS_HTTP_STATUS_OK == status) {
+      DEBUG_LOG("The origin does not support range requests, attempting to disable cache write.");
+      if (TS_SUCCESS == TSHttpTxnServerRespNoStoreSet(txnp, 1)) {
+        DEBUG_LOG("Cache write has been disabled for this transaction.");
+      } else {
+        DEBUG_LOG("Unable to disable cache write for this transaction.");
+      }
+    }
+  }
+  TSHandleMLocRelease(response, resp_hdr, NULL);
+}
+
+/**
+ * Remove a header (fully) from an TSMLoc / TSMBuffer. Return the number
+ * of fields (header values) we removed.
+ *
+ * From background_fetch.cc
+ */
+static int
+remove_header(TSMBuffer bufp, TSMLoc hdr_loc, const char *header, int len)
+{
+  TSMLoc field = TSMimeHdrFieldFind(bufp, hdr_loc, header, len);
+  int cnt = 0;
+
+  while (field) {
+    TSMLoc tmp = TSMimeHdrFieldNextDup(bufp, hdr_loc, field);
+
+    ++cnt;
+    TSMimeHdrFieldDestroy(bufp, hdr_loc, field);
+    TSHandleMLocRelease(bufp, hdr_loc, field);
+    field = tmp;
+  }
+
+  return cnt;
+}
+
+/**
+ * Set a header to a specific value. This will avoid going to through a
+ * remove / add sequence in case of an existing header.
+ * but clean.
+ *
+ * From background_fetch.cc
+ */
+static bool
+set_header(TSMBuffer bufp, TSMLoc hdr_loc, const char *header, int len, const char *val, int val_len)
+{
+  if (!bufp || !hdr_loc || !header || len <= 0 || !val || val_len <= 0) {
+    return false;
+  }
+
+  DEBUG_LOG("header: %s, len: %d, val: %s, val_len: %d", header, len, val, val_len);
+  bool ret = false;
+  TSMLoc field_loc = TSMimeHdrFieldFind(bufp, hdr_loc, header, len);
+
+  if (!field_loc) {
+    // No existing header, so create one
+    if (TS_SUCCESS == TSMimeHdrFieldCreateNamed(bufp, hdr_loc, header, len, &field_loc)) {
+      if (TS_SUCCESS == TSMimeHdrFieldValueStringSet(bufp, hdr_loc, field_loc, -1, val, val_len)) {
+        TSMimeHdrFieldAppend(bufp, hdr_loc, field_loc);
+        ret = true;
+      }
+      TSHandleMLocRelease(bufp, hdr_loc, field_loc);
+    }
+  } else {
+    TSMLoc tmp = NULL;
+    bool first = true;
+
+    while (field_loc) {
+      if (first) {
+        first = false;
+        if (TS_SUCCESS == TSMimeHdrFieldValueStringSet(bufp, hdr_loc, field_loc, -1, val, val_len)) {
+          ret = true;
+        }
+      } else {
+        TSMimeHdrFieldDestroy(bufp, hdr_loc, field_loc);
+      }
+      tmp = TSMimeHdrFieldNextDup(bufp, hdr_loc, field_loc);
+      TSHandleMLocRelease(bufp, hdr_loc, field_loc);
+      field_loc = tmp;
+    }
+  }
+
+  return ret;
+}
+
+/**
+ * Remap initialization.
+ */
+TSReturnCode
+TSRemapInit(TSRemapInterface *api_info, char *errbuf, int errbuf_size)
+{
+  if (!api_info) {
+    strncpy(errbuf, "[tsremap_init] - Invalid TSRemapInterface argument", errbuf_size - 1);
+    return TS_ERROR;
+  }
+
+  if (api_info->tsremap_version < TSREMAP_VERSION) {
+    snprintf(errbuf, errbuf_size - 1, "[TSRemapInit] - Incorrect API version %ld.%ld", api_info->tsremap_version >> 16,
+             (api_info->tsremap_version & 0xffff));
+    return TS_ERROR;
+  }
+
+  DEBUG_LOG("cache_range_requests remap is successfully initialized.");
+  return TS_SUCCESS;
+}
+
+/**
+ * not used.
+ */
+TSReturnCode
+TSRemapNewInstance(int argc, char *argv[], void **ih, char * /*errbuf */, int /* errbuf_size */)
+{
+  return TS_SUCCESS;
+}
+
+/**
+ * not used.
+ */
+void
+TSRemapDeleteInstance(void *ih)
+{
+  DEBUG_LOG("no op");
+}
+
+/**
+ * Remap entry point.
+ */
+TSRemapStatus
+TSRemapDoRemap(void *ih, TSHttpTxn txnp, TSRemapRequestInfo * /* rri */)
+{
+  range_header_check(txnp);
+  return TSREMAP_NO_REMAP;
+}
+
+/**
+ * Global plugin initialization.
+ */
+void
+TSPluginInit(int argc, const char *argv[])
+{
+  TSPluginRegistrationInfo info;
+  TSCont txnp_cont;
+
+  info.plugin_name = (char *)PLUGIN_NAME;
+  info.vendor_name = (char *)"Comcast";
+  info.support_email = (char *)"John_Rushford@cable.comcast.com";
+
+  if (TSPluginRegister(TS_SDK_VERSION_3_0, &info) != TS_SUCCESS) {
+    ERROR_LOG("Plugin registration failed.\n");
+    ERROR_LOG("Unable to initialize plugin (disabled).");
+    return;
+  }
+
+  if (NULL == (txnp_cont = TSContCreate((TSEventFunc)handle_read_request_header, NULL))) {
+    ERROR_LOG("failed to create the transaction continuation handler.");
+    return;
+  } else {
+    TSHttpHookAdd(TS_HTTP_READ_REQUEST_HDR_HOOK, txnp_cont);
+  }
+}
+
+/**
+ * Transaction event handler.
+ */
+static void
+transaction_handler(TSCont contp, TSEvent event, void *edata)
+{
+  TSHttpTxn txnp = static_cast<TSHttpTxn>(edata);
+  struct txndata *txn_state = (struct txndata *)TSContDataGet(contp);
+
+  switch (event) {
+  case TS_EVENT_HTTP_READ_RESPONSE_HDR:
+    handle_server_read_response(txnp, txn_state);
+    break;
+  case TS_EVENT_HTTP_SEND_REQUEST_HDR:
+    handle_send_origin_request(contp, txnp, txn_state);
+    break;
+  case TS_EVENT_HTTP_SEND_RESPONSE_HDR:
+    handle_client_send_response(txnp, txn_state);
+    break;
+  case TS_EVENT_HTTP_TXN_CLOSE:
+    if (txn_state != NULL && txn_state->range_value != NULL)
+      TSfree(txn_state->range_value);
+    if (txn_state != NULL)
+      TSfree(txn_state);
+    TSContDestroy(contp);
+    break;
+  default:
+    TSAssert(!"Unexpected event");
+    break;
+  }
+  TSHttpTxnReenable(txnp, TS_EVENT_HTTP_CONTINUE);
+}
diff --git a/plugins/experimental/regex_revalidate/regex_revalidate.c b/plugins/experimental/regex_revalidate/regex_revalidate.c
index f25c36f..d261308 100644
--- a/plugins/experimental/regex_revalidate/regex_revalidate.c
+++ b/plugins/experimental/regex_revalidate/regex_revalidate.c
@@ -40,8 +40,35 @@
 #include <pcre.h>
 #endif
 
-#define LOG_PREFIX "regex_revalidate"
-#define CONFIG_TMOUT 60000
+typedef struct invalidate_t {
+  const char *regex_text;
+  pcre *regex;
+  pcre_extra *regex_extra;
+  time_t epoch;
+  time_t expiry;
+  struct invalidate_t *volatile next;
+} invalidate_t;
+
+typedef invalidate_t config_t;
+
+typedef struct {
+  char *config_path;
+  volatile time_t last_load;
+  config_t *config;
+  TSTextLogObject log;
+} config_holder_t;
+
+static int free_handler(TSCont cont, TSEvent event, void *edata);
+static int config_handler(TSCont cont, TSEvent event, void *edata);
+static config_t *get_config(TSCont cont);
+static config_holder_t *new_config_holder();
+static config_holder_t *init_config_holder(config_holder_t *config_holder, const char *path);
+static void free_config_holder_t(config_holder_t *config_holder);
+static void schedule_free_invalidate_t(invalidate_t *iptr);
+
+#define PLUGIN_TAG "regex_revalidate"
+#define DEFAULT_CONFIG_NAME "regex_revalidate.config"
+#define PRUNE_TMOUT 60000
 #define FREE_TMOUT 300000
 #define OVECTOR_SIZE 30
 #define LOG_ROLL_INTERVAL 86400
@@ -59,22 +86,6 @@ ts_free(void *s)
   return TSfree(s);
 }
 
-typedef struct invalidate_t {
-  const char *regex_text;
-  pcre *regex;
-  pcre_extra *regex_extra;
-  time_t epoch;
-  time_t expiry;
-  struct invalidate_t *next;
-} invalidate_t;
-
-typedef struct {
-  invalidate_t *volatile invalidate_list;
-  char *config_file;
-  volatile time_t last_load;
-  TSTextLogObject log;
-} plugin_state_t;
-
 static invalidate_t *
 init_invalidate_t(invalidate_t *i)
 {
@@ -111,65 +122,6 @@ free_invalidate_t_list(invalidate_t *i)
   free_invalidate_t(i);
 }
 
-static plugin_state_t *
-init_plugin_state_t(plugin_state_t *pstate)
-{
-  pstate->invalidate_list = NULL;
-  pstate->config_file = NULL;
-  pstate->last_load = 0;
-  pstate->log = NULL;
-  return pstate;
-}
-
-static void
-free_plugin_state_t(plugin_state_t *pstate)
-{
-  if (pstate->invalidate_list)
-    free_invalidate_t_list(pstate->invalidate_list);
-  if (pstate->config_file)
-    TSfree(pstate->config_file);
-  if (pstate->log)
-    TSTextLogObjectDestroy(pstate->log);
-  TSfree(pstate);
-}
-
-static invalidate_t *
-copy_invalidate_t(invalidate_t *i)
-{
-  invalidate_t *iptr;
-  const char *errptr;
-  int erroffset;
-
-  iptr = (invalidate_t *)TSmalloc(sizeof(invalidate_t));
-  iptr->regex_text = TSstrdup(i->regex_text);
-  iptr->regex = pcre_compile(iptr->regex_text, 0, &errptr, &erroffset, NULL); // There is no pcre_copy :-(
-  iptr->regex_extra = pcre_study(iptr->regex, 0, &errptr);                    // Assuming no errors since this worked before :-/
-  iptr->epoch = i->epoch;
-  iptr->expiry = i->expiry;
-  iptr->next = NULL;
-  return iptr;
-}
-
-static invalidate_t *
-copy_config(invalidate_t *old_list)
-{
-  invalidate_t *new_list = NULL;
-  invalidate_t *iptr_old, *iptr_new;
-
-  if (old_list) {
-    new_list = copy_invalidate_t(old_list);
-    iptr_old = old_list->next;
-    iptr_new = new_list;
-    while (iptr_old) {
-      iptr_new->next = copy_invalidate_t(iptr_old);
-      iptr_new = iptr_new->next;
-      iptr_old = iptr_old->next;
-    }
-  }
-
-  return new_list;
-}
-
 static bool
 prune_config(invalidate_t **i)
 {
@@ -184,14 +136,20 @@ prune_config(invalidate_t **i)
     ilast = NULL;
     while (iptr) {
       if (difftime(iptr->expiry, now) < 0) {
-        TSDebug(LOG_PREFIX, "Removing %s expiry: %d now: %d", iptr->regex_text, (int)iptr->expiry, (int)now);
+        TSDebug(PLUGIN_TAG, "Removing %s expiry: %d now: %d", iptr->regex_text, (int)iptr->expiry, (int)now);
+        TSError(PLUGIN_TAG " - Removing %s expiry: %d now: %d", iptr->regex_text, (int)iptr->expiry, (int)now);
         if (ilast) {
+          // jlaue: TODO is this right?
+          //                    iptr = __sync_val_compare_and_swap(&(ilast->next), ilast->next, iptr->next);
           ilast->next = iptr->next;
-          free_invalidate_t(iptr);
+          //                    free_invalidate_t(iptr);
+          schedule_free_invalidate_t(iptr);
           iptr = ilast->next;
+
         } else {
           *i = iptr->next;
-          free_invalidate_t(iptr);
+          //                    free_invalidate_t(iptr);
+          schedule_free_invalidate_t(iptr);
           iptr = *i;
         }
         pruned = true;
@@ -204,161 +162,44 @@ prune_config(invalidate_t **i)
   return pruned;
 }
 
-static bool
-load_config(plugin_state_t *pstate, invalidate_t **ilist)
-{
-  FILE *fs;
-  struct stat s;
-  size_t path_len;
-  char *path;
-  char line[LINE_MAX];
-  time_t now;
-  pcre *config_re;
-  const char *errptr;
-  int erroffset, ovector[OVECTOR_SIZE], rc;
-  int ln = 0;
-  invalidate_t *iptr, *i;
-
-  if (pstate->config_file[0] != '/') {
-    path_len = strlen(TSConfigDirGet()) + strlen(pstate->config_file) + 2;
-    path = alloca(path_len);
-    snprintf(path, path_len, "%s/%s", TSConfigDirGet(), pstate->config_file);
-  } else
-    path = pstate->config_file;
-  if (stat(path, &s) < 0) {
-    TSDebug(LOG_PREFIX, "Could not stat %s", path);
-    return false;
-  }
-  if (s.st_mtime > pstate->last_load) {
-    now = time(NULL);
-    if (!(fs = fopen(path, "r"))) {
-      TSDebug(LOG_PREFIX, "Could not open %s for reading", path);
-      return false;
-    }
-    config_re = pcre_compile("^([^#].+?)\\s+(\\d+)\\s*$", 0, &errptr, &erroffset, NULL);
-    while (fgets(line, LINE_MAX, fs) != NULL) {
-      ln++;
-      TSDebug(LOG_PREFIX, "Processing: %d %s", ln, line);
-      rc = pcre_exec(config_re, NULL, line, strlen(line), 0, 0, ovector, OVECTOR_SIZE);
-      if (rc == 3) {
-        i = (invalidate_t *)TSmalloc(sizeof(invalidate_t));
-        init_invalidate_t(i);
-        pcre_get_substring(line, ovector, rc, 1, &i->regex_text);
-        i->epoch = now;
-        i->expiry = atoi(line + ovector[4]);
-        i->regex = pcre_compile(i->regex_text, 0, &errptr, &erroffset, NULL);
-        if (i->expiry <= i->epoch) {
-          TSDebug(LOG_PREFIX, "Rule is already expired!");
-          free_invalidate_t(i);
-        } else if (i->regex == NULL) {
-          TSDebug(LOG_PREFIX, "%s did not compile", i->regex_text);
-          free_invalidate_t(i);
-        } else {
-          i->regex_extra = pcre_study(i->regex, 0, &errptr);
-          if (!*ilist) {
-            *ilist = i;
-            TSDebug(LOG_PREFIX, "Created new list and Loaded %s %d %d", i->regex_text, (int)i->epoch, (int)i->expiry);
-          } else {
-            iptr = *ilist;
-            while (1) {
-              if (strcmp(i->regex_text, iptr->regex_text) == 0) {
-                if (iptr->expiry != i->expiry) {
-                  TSDebug(LOG_PREFIX, "Updating duplicate %s", i->regex_text);
-                  iptr->epoch = i->epoch;
-                  iptr->expiry = i->expiry;
-                }
-                free_invalidate_t(i);
-                i = NULL;
-                break;
-              } else if (!iptr->next)
-                break;
-              else
-                iptr = iptr->next;
-            }
-            if (i) {
-              iptr->next = i;
-              TSDebug(LOG_PREFIX, "Loaded %s %d %d", i->regex_text, (int)i->epoch, (int)i->expiry);
-            }
-          }
-        }
-      } else
-        TSDebug(LOG_PREFIX, "Skipping line %d", ln);
-    }
-    pcre_free(config_re);
-    fclose(fs);
-    pstate->last_load = s.st_mtime;
-    return true;
-  } else
-    TSDebug(LOG_PREFIX, "File mod time is not newer: %d >= %d", (int)pstate->last_load, (int)s.st_mtime);
-  return false;
-}
 
 static void
-list_config(plugin_state_t *pstate, invalidate_t *i)
+list_config(config_holder_t *config_holder, invalidate_t *i)
 {
   invalidate_t *iptr;
 
-  TSDebug(LOG_PREFIX, "Current config:");
-  if (pstate->log)
-    TSTextLogObjectWrite(pstate->log, "Current config:");
+  TSDebug(PLUGIN_TAG, "Current config:");
+  if (config_holder->log)
+    TSTextLogObjectWrite(config_holder->log, "Current config:");
   if (i) {
     iptr = i;
     while (iptr) {
-      TSDebug(LOG_PREFIX, "%s epoch: %d expiry: %d", iptr->regex_text, (int)iptr->epoch, (int)iptr->expiry);
-      if (pstate->log)
-        TSTextLogObjectWrite(pstate->log, "%s epoch: %d expiry: %d", iptr->regex_text, (int)iptr->epoch, (int)iptr->expiry);
+      TSDebug(PLUGIN_TAG, "%s epoch: %d expiry: %d", iptr->regex_text, (int)iptr->epoch, (int)iptr->expiry);
+      if (config_holder->log)
+        TSTextLogObjectWrite(config_holder->log, "%s epoch: %d expiry: %d", iptr->regex_text, (int)iptr->epoch, (int)iptr->expiry);
       iptr = iptr->next;
     }
   } else {
-    TSDebug(LOG_PREFIX, "EMPTY");
-    if (pstate->log)
-      TSTextLogObjectWrite(pstate->log, "EMPTY");
+    TSDebug(PLUGIN_TAG, "EMPTY");
+    if (config_holder->log)
+      TSTextLogObjectWrite(config_holder->log, "EMPTY");
   }
 }
 
 static int
-free_handler(TSCont cont, TSEvent event ATS_UNUSED, void *edata ATS_UNUSED)
+config_pruner(TSCont cont, TSEvent event ATS_UNUSED, void *edata ATS_UNUSED)
 {
-  invalidate_t *iptr;
+  invalidate_t *i;
 
-  TSDebug(LOG_PREFIX, "Freeing old config");
-  iptr = (invalidate_t *)TSContDataGet(cont);
-  free_invalidate_t_list(iptr);
-  TSContDestroy(cont);
-  return 0;
-}
+  TSDebug(PLUGIN_TAG, "config_pruner");
+  config_holder_t *configh = (config_holder_t *)TSContDataGet(cont);
+  i = configh->config;
 
-static int
-config_handler(TSCont cont, TSEvent event ATS_UNUSED, void *edata ATS_UNUSED)
-{
-  plugin_state_t *pstate;
-  invalidate_t *i, *iptr;
-  TSCont free_cont;
-  bool updated;
+  prune_config(&i);
 
-  TSDebug(LOG_PREFIX, "In config Handler");
-  pstate = (plugin_state_t *)TSContDataGet(cont);
-  i = copy_config(pstate->invalidate_list);
+  configh->config = i;
 
-  updated = prune_config(&i);
-  updated = load_config(pstate, &i) || updated;
-
-  if (updated) {
-    list_config(pstate, i);
-    iptr = __sync_val_compare_and_swap(&(pstate->invalidate_list), pstate->invalidate_list, i);
-
-    if (iptr) {
-      free_cont = TSContCreate(free_handler, NULL);
-      TSContDataSet(free_cont, (void *)iptr);
-      TSContSchedule(free_cont, FREE_TMOUT, TS_THREAD_POOL_TASK);
-    }
-  } else {
-    TSDebug(LOG_PREFIX, "No Changes");
-    if (i)
-      free_invalidate_t_list(i);
-  }
-
-  TSContSchedule(cont, CONFIG_TMOUT, TS_THREAD_POOL_TASK);
+  TSContSchedule(cont, PRUNE_TMOUT, TS_THREAD_POOL_TASK);
   return 0;
 }
 
@@ -387,7 +228,6 @@ main_handler(TSCont cont, TSEvent event, void *edata)
   TSHttpTxn txn = (TSHttpTxn)edata;
   int status;
   invalidate_t *iptr;
-  plugin_state_t *pstate;
 
   time_t date = 0, now = 0;
   char *url = NULL;
@@ -397,8 +237,7 @@ main_handler(TSCont cont, TSEvent event, void *edata)
   case TS_EVENT_HTTP_CACHE_LOOKUP_COMPLETE:
     if (TSHttpTxnCacheLookupStatusGet(txn, &status) == TS_SUCCESS) {
       if (status == TS_CACHE_LOOKUP_HIT_FRESH) {
-        pstate = (plugin_state_t *)TSContDataGet(cont);
-        iptr = pstate->invalidate_list;
+        iptr = get_config(cont);
         while (iptr) {
           if (!date) {
             date = get_date_from_cached_hdr(txn);
@@ -410,7 +249,7 @@ main_handler(TSCont cont, TSEvent event, void *edata)
             if (pcre_exec(iptr->regex, iptr->regex_extra, url, url_len, 0, 0, NULL, 0) >= 0) {
               TSHttpTxnCacheLookupStatusSet(txn, TS_CACHE_LOOKUP_HIT_STALE);
               iptr = NULL;
-              TSDebug(LOG_PREFIX, "Forced revalidate - %.*s", url_len, url);
+              TSDebug(PLUGIN_TAG, "Forced revalidate - %.*s", url_len, url);
             }
           }
           if (iptr)
@@ -457,13 +296,12 @@ TSPluginInit(int argc, const char *argv[])
 {
   TSPluginRegistrationInfo info;
   TSCont main_cont, config_cont;
-  plugin_state_t *pstate;
-  invalidate_t *iptr = NULL;
+  config_holder_t *config_holder;
+  char *path = NULL;
 
-  TSDebug(LOG_PREFIX, "Starting plugin init.");
+  TSDebug(PLUGIN_TAG, "Starting plugin init.");
 
-  pstate = (plugin_state_t *)TSmalloc(sizeof(plugin_state_t));
-  init_plugin_state_t(pstate);
+  config_holder = new_config_holder();
 
   int c;
   optind = 1;
@@ -473,46 +311,48 @@ TSPluginInit(int argc, const char *argv[])
   while ((c = getopt_long(argc, (char *const *)argv, "c:l:", longopts, NULL)) != -1) {
     switch (c) {
     case 'c':
-      pstate->config_file = TSstrdup(optarg);
+      path = TSstrdup(optarg);
       break;
     case 'l':
-      TSTextLogObjectCreate(optarg, TS_LOG_MODE_ADD_TIMESTAMP, &pstate->log);
-      TSTextLogObjectRollingEnabledSet(pstate->log, 1);
-      TSTextLogObjectRollingIntervalSecSet(pstate->log, LOG_ROLL_INTERVAL);
-      TSTextLogObjectRollingOffsetHrSet(pstate->log, LOG_ROLL_OFFSET);
+      TSTextLogObjectCreate(optarg, TS_LOG_MODE_ADD_TIMESTAMP, &config_holder->log);
+      TSTextLogObjectRollingEnabledSet(config_holder->log, 1);
+      TSTextLogObjectRollingIntervalSecSet(config_holder->log, LOG_ROLL_INTERVAL);
+      TSTextLogObjectRollingOffsetHrSet(config_holder->log, LOG_ROLL_OFFSET);
       break;
     default:
       break;
     }
   }
+  config_holder = init_config_holder(config_holder, path);
 
-  if (!pstate->config_file) {
+  if (!config_holder->config_path) {
     TSError("Plugin requires a --config option along with a config file name.");
-    free_plugin_state_t(pstate);
+    free_config_holder_t(config_holder);
     return;
   }
 
-  if (!load_config(pstate, &iptr))
-    TSDebug(LOG_PREFIX, "Problem loading config from file %s", pstate->config_file);
+  //    if (!load_config(free_config_holder_t, &iptr))
+  if (config_holder->config)
+    TSDebug(PLUGIN_TAG, "Problem loading config from file %s", config_holder->config_path);
   else {
-    pstate->invalidate_list = iptr;
-    list_config(pstate, iptr);
+    //        config_holder->config = iptr;
+    list_config(config_holder, config_holder->config);
   }
 
-  info.plugin_name = LOG_PREFIX;
+  info.plugin_name = PLUGIN_TAG;
   info.vendor_name = "Apache Software Foundation";
   info.support_email = "dev@trafficserver.apache.org";
 
   if (TSPluginRegister(TS_SDK_VERSION_3_0, &info) != TS_SUCCESS) {
     TSError("Plugin registration failed.");
-    free_plugin_state_t(pstate);
+    free_config_holder_t(config_holder);
     return;
   } else
-    TSDebug(LOG_PREFIX, "Plugin registration succeeded.");
+    TSDebug(PLUGIN_TAG, "Plugin registration succeeded.");
 
   if (!check_ts_version()) {
     TSError("Plugin requires Traffic Server %d.%d.%d", TS_VERSION_MAJOR, TS_VERSION_MINOR, TS_VERSION_MICRO);
-    free_plugin_state_t(pstate);
+    free_config_holder_t(config_holder);
     return;
   }
 
@@ -520,12 +360,235 @@ TSPluginInit(int argc, const char *argv[])
   pcre_free = &ts_free;
 
   main_cont = TSContCreate(main_handler, NULL);
-  TSContDataSet(main_cont, (void *)pstate);
+  TSContDataSet(main_cont, (void *)config_holder);
   TSHttpHookAdd(TS_HTTP_CACHE_LOOKUP_COMPLETE_HOOK, main_cont);
 
+  config_cont = TSContCreate(config_pruner, TSMutexCreate());
+  TSContDataSet(config_cont, (void *)config_holder);
+  TSContSchedule(config_cont, PRUNE_TMOUT, TS_THREAD_POOL_TASK);
+
   config_cont = TSContCreate(config_handler, TSMutexCreate());
-  TSContDataSet(config_cont, (void *)pstate);
-  TSContSchedule(config_cont, CONFIG_TMOUT, TS_THREAD_POOL_TASK);
+  TSContDataSet(config_cont, (void *)config_holder);
+  TSMgmtUpdateRegister(config_cont, PLUGIN_TAG);
+
+  TSDebug(PLUGIN_TAG, "Plugin Init Complete.");
+}
+
+static config_t *
+new_config(TSFile fs)
+{
+  char line[LINE_MAX];
+  time_t now;
+  pcre *config_re;
+  const char *errptr;
+  int erroffset, ovector[OVECTOR_SIZE], rc;
+  int ln = 0;
+  invalidate_t *iptr, *i, *config = 0;
+
+  now = time(NULL);
+
+  config_re = pcre_compile("^([^#].+?)\\s+(\\d+)\\s*$", 0, &errptr, &erroffset, NULL);
+  while (TSfgets(fs, line, LINE_MAX - 1) != NULL) {
+    ln++;
+    TSDebug(PLUGIN_TAG, "Processing: %d %s", ln, line);
+    rc = pcre_exec(config_re, NULL, line, strlen(line), 0, 0, ovector, OVECTOR_SIZE);
+    if (rc == 3) {
+      i = (invalidate_t *)TSmalloc(sizeof(invalidate_t));
+      init_invalidate_t(i);
+      pcre_get_substring(line, ovector, rc, 1, &i->regex_text);
+      i->epoch = now;
+      i->expiry = atoi(line + ovector[4]);
+      i->regex = pcre_compile(i->regex_text, 0, &errptr, &erroffset, NULL);
+      if (i->expiry <= i->epoch) {
+        TSDebug(PLUGIN_TAG, "NOT Loaded, already expired! %s %d %d", i->regex_text, (int)i->epoch, (int)i->expiry);
+        TSError(PLUGIN_TAG " - NOT Loaded, already expired: %s %d %d", i->regex_text, (int)i->epoch, (int)i->expiry);
+        free_invalidate_t(i);
+      } else if (i->regex == NULL) {
+        TSDebug(PLUGIN_TAG, "%s did not compile", i->regex_text);
+        free_invalidate_t(i);
+      } else {
+        i->regex_extra = pcre_study(i->regex, 0, &errptr);
+        if (!config) {
+          config = i;
+          TSDebug(PLUGIN_TAG, "Created new list and Loaded %s %d %d", i->regex_text, (int)i->epoch, (int)i->expiry);
+          TSError(PLUGIN_TAG " - New Revalidate: %s %d %d", i->regex_text, (int)i->epoch, (int)i->expiry);
+        } else {
+          iptr = config;
+          while (1) {
+            if (strcmp(i->regex_text, iptr->regex_text) == 0) {
+              if (iptr->expiry != i->expiry) {
+                TSDebug(PLUGIN_TAG, "Updating duplicate %s", i->regex_text);
+                iptr->epoch = i->epoch;
+                iptr->expiry = i->expiry;
+              }
+              free_invalidate_t(i);
+              i = NULL;
+              break;
+            } else if (!iptr->next)
+              break;
+            else
+              iptr = iptr->next;
+          }
+          if (i) {
+            iptr->next = i;
+            TSDebug(PLUGIN_TAG, "Loaded %s %d %d", i->regex_text, (int)i->epoch, (int)i->expiry);
+          }
+        }
+      }
+    } else
+      TSDebug(PLUGIN_TAG, "Skipping line %d", ln);
+  }
+  pcre_free(config_re);
+
+  return config;
+}
+
+static void
+delete_config(config_t *config)
+{
+  TSDebug(PLUGIN_TAG, "Freeing config");
+  free_invalidate_t_list(config);
+}
+
+static int
+free_invalidate_handler(TSCont cont, TSEvent event ATS_UNUSED, void *edata ATS_UNUSED)
+{
+  invalidate_t *i = (invalidate_t *)TSContDataGet(cont);
+  free_invalidate_t(i);
+  TSContDestroy(cont);
+  return 0;
+}
+
+static void
+schedule_free_invalidate_t(invalidate_t *iptr)
+{
+  TSCont free_cont;
+  free_cont = TSContCreate(free_invalidate_handler, NULL);
+  TSContDataSet(free_cont, (void *)iptr);
+  TSContSchedule(free_cont, FREE_TMOUT, TS_THREAD_POOL_TASK);
+  return;
+}
 
-  TSDebug(LOG_PREFIX, "Plugin Init Complete.");
+static config_t *
+get_config(TSCont cont)
+{
+  config_holder_t *configh = (config_holder_t *)TSContDataGet(cont);
+  if (!configh) {
+    return 0;
+  }
+  return configh->config;
+}
+
+static void
+load_config_file(config_holder_t *config_holder)
+{
+  TSFile fh;
+  struct stat s;
+
+  config_t *newconfig, *oldconfig;
+  TSCont free_cont;
+
+  // check date
+  if (stat(config_holder->config_path, &s) < 0) {
+    TSDebug(PLUGIN_TAG, "Could not stat %s", config_holder->config_path);
+    if (config_holder->config) {
+      return;
+    }
+  } else {
+    TSDebug(PLUGIN_TAG, "s.st_mtime=%lu, last_load=%lu", s.st_mtime, config_holder->last_load);
+    if (s.st_mtime < config_holder->last_load) {
+      return;
+    }
+  }
+
+  TSDebug(PLUGIN_TAG, "Opening config file: %s", config_holder->config_path);
+  fh = TSfopen(config_holder->config_path, "r");
+  TSError(PLUGIN_TAG " - Reading config: %s", config_holder->config_path);
+
+  if (!fh) {
+    TSError("[%s] Unable to open config: %s.\n", PLUGIN_TAG, config_holder->config_path);
+    return;
+  }
+
+  newconfig = 0;
+  newconfig = new_config(fh);
+  if (newconfig) {
+    config_holder->last_load = time(NULL);
+    config_t **confp = &(config_holder->config);
+    oldconfig = __sync_lock_test_and_set(confp, newconfig);
+    if (oldconfig) {
+      TSDebug(PLUGIN_TAG, "scheduling free: %p (%p)", oldconfig, newconfig);
+      free_cont = TSContCreate(free_handler, NULL);
+      TSContDataSet(free_cont, (void *)oldconfig);
+      TSContSchedule(free_cont, FREE_TMOUT, TS_THREAD_POOL_TASK);
+    }
+  }
+  if (fh)
+    TSfclose(fh);
+  return;
+}
+
+static config_holder_t *
+new_config_holder(void)
+{
+  config_holder_t *config_holder = TSmalloc(sizeof(config_holder_t));
+  return config_holder;
+}
+
+static config_holder_t *
+init_config_holder(config_holder_t *config_holder, const char *path)
+{
+  int path_len = 0;
+  config_holder->config_path = 0;
+  config_holder->config = 0;
+  config_holder->last_load = 0;
+  config_holder->log = 0;
+
+  if (!path)
+    path = DEFAULT_CONFIG_NAME;
+  if (path[0] != '/') {
+    path_len = strlen(TSConfigDirGet()) + strlen(path) + 2;
+    config_holder->config_path = ts_malloc(path_len);
+    snprintf(config_holder->config_path, path_len, "%s/%s", TSConfigDirGet(), path);
+    TSDebug(PLUGIN_TAG, "path: '%s' len=%d", config_holder->config_path, path_len);
+  } else
+    config_holder->config_path = TSstrdup(path);
+
+  load_config_file(config_holder);
+  return config_holder;
+}
+
+static void
+free_config_holder_t(config_holder_t *config_holder)
+{
+  if (config_holder->config)
+    free_invalidate_t_list(config_holder->config);
+  if (config_holder->config_path)
+    TSfree(config_holder->config_path);
+  if (config_holder->log)
+    TSTextLogObjectDestroy(config_holder->log);
+  TSfree(config_holder);
+}
+
+static int
+free_handler(TSCont cont, TSEvent event ATS_UNUSED, void *edata ATS_UNUSED)
+{
+  config_t *config;
+
+  TSDebug(PLUGIN_TAG, "Freeing old config");
+  config = (config_t *)TSContDataGet(cont);
+  delete_config(config);
+  TSContDestroy(cont);
+  return 0;
+}
+
+static int
+config_handler(TSCont cont, TSEvent event ATS_UNUSED, void *edata ATS_UNUSED)
+{
+  config_holder_t *config_holder;
+
+  TSDebug(PLUGIN_TAG, "In config Handler");
+  config_holder = (config_holder_t *)TSContDataGet(cont);
+  load_config_file(config_holder);
+  return 0;
 }
diff --git a/plugins/experimental/remap_stats/remap_stats.c b/plugins/experimental/remap_stats/remap_stats.c
index e231ec2..8d3f987 100644
--- a/plugins/experimental/remap_stats/remap_stats.c
+++ b/plugins/experimental/remap_stats/remap_stats.c
@@ -23,12 +23,14 @@
 #include "ink_defs.h"
 
 #include "ts/ts.h"
+
 #include <stdint.h>
 #include <stdbool.h>
 #include <string.h>
 #include <stdio.h>
 #include <getopt.h>
 #include <search.h>
+#include <time.h>
 
 #define PLUGIN_NAME "remap_stats"
 #define DEBUG_TAG PLUGIN_NAME
@@ -36,18 +38,52 @@
 #define MAX_STAT_LENGTH (1 << 8)
 
 typedef struct {
+  time_t last_update;
   bool post_remap_host;
-  int txn_slot;
+  int txn_slot, schedule_delay;
   TSStatPersistence persist_type;
   TSMutex stat_creation_mutex;
 } config_t;
 
+typedef struct {
+  int stat_id;
+  time_t last_update;
+} value_t;
+
+static int
+lookup_stat(char *name, TSStatPersistence persist_type, TSMutex create_mutex)
+{
+  int stat_id = -1;
+
+  TSMutexLock(create_mutex);
+  if (TS_ERROR == TSStatFindName((const char *)name, &stat_id)) {
+    stat_id = TSStatCreate((const char *)name, TS_RECORDDATATYPE_INT, persist_type, TS_STAT_SYNC_SUM);
+    if (stat_id == TS_ERROR)
+      TSDebug(DEBUG_TAG, "Error creating stat_name: %s", name);
+    else
+      TSError("[%s:%d] Created stat_name: %s stat_id: %d", __FILE__, __LINE__, name, stat_id);
+  }
+  TSMutexUnlock(create_mutex);
+
+  return stat_id;
+}
+
+static inline time_t
+now()
+{
+  struct timespec ts;
+
+  clock_gettime(CLOCK_MONOTONIC_COARSE, &ts);
+
+  return ts.tv_sec;
+}
 
 static void
-stat_add(char *name, TSMgmtInt amount, TSStatPersistence persist_type, TSMutex create_mutex)
+stat_add(char *name, TSMgmtInt amount, TSStatPersistence persist_type, TSMutex create_mutex, time_t config_last_update)
 {
   int stat_id = -1;
   ENTRY search, *result = NULL;
+  value_t *val;
   static __thread struct hsearch_data stat_cache;
   static __thread bool hash_init = false;
 
@@ -65,32 +101,43 @@ stat_add(char *name, TSMgmtInt amount, TSStatPersistence persist_type, TSMutex c
     // This is an unlikely path because we most likely have the stat cached
     // so this mutex won't be much overhead and it fixes a race condition
     // in the RecCore. Hopefully this can be removed in the future.
-    TSMutexLock(create_mutex);
-    if (TS_ERROR == TSStatFindName((const char *)name, &stat_id)) {
-      stat_id = TSStatCreate((const char *)name, TS_RECORDDATATYPE_INT, persist_type, TS_STAT_SYNC_SUM);
-      if (stat_id == TS_ERROR)
-        TSDebug(DEBUG_TAG, "Error creating stat_name: %s", name);
-      else
-        TSDebug(DEBUG_TAG, "Created stat_name: %s stat_id: %d", name, stat_id);
-    }
-    TSMutexUnlock(create_mutex);
+    stat_id = lookup_stat(name, persist_type, create_mutex);
 
     if (stat_id >= 0) {
       search.key = TSstrdup(name);
-      search.data = (void *)((intptr_t)stat_id);
+      val = (value_t *)TSmalloc(sizeof(value_t));
+      val->stat_id = stat_id;
+      val->last_update = now();
+      search.data = (void *)val;
       hsearch_r(search, ENTER, &result, &stat_cache);
       TSDebug(DEBUG_TAG, "Cached stat_name: %s stat_id: %d", name, stat_id);
     }
-  } else
-    stat_id = (int)((intptr_t)result->data);
+  } else {
+    val = (value_t *)result->data;
+
+    // Stat expiry should be rare, so lets assume this is unlikely
+    if (unlikely(val->last_update < config_last_update)) {
+      stat_id = lookup_stat(name, persist_type, create_mutex);
+      TSDebug(DEBUG_TAG, "stat_add(): running stat expiry check for stat_id:%d named: %s", stat_id, name);
+      // Stat changes should not happen so lets assume this is unlikely
+      if (unlikely(val->stat_id != stat_id)) {
+        TSError("[%s:%d] Found difference stat_name: %s old stat_id: %d new stat_id: %d", __FILE__, __LINE__, name, val->stat_id,
+                stat_id);
+        val->stat_id = stat_id;
+        val->last_update = now();
+      }
+    } else {
+      stat_id = val->stat_id;
+    }
+  }
 
-  if (likely(stat_id >= 0))
+  if (likely(stat_id >= 0)) {
+    TSDebug(DEBUG_TAG, "stat_add(): preparing to increment, name=%s, stat_id=%d, amount=%" PRId64, name, stat_id, amount);
     TSStatIntIncrement(stat_id, amount);
-  else
+  } else
     TSDebug(DEBUG_TAG, "stat error! stat_name: %s stat_id: %d", name, stat_id);
 }
 
-
 static char *
 get_effective_host(TSHttpTxn txn)
 {
@@ -113,7 +160,6 @@ get_effective_host(TSHttpTxn txn)
   return tmp;
 }
 
-
 static int
 handle_read_req_hdr(TSCont cont, TSEvent event ATS_UNUSED, void *edata)
 {
@@ -130,7 +176,6 @@ handle_read_req_hdr(TSCont cont, TSEvent event ATS_UNUSED, void *edata)
   return 0;
 }
 
-
 static int
 handle_post_remap(TSCont cont, TSEvent event ATS_UNUSED, void *edata)
 {
@@ -148,14 +193,12 @@ handle_post_remap(TSCont cont, TSEvent event ATS_UNUSED, void *edata)
   }
 
   TSHttpTxnReenable(txn, TS_EVENT_HTTP_CONTINUE);
-  TSDebug(DEBUG_TAG, "Post Remap Handler Finished");
+  TSDebug(DEBUG_TAG, "Post Remap Handler Finished.");
   return 0;
 }
 
-
 #define CREATE_STAT_NAME(s, h, b) snprintf(s, MAX_STAT_LENGTH, "plugin.%s.%s.%s", PLUGIN_NAME, h, b)
 
-
 static int
 handle_txn_close(TSCont cont, TSEvent event ATS_UNUSED, void *edata)
 {
@@ -175,6 +218,8 @@ handle_txn_close(TSCont cont, TSEvent event ATS_UNUSED, void *edata)
 
   hostname = (char *)((uintptr_t)txnd & (~((uintptr_t)0x01))); // Get hostname
 
+  TSDebug(DEBUG_TAG, "handle_txn_close(): hostname: %s", hostname);
+
   if (txnd) {
     if ((uintptr_t)txnd & 0x01) // remap succeeded?
     {
@@ -190,13 +235,13 @@ handle_txn_close(TSCont cont, TSEvent event ATS_UNUSED, void *edata)
       in_bytes += TSHttpTxnClientReqBodyBytesGet(txn);
 
       CREATE_STAT_NAME(stat_name, remap, "in_bytes");
-      stat_add(stat_name, (TSMgmtInt)in_bytes, config->persist_type, config->stat_creation_mutex);
+      stat_add(stat_name, (TSMgmtInt)in_bytes, config->persist_type, config->stat_creation_mutex, config->last_update);
 
       out_bytes = TSHttpTxnClientRespHdrBytesGet(txn);
       out_bytes += TSHttpTxnClientRespBodyBytesGet(txn);
 
       CREATE_STAT_NAME(stat_name, remap, "out_bytes");
-      stat_add(stat_name, (TSMgmtInt)out_bytes, config->persist_type, config->stat_creation_mutex);
+      stat_add(stat_name, (TSMgmtInt)out_bytes, config->persist_type, config->stat_creation_mutex, config->last_update);
 
       if (TSHttpTxnClientRespGet(txn, &buf, &hdr_loc) == TS_SUCCESS) {
         status_code = (int)TSHttpHdrStatusGet(buf, hdr_loc);
@@ -215,10 +260,10 @@ handle_txn_close(TSCont cont, TSEvent event ATS_UNUSED, void *edata)
         else
           CREATE_STAT_NAME(stat_name, remap, "status_other");
 
-        stat_add(stat_name, 1, config->persist_type, config->stat_creation_mutex);
+        stat_add(stat_name, 1, config->persist_type, config->stat_creation_mutex, config->last_update);
       } else {
         CREATE_STAT_NAME(stat_name, remap, "status_unknown");
-        stat_add(stat_name, 1, config->persist_type, config->stat_creation_mutex);
+        stat_add(stat_name, 1, config->persist_type, config->stat_creation_mutex, config->last_update);
       }
 
       if (remap != unknown)
@@ -232,11 +277,43 @@ handle_txn_close(TSCont cont, TSEvent event ATS_UNUSED, void *edata)
   return 0;
 }
 
+static int
+do_time_update(TSCont cont, TSEvent event ATS_UNUSED, void *edata ATS_UNUSED)
+{
+  config_t *config = (config_t *)TSContDataGet(cont);
+  TSDebug(DEBUG_TAG, "do_time_update() called, updating config->last_update.");
+
+
+  while (!__sync_bool_compare_and_swap(&(config->last_update), config->last_update, now()))
+    ;
+
+  TSContDestroy(cont);
+  return 0;
+}
+
+static int
+handle_config_update(TSCont cont, TSEvent event ATS_UNUSED, void *edata ATS_UNUSED)
+{
+  config_t *config = (config_t *)TSContDataGet(cont);
+
+  TSDebug(DEBUG_TAG, "handle_config_update() called due to management update.");
+
+  if (config->schedule_delay > 0) {
+    TSCont do_update_cont = TSContCreate(do_time_update, NULL);
+    TSContDataSet(do_update_cont, (void *)config);
+    TSContSchedule(do_update_cont, config->schedule_delay * 1000, TS_THREAD_POOL_TASK);
+  } else {
+    while (!__sync_bool_compare_and_swap(&(config->last_update), config->last_update, now()))
+      ;
+  }
+  return 0;
+}
+
 void
 TSPluginInit(int argc, const char *argv[])
 {
   TSPluginRegistrationInfo info;
-  TSCont pre_remap_cont, post_remap_cont, global_cont;
+  TSCont pre_remap_cont, post_remap_cont, global_cont, update_cont;
   config_t *config;
 
   info.plugin_name = PLUGIN_NAME;
@@ -253,14 +330,18 @@ TSPluginInit(int argc, const char *argv[])
   config->post_remap_host = false;
   config->persist_type = TS_STAT_NON_PERSISTENT;
   config->stat_creation_mutex = TSMutexCreate();
+  config->schedule_delay = 0;
+  config->last_update = 0;
 
   if (argc > 1) {
     int c;
     optind = 1;
-    static const struct option longopts[] = {
-      {"post-remap-host", no_argument, NULL, 'P'}, {"persistent", no_argument, NULL, 'p'}, {NULL, 0, NULL, 0}};
+    static const struct option longopts[] = {{"post-remap-host", no_argument, NULL, 'P'},
+                                             {"persistent", no_argument, NULL, 'p'},
+                                             {"delay", required_argument, NULL, 'd'},
+                                             {NULL, 0, NULL, 0}};
 
-    while ((c = getopt_long(argc, (char *const *)argv, "Pp", longopts, NULL)) != -1) {
+    while ((c = getopt_long(argc, (char *const *)argv, "Ppd:", longopts, NULL)) != -1) {
       switch (c) {
       case 'P':
         config->post_remap_host = true;
@@ -270,6 +351,10 @@ TSPluginInit(int argc, const char *argv[])
         config->persist_type = TS_STAT_PERSISTENT;
         TSDebug(DEBUG_TAG, "Using persistent stats");
         break;
+      case 'd':
+        config->schedule_delay = atoi(optarg);
+        TSDebug(DEBUG_TAG, "Setting scheduling delay to %d", config->schedule_delay);
+        break;
       default:
         break;
       }
@@ -292,5 +377,9 @@ TSPluginInit(int argc, const char *argv[])
   TSContDataSet(global_cont, (void *)config);
   TSHttpHookAdd(TS_HTTP_TXN_CLOSE_HOOK, global_cont);
 
+  update_cont = TSContCreate(handle_config_update, NULL);
+  TSContDataSet(update_cont, (void *)config);
+  TSMgmtUpdateRegister(update_cont, PLUGIN_NAME);
+
   TSDebug(DEBUG_TAG, "Init complete");
 }
diff --git a/plugins/experimental/stale_while_revalidate/stale_while_revalidate.c b/plugins/experimental/stale_while_revalidate/stale_while_revalidate.c
index c3cd9bc..dd45572 100644
--- a/plugins/experimental/stale_while_revalidate/stale_while_revalidate.c
+++ b/plugins/experimental/stale_while_revalidate/stale_while_revalidate.c
@@ -268,6 +268,7 @@ consume_resource(TSCont cont, TSEvent event ATS_UNUSED, void *edata ATS_UNUSED)
   case TS_EVENT_VCONN_WRITE_READY:
     // We shouldn't get here because we specify the exact size of the buffer.
     TSDebug(PLUGIN_NAME, "Write Ready");
+    break;
   case TS_EVENT_VCONN_WRITE_COMPLETE:
     TSDebug(PLUGIN_NAME, "Write Complete");
     // TSDebug(PLUGIN_NAME, "TSVConnShutdown()");
diff --git a/plugins/experimental/ts_lua/ts_lua_http_config.c b/plugins/experimental/ts_lua/ts_lua_http_config.c
index f840625..be81bd6 100644
--- a/plugins/experimental/ts_lua/ts_lua_http_config.c
+++ b/plugins/experimental/ts_lua/ts_lua_http_config.c
@@ -81,6 +81,13 @@ typedef enum {
   TS_LUA_CONFIG_HTTP_CACHE_FUZZ_PROBABILITY = TS_CONFIG_HTTP_CACHE_FUZZ_PROBABILITY,
   TS_LUA_CONFIG_NET_SOCK_PACKET_MARK_OUT = TS_CONFIG_NET_SOCK_PACKET_MARK_OUT,
   TS_LUA_CONFIG_NET_SOCK_PACKET_TOS_OUT = TS_CONFIG_NET_SOCK_PACKET_TOS_OUT,
+  TS_LUA_CONFIG_HTTP_PER_PARENT_CONNECT_ATTEMPTS = TS_CONFIG_HTTP_PER_PARENT_CONNECT_ATTEMPTS,
+  TS_LUA_CONFIG_HTTP_PARENT_TOTAL_CONNECT_ATTEMPTS = TS_CONFIG_HTTP_PARENT_TOTAL_CONNECT_ATTEMPTS,
+  TS_LUA_CONFIG_HTTP_SIMPLE_RETRY_ENABLED = TS_CONFIG_HTTP_SIMPLE_RETRY_ENABLED,
+  TS_LUA_CONFIG_HTTP_SIMPLE_RETRY_RESPONSE_CODES = TS_CONFIG_HTTP_SIMPLE_RETRY_RESPONSE_CODES,
+  TS_LUA_CONFIG_HTTP_DEAD_SERVER_RETRY_ENABLED = TS_CONFIG_HTTP_DEAD_SERVER_RETRY_ENABLED,
+  TS_LUA_CONFIG_HTTP_DEAD_SERVER_RETRY_RESPONSE_CODES = TS_CONFIG_HTTP_SIMPLE_RETRY_RESPONSE_CODES,
+  TS_LUA_CONFIG_HTTP_URL_REMAP_REQUIRED = TS_CONFIG_HTTP_URL_REMAP_REQUIRED,
   TS_LUA_CONFIG_LAST_ENTRY = TS_CONFIG_LAST_ENTRY
 } TSLuaOverridableConfigKey;
 
diff --git a/plugins/experimental/url_sig/url_sig.c b/plugins/experimental/url_sig/url_sig.c
index 672f2c5..2418f21 100644
--- a/plugins/experimental/url_sig/url_sig.c
+++ b/plugins/experimental/url_sig/url_sig.c
@@ -32,6 +32,12 @@
 #include <limits.h>
 #include <ctype.h>
 
+#ifdef HAVE_PCRE_PCRE_H
+#include <pcre/pcre.h>
+#else
+#include <pcre.h>
+#endif
+
 #include <ts/ts.h>
 #include <ts/remap.h>
 
@@ -41,13 +47,26 @@ struct config {
   TSHttpStatus err_status;
   char *err_url;
   char keys[MAX_KEY_NUM][MAX_KEY_LEN];
+  pcre *regex;
+  pcre_extra *regex_extra;
 };
 
-void
+static void
 free_cfg(struct config *cfg)
 {
   TSError("Cleaning up...");
   TSfree(cfg->err_url);
+
+  if (cfg->regex_extra)
+#ifndef PCRE_STUDY_JIT_COMPILE
+    pcre_free(cfg->regex_extra);
+#else
+    pcre_free_study(cfg->regex_extra);
+#endif
+
+  if (cfg->regex)
+    pcre_free(cfg->regex);
+
   TSfree(cfg);
 }
 
@@ -150,16 +169,30 @@ TSRemapNewInstance(int argc, char *argv[], void **ih, char *errbuf, int errbuf_s
       value += 3;
       while (isspace(*value))
         value++;
-      //                      if (strncmp(value, "http://", strlen("http://")) != 0) {
-      //                              snprintf(errbuf, errbuf_size - 1,
-      //                                              "[TSRemapNewInstance] - Invalid config, err_status == 302, but err_url does
-      //                                              not start with \"http://\"");
-      //                              return TS_ERROR;
-      //                      }
       if (cfg->err_status == TS_HTTP_STATUS_MOVED_TEMPORARILY)
         cfg->err_url = TSstrndup(value, strlen(value));
       else
         cfg->err_url = NULL;
+    } else if (strncmp(line, "excl_regex", 10) == 0) {
+      // compile and study regex
+      const char *errptr;
+      int erroffset, options = 0;
+
+      if (cfg->regex) {
+        TSDebug(PLUGIN_NAME, "Skipping duplicate excl_regex");
+        continue;
+      }
+
+      cfg->regex = pcre_compile(value, options, &errptr, &erroffset, NULL);
+      if (cfg->regex == NULL) {
+        TSDebug(PLUGIN_NAME, "Regex compilation failed with error (%s) at character %d.", errptr, erroffset);
+      } else {
+#ifdef PCRE_STUDY_JIT_COMPILE
+        options = PCRE_STUDY_JIT_COMPILE;
+#endif
+        cfg->regex_extra = pcre_study(
+          cfg->regex, options, &errptr); // We do not need to check the error here because we can still run without the studying?
+      }
     } else {
       TSError("Error parsing line %d of file %s (%s).", line_no, config_file, line);
     }
@@ -201,7 +234,7 @@ TSRemapDeleteInstance(void *ih)
   free_cfg((struct config *)ih);
 }
 
-void
+static void
 err_log(char *url, char *msg)
 {
   if (msg && url) {
@@ -258,6 +291,24 @@ TSRemapDoRemap(void *ih, TSHttpTxn txnp, TSRemapRequestInfo *rri)
   TSDebug(PLUGIN_NAME, "%s", url);
 
   query = strstr(url, "?");
+
+  if (cfg->regex) {
+    int offset = 0, options = 0;
+    int ovector[30];
+    int len = url_len;
+    char *anchor = strstr(url, "#");
+    if (query && !anchor) {
+      len -= (query - url);
+    } else if (anchor && !query) {
+      len -= (anchor - url);
+    } else if (anchor && query) {
+      len -= ((query < anchor ? query : anchor) - url);
+    }
+    if (pcre_exec(cfg->regex, cfg->regex_extra, url, len, offset, options, ovector, 30) >= 0) {
+      goto allow;
+    }
+  }
+
   if (query == NULL) {
     err_log(url, "Has no query string.");
     goto deny;
diff --git a/plugins/experimental/url_sig/url_sig.h b/plugins/experimental/url_sig/url_sig.h
index d27ddf2..6e22600 100644
--- a/plugins/experimental/url_sig/url_sig.h
+++ b/plugins/experimental/url_sig/url_sig.h
@@ -49,5 +49,4 @@
 #define USIG_HMAC_SHA1 1
 #define USIG_HMAC_MD5 2
 
-
 #endif /* URL_SIG_H_ */
diff --git a/plugins/header_rewrite/Examples/header_rewrite.config b/plugins/header_rewrite/Examples/header_rewrite.config
new file mode 100644
index 0000000..c1aa7a2
--- /dev/null
+++ b/plugins/header_rewrite/Examples/header_rewrite.config
@@ -0,0 +1,3 @@
+include header_rewrite/Regression
+include header_rewrite/YCS-EC
+#include header_rewrite/Force-close
diff --git a/plugins/header_rewrite/Makefile.am b/plugins/header_rewrite/Makefile.am
index 4a6ca58..bd09044 100644
--- a/plugins/header_rewrite/Makefile.am
+++ b/plugins/header_rewrite/Makefile.am
@@ -28,6 +28,7 @@ header_rewrite_la_SOURCES = \
   operator.cc \
   operators.cc \
   parser.cc \
+  pluginconfig.cc \
   regex_helper.cc \
   resources.cc \
   ruleset.cc \
diff --git a/plugins/header_rewrite/factory.cc b/plugins/header_rewrite/factory.cc
index 2759e7e..fc53bac 100644
--- a/plugins/header_rewrite/factory.cc
+++ b/plugins/header_rewrite/factory.cc
@@ -59,6 +59,8 @@ operator_factory(const std::string &op)
     o = new OperatorCounter();
   } else if (op == "set-conn-dscp") {
     o = new OperatorSetConnDSCP();
+  } else if (op == "set-method") {
+    o = new OperatorSetMethod();
   } else {
     TSError("%s: unknown operator: %s", PLUGIN_NAME, op.c_str());
     return NULL;
diff --git a/plugins/header_rewrite/header_rewrite.cc b/plugins/header_rewrite/header_rewrite.cc
index ca85a24..f7c751e 100644
--- a/plugins/header_rewrite/header_rewrite.cc
+++ b/plugins/header_rewrite/header_rewrite.cc
@@ -25,26 +25,27 @@
 #include "ruleset.h"
 #include "resources.h"
 
+#include "pluginconfig.h"
+
 // Debugs
 const char PLUGIN_NAME[] = "header_rewrite";
 const char PLUGIN_NAME_DBG[] = "dbg_header_rewrite";
 
 // Forward declaration for the main continuation.
-static int cont_rewrite_headers(TSCont, TSEvent, void *);
-
+static int holder_rewrite_headers(TSCont contp, TSEvent event, void *edata);
 
 // Simple wrapper around a configuration file / set. This is useful such that
 // we can reuse most of the code for both global and per-remap rule sets.
-class RulesConfig
+class RulesConfig : public PluginConfig
 {
 public:
-  RulesConfig()
+  RulesConfig(TSHttpHookID default_hook)
   {
     memset(_rules, 0, sizeof(_rules));
     memset(_resids, 0, sizeof(_resids));
 
-    _cont = TSContCreate(cont_rewrite_headers, NULL);
-    TSContDataSet(_cont, static_cast<void *>(this));
+    this->default_hook = default_hook;
+    _cont = 0;
   }
 
   ~RulesConfig()
@@ -52,8 +53,6 @@ public:
     for (int i = TS_HTTP_READ_REQUEST_HDR_HOOK; i < TS_HTTP_LAST_HOOK; ++i) {
       delete _rules[i];
     }
-
-    TSContDestroy(_cont);
   }
 
   TSCont
@@ -61,6 +60,11 @@ public:
   {
     return _cont;
   }
+  void
+  continuation(TSCont c)
+  {
+    _cont = c;
+  }
 
   ResourceIDs
   resid(int hook) const
@@ -73,7 +77,18 @@ public:
     return _rules[hook];
   }
 
-  bool parse_config(const std::string fname, TSHttpHookID default_hook);
+  virtual bool parse_config(const std::string fname);
+
+  virtual PluginConfig *
+  clone()
+  {
+    TSDebug(PLUGIN_NAME, "pr_list::load(TSFile fh)");
+    RulesConfig *conf = new RulesConfig(this->default_hook);
+    conf->_cont = this->_cont;
+    return conf;
+  }
+
+  int rewrite_headers(TSEvent event, TSHttpTxn txnp);
 
 private:
   bool add_rule(RuleSet *rule);
@@ -81,8 +96,11 @@ private:
   TSCont _cont;
   RuleSet *_rules[TS_HTTP_LAST_HOOK + 1];
   ResourceIDs _resids[TS_HTTP_LAST_HOOK + 1];
+  TSHttpHookID default_hook;
 };
 
+#define DEFAULT_CONFIG_NAME "header_rewrite.config"
+
 // Helper function to add a rule to the rulesets
 bool
 RulesConfig::add_rule(RuleSet *rule)
@@ -100,7 +118,6 @@ RulesConfig::add_rule(RuleSet *rule)
   return false;
 }
 
-
 ///////////////////////////////////////////////////////////////////////////////
 // Config parser, use to parse both the global, and per-remap, configurations.
 //
@@ -108,12 +125,13 @@ RulesConfig::add_rule(RuleSet *rule)
 // anyways (or reload for remap.config), so not really in the critical path.
 //
 bool
-RulesConfig::parse_config(const std::string fname, TSHttpHookID default_hook)
+RulesConfig::parse_config(const std::string fname)
 {
   RuleSet *rule = NULL;
   std::string filename;
   std::ifstream f;
   int lineno = 0;
+  TSDebug(PLUGIN_NAME, "parse_config");
 
   if (0 == fname.size()) {
     TSError("%s: no config filename provided", PLUGIN_NAME);
@@ -152,6 +170,22 @@ RulesConfig::parse_config(const std::string fname, TSHttpHookID default_hook)
       continue;
     }
 
+    // include -> file reference
+    int inp = line.find("include ");
+    TSDebug(PLUGIN_NAME, "inp: %d: %s", inp, line.c_str());
+    if (inp >= 0) {
+      std::string path = line.substr(inp + strlen("include "));
+      while (std::isspace(path[0])) {
+        path.erase(0, 1);
+      }
+
+      while (std::isspace(path[path.length() - 1])) {
+        path.erase(path.length() - 1, 1);
+      }
+      TSDebug(PLUGIN_NAME, "load included config file: %s", path.c_str());
+      parse_config(path);
+    }
+
     Parser p(line); // Tokenize and parse this line
     if (p.empty()) {
       continue;
@@ -168,7 +202,10 @@ RulesConfig::parse_config(const std::string fname, TSHttpHookID default_hook)
 
       // Special case for specifying the HOOK this rule applies to.
       // These can only be at the beginning of a rule, and have an implicit [AND].
-      if (p.cond_op_is("READ_RESPONSE_HDR_HOOK")) {
+      if (p.cond_op_is("TXN_START_HOOK")) {
+        rule->set_hook(TS_HTTP_TXN_START_HOOK);
+        continue;
+      } else if (p.cond_op_is("READ_RESPONSE_HDR_HOOK")) {
         rule->set_hook(TS_HTTP_READ_RESPONSE_HDR_HOOK);
         continue;
       } else if (p.cond_op_is("READ_REQUEST_HDR_HOOK")) {
@@ -186,6 +223,9 @@ RulesConfig::parse_config(const std::string fname, TSHttpHookID default_hook)
       } else if (p.cond_op_is("REMAP_PSEUDO_HOOK")) {
         rule->set_hook(TS_REMAP_PSEUDO_HOOK);
         continue;
+      } else if (p.cond_op_is("TXN_CLOSE_HOOK")) {
+        rule->set_hook(TS_HTTP_TXN_CLOSE_HOOK);
+        continue;
       }
     }
 
@@ -203,24 +243,29 @@ RulesConfig::parse_config(const std::string fname, TSHttpHookID default_hook)
   for (int i = TS_HTTP_READ_REQUEST_HDR_HOOK; i < TS_HTTP_LAST_HOOK; ++i) {
     if (_rules[i]) {
       _resids[i] = _rules[i]->get_all_resource_ids();
+      if (default_hook == TS_HTTP_READ_RESPONSE_HDR_HOOK) {
+        // TODO jlaue do not re-register
+        TSDebug(PLUGIN_NAME, "Adding global ruleset to hook=%s", TSHttpHookNameLookup((TSHttpHookID)i));
+        TSHttpHookAdd(static_cast<TSHttpHookID>(i), this->_cont);
+      }
     }
   }
 
   return true;
 }
 
-
 ///////////////////////////////////////////////////////////////////////////////
 // Continuation
 //
-static int
-cont_rewrite_headers(TSCont contp, TSEvent event, void *edata)
+int
+RulesConfig::rewrite_headers(TSEvent event, TSHttpTxn txnp)
 {
-  TSHttpTxn txnp = static_cast<TSHttpTxn>(edata);
   TSHttpHookID hook = TS_HTTP_LAST_HOOK;
-  RulesConfig *conf = static_cast<RulesConfig *>(TSContDataGet(contp));
 
   switch (event) {
+  case TS_EVENT_HTTP_TXN_START:
+    hook = TS_HTTP_TXN_START_HOOK;
+    break;
   case TS_EVENT_HTTP_READ_RESPONSE_HDR:
     hook = TS_HTTP_READ_RESPONSE_HDR_HOOK;
     break;
@@ -236,6 +281,9 @@ cont_rewrite_headers(TSCont contp, TSEvent event, void *edata)
   case TS_EVENT_HTTP_SEND_RESPONSE_HDR:
     hook = TS_HTTP_SEND_RESPONSE_HDR_HOOK;
     break;
+  case TS_EVENT_HTTP_TXN_CLOSE:
+    hook = TS_HTTP_TXN_CLOSE_HOOK;
+    break;
   default:
     TSError("%s: unknown event for this plugin", PLUGIN_NAME);
     TSDebug(PLUGIN_NAME, "unknown event for this plugin");
@@ -243,11 +291,11 @@ cont_rewrite_headers(TSCont contp, TSEvent event, void *edata)
   }
 
   if (hook != TS_HTTP_LAST_HOOK) {
-    const RuleSet *rule = conf->rule(hook);
-    Resources res(txnp, contp);
+    const RuleSet *rule = this->rule(hook);
+    Resources res(txnp, _cont);
 
     // Get the resources necessary to process this event
-    res.gather(conf->resid(hook), hook);
+    res.gather(resid(hook), hook);
 
     // Evaluation of all rules. This code is sort of duplicate in DoRemap as well.
     while (rule) {
@@ -262,10 +310,20 @@ cont_rewrite_headers(TSCont contp, TSEvent event, void *edata)
     }
   }
 
-  TSHttpTxnReenable(txnp, TS_EVENT_HTTP_CONTINUE);
   return 0;
 }
 
+static int
+holder_rewrite_headers(TSCont contp, TSEvent event, void *edata)
+{
+  TSHttpTxn txnp = static_cast<TSHttpTxn>(edata);
+  RulesConfig *conf = static_cast<RulesConfig *>(ConfigHolder::get_config(contp));
+
+  conf->rewrite_headers(event, txnp);
+
+  TSHttpTxnReenable(txnp, TS_EVENT_HTTP_CONTINUE);
+  return 0;
+}
 
 ///////////////////////////////////////////////////////////////////////////////
 // Initialize the InkAPI plugin for the global hooks we support.
@@ -273,7 +331,9 @@ cont_rewrite_headers(TSCont contp, TSEvent event, void *edata)
 void
 TSPluginInit(int argc, const char *argv[])
 {
+  ConfigHolder *config_holder;
   TSPluginRegistrationInfo info;
+  const char *path = NULL;
 
   info.plugin_name = (char *)PLUGIN_NAME;
   info.vendor_name = (char *)"Apache Software Foundation";
@@ -285,38 +345,27 @@ TSPluginInit(int argc, const char *argv[])
 
   // Parse the global config file(s). All rules are just appended
   // to the "global" Rules configuration.
-  RulesConfig *conf = new RulesConfig;
-  bool got_config = false;
-
-  for (int i = 1; i < argc; ++i) {
-    // Parse the config file(s). Note that multiple config files are
-    // just appended to the configurations.
-    TSDebug(PLUGIN_NAME, "Loading global configuration file %s", argv[i]);
-    if (conf->parse_config(argv[i], TS_HTTP_READ_RESPONSE_HDR_HOOK)) {
-      TSDebug(PLUGIN_NAME, "Succesfully loaded global config file %s", argv[i]);
-      got_config = true;
-    } else {
-      TSError("header_rewrite: failed to parse configuration file %s", argv[i]);
-    }
-  }
+  RulesConfig *conf = new RulesConfig(TS_HTTP_READ_RESPONSE_HDR_HOOK);
 
-  if (got_config) {
-    TSCont contp = TSContCreate(cont_rewrite_headers, NULL);
-    TSContDataSet(contp, conf);
+  config_holder = new ConfigHolder(conf, DEFAULT_CONFIG_NAME, PLUGIN_NAME);
+  if (1 < argc) {
+    // Parse the config file. jlaue - reduced to single config file
+    path = argv[1];
+    TSDebug(PLUGIN_NAME, "Loading global configuration file %s", path);
+  }
 
-    for (int i = TS_HTTP_READ_REQUEST_HDR_HOOK; i < TS_HTTP_LAST_HOOK; ++i) {
-      if (conf->rule(i)) {
-        TSDebug(PLUGIN_NAME, "Adding global ruleset to hook=%s", TSHttpHookNameLookup((TSHttpHookID)i));
-        TSHttpHookAdd(static_cast<TSHttpHookID>(i), contp);
-      }
-    }
-  } else {
-    // Didn't get anything, nuke it.
-    TSError("%s: failed to parse configuration file", PLUGIN_NAME);
-    delete conf;
+  if (!path) {
+    delete config_holder;
+    return;
   }
-}
 
+  TSCont contp = TSContCreate(holder_rewrite_headers, NULL);
+  TSContDataSet(contp, config_holder);
+  conf->continuation(contp);
+
+  config_holder->init(path);
+  config_holder->addUpdateRegister();
+}
 
 ///////////////////////////////////////////////////////////////////////////////
 // Initialize the plugin as a remap plugin.
@@ -344,7 +393,6 @@ TSRemapInit(TSRemapInterface *api_info, char *errbuf, int errbuf_size)
   return TS_SUCCESS;
 }
 
-
 TSReturnCode
 TSRemapNewInstance(int argc, char *argv[], void **ih, char * /* errbuf ATS_UNUSED */, int /* errbuf_size ATS_UNUSED */)
 {
@@ -355,28 +403,54 @@ TSRemapNewInstance(int argc, char *argv[], void **ih, char * /* errbuf ATS_UNUSE
     return TS_ERROR;
   }
 
-  RulesConfig *conf = new RulesConfig;
+  RulesConfig *conf = new RulesConfig(TS_REMAP_PSEUDO_HOOK);
 
-  for (int i = 2; i < argc; ++i) {
-    TSDebug(PLUGIN_NAME, "Loading remap configuration file %s", argv[i]);
-    if (!conf->parse_config(argv[i], TS_REMAP_PSEUDO_HOOK)) {
-      TSError("%s: Unable to create remap instance", PLUGIN_NAME);
+  ConfigHolder *config_holder;
+  config_holder = new ConfigHolder(conf, DEFAULT_CONFIG_NAME, PLUGIN_NAME);
+  TSCont contp = TSContCreate(holder_rewrite_headers, NULL);
+  TSContDataSet(contp, config_holder);
+  conf->continuation(contp);
+
+  if (argc < 4) { // jlaue: config reload is only supported with 1 top level config
+
+    char *path = 0;
+    if (argc > 2) {
+      // Parse the config file. jlaue - reduced to single config file
+      path = argv[2];
+    }
+    TSDebug(PLUGIN_NAME, "Loading reloadable configuration file %s", path);
+
+    if (!path) {
+      delete config_holder;
       return TS_ERROR;
-    } else {
-      TSDebug(PLUGIN_NAME, "Succesfully loaded remap config file %s", argv[i]);
     }
-  }
 
-  // For debugging only
-  if (TSIsDebugTagSet(PLUGIN_NAME)) {
-    for (int i = TS_HTTP_READ_REQUEST_HDR_HOOK; i < TS_HTTP_LAST_HOOK; ++i) {
-      if (conf->rule(i)) {
-        TSDebug(PLUGIN_NAME, "Adding remap ruleset to hook=%s", TSHttpHookNameLookup((TSHttpHookID)i));
+    config_holder->init(path);
+    config_holder->addUpdateRegister();
+
+  } else {
+    for (int i = 2; i < argc; ++i) {
+      TSDebug(PLUGIN_NAME, "Loading remap configuration file %s", argv[i]);
+      if (!conf->parse_config(argv[i])) {
+        TSError("%s: Unable to create remap instance", PLUGIN_NAME);
+        return TS_ERROR;
+      } else {
+        TSDebug(PLUGIN_NAME, "Successfully loaded remap config file %s", argv[i]);
       }
     }
+
+    // For debugging only
+    if (TSIsDebugTagSet(PLUGIN_NAME)) {
+      for (int i = TS_HTTP_READ_REQUEST_HDR_HOOK; i < TS_HTTP_LAST_HOOK; ++i) {
+        if (conf->rule(i)) {
+          TSDebug(PLUGIN_NAME, "Adding remap ruleset to hook=%s", TSHttpHookNameLookup((TSHttpHookID)i));
+        }
+      }
+    }
+    config_holder->config = conf;
   }
 
-  *ih = static_cast<void *>(conf);
+  *ih = static_cast<void *>(config_holder);
 
   return TS_SUCCESS;
 }
@@ -384,12 +458,13 @@ TSRemapNewInstance(int argc, char *argv[], void **ih, char * /* errbuf ATS_UNUSE
 void
 TSRemapDeleteInstance(void *ih)
 {
-  RulesConfig *conf = static_cast<RulesConfig *>(ih);
-
-  delete conf;
+  ConfigHolder *config_holder = static_cast<ConfigHolder *>(ih);
+  RulesConfig *conf = static_cast<RulesConfig *>(config_holder->config);
+  TSContDestroy(conf->continuation());
+  config_holder->removeUpdateRegister();
+  delete config_holder;
 }
 
-
 ///////////////////////////////////////////////////////////////////////////////
 // This is the main "entry" point for the plugin, called for every request.
 //
@@ -403,7 +478,8 @@ TSRemapDoRemap(void *ih, TSHttpTxn rh, TSRemapRequestInfo *rri)
   }
 
   TSRemapStatus rval = TSREMAP_NO_REMAP;
-  RulesConfig *conf = static_cast<RulesConfig *>(ih);
+  ConfigHolder *config_holder = static_cast<ConfigHolder *>(ih);
+  RulesConfig *conf = static_cast<RulesConfig *>(config_holder->config);
 
   // Go through all hooks we support, and setup the txn hook(s) as necessary
   for (int i = TS_HTTP_READ_REQUEST_HDR_HOOK; i < TS_HTTP_LAST_HOOK; ++i) {
@@ -414,7 +490,7 @@ TSRemapDoRemap(void *ih, TSHttpTxn rh, TSRemapRequestInfo *rri)
   }
 
   // Now handle the remap specific rules for the "remap hook" (which is not a real hook).
-  // This is sufficiently differen than the normal cont_rewrite_headers() callback, and
+  // This is sufficiently different than the normal cont_rewrite_headers() callback, and
   // we can't (shouldn't) schedule this as a TXN hook.
   RuleSet *rule = conf->rule(TS_REMAP_PSEUDO_HOOK);
   Resources res(rh, rri);
@@ -435,6 +511,6 @@ TSRemapDoRemap(void *ih, TSHttpTxn rh, TSRemapRequestInfo *rri)
     rule = rule->next;
   }
 
-  TSDebug(PLUGIN_NAME_DBG, "Returing from TSRemapDoRemap with status: %d", rval);
+  TSDebug(PLUGIN_NAME_DBG, "Returning from TSRemapDoRemap with status: %d", rval);
   return rval;
 }
diff --git a/plugins/header_rewrite/operators.cc b/plugins/header_rewrite/operators.cc
index 173104f..5733b05 100644
--- a/plugins/header_rewrite/operators.cc
+++ b/plugins/header_rewrite/operators.cc
@@ -595,3 +595,33 @@ OperatorSetConnDSCP::exec(const Resources &res) const
     TSHttpTxnClientPacketDscpSet(res.txnp, _ds_value.get_int_value());
   }
 }
+
+// OperatorSetMethod
+void
+OperatorSetMethod::initialize(Parser &p)
+{
+  OperatorHeaders::initialize(p);
+
+  _method.set_value(p.get_arg());
+}
+
+void
+OperatorSetMethod::initialize_hooks()
+{
+  add_allowed_hook(TS_HTTP_READ_REQUEST_HDR_HOOK);
+  add_allowed_hook(TS_HTTP_SEND_REQUEST_HDR_HOOK);
+  add_allowed_hook(TS_REMAP_PSEUDO_HOOK);
+}
+
+void
+OperatorSetMethod::exec(const Resources &res) const
+{
+  std::string method;
+
+  _method.append_value(method, res);
+
+  if (res.bufp && res.hdr_loc) {
+    TSDebug(PLUGIN_NAME, "OperatorSetMethod::exec() invoked setting METHOD(%s)", method.c_str());
+    TSHttpHdrMethodSet(res.bufp, res.hdr_loc, method.c_str(), method.size());
+  }
+}
diff --git a/plugins/header_rewrite/operators.h b/plugins/header_rewrite/operators.h
index cfb59e9..bb80cd3 100644
--- a/plugins/header_rewrite/operators.h
+++ b/plugins/header_rewrite/operators.h
@@ -257,4 +257,20 @@ private:
   Value _ds_value;
 };
 
+class OperatorSetMethod : public OperatorHeaders
+{
+public:
+  OperatorSetMethod() { TSDebug(PLUGIN_NAME_DBG, "Calling CTOR for OperatorSetMethod"); }
+  void initialize(Parser &p);
+
+protected:
+  void initialize_hooks();
+  void exec(const Resources &res) const;
+
+private:
+  DISALLOW_COPY_AND_ASSIGN(OperatorSetMethod);
+
+  Value _method;
+};
+
 #endif // __OPERATORS_H
diff --git a/plugins/header_rewrite/pluginconfig.cc b/plugins/header_rewrite/pluginconfig.cc
new file mode 100644
index 0000000..ada06e5
--- /dev/null
+++ b/plugins/header_rewrite/pluginconfig.cc
@@ -0,0 +1,166 @@
+/** @file
+
+  A brief file description
+
+  @section license License
+
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+ */
+
+/*
+ * pluginconfig.cc
+ *
+ *  Created on: Jul 15, 2014
+ *      Author: jlaue
+ */
+
+#include <sys/stat.h>
+#include <time.h>
+#include <stdio.h>
+#include <string>
+
+#include "ink_defs.h"
+#include "ts/ts.h"
+#include "pluginconfig.h"
+
+#define FREE_TMOUT 300000
+
+static int free_handler(TSCont cont, TSEvent event, void *edata);
+
+PluginConfig *
+ConfigHolder::get_config(TSCont cont)
+{
+  ConfigHolder *configh = (ConfigHolder *)TSContDataGet(cont);
+  if (!configh) {
+    return 0;
+  }
+  return configh->config;
+}
+
+void
+ConfigHolder::load_config_file()
+{
+  struct stat s;
+
+  PluginConfig *newconfig, *oldconfig;
+  TSCont free_cont;
+
+  TSDebug(pluginName, "load_config_file() here");
+
+  // check date
+  if (stat(config_path, &s) < 0) {
+    TSDebug(pluginName, "Could not stat %s", config_path);
+    if (config) {
+      return;
+    }
+  } else {
+    TSDebug(pluginName, "s.st_mtime=%lu, last_load=%lu", s.st_mtime, last_load);
+    if (s.st_mtime < last_load) {
+      return;
+    }
+  }
+
+  TSDebug(pluginName, "Calling new_config: %s / %p", config_path, config);
+  newconfig = config->clone();
+  if (newconfig) {
+    if (newconfig->parse_config(config_path)) {
+      TSDebug(pluginName, "after new_config parse: %s", config_path);
+      last_load = time(NULL);
+      PluginConfig **confp = &(config);
+      oldconfig = __sync_lock_test_and_set(confp, newconfig);
+      if (oldconfig) {
+        TSDebug(pluginName, "scheduling free: %p (%p)", oldconfig, newconfig);
+        free_cont = TSContCreate(free_handler, NULL);
+        TSContDataSet(free_cont, (void *)oldconfig);
+        TSContSchedule(free_cont, FREE_TMOUT, TS_THREAD_POOL_TASK);
+      }
+    } else {
+      TSDebug(pluginName, "new_config parse failed: %s", config_path);
+      delete newconfig;
+    }
+  } else {
+    TSDebug(pluginName, "config clone failed");
+  }
+  TSDebug(pluginName, "load_config_file end");
+  return;
+}
+
+ConfigHolder *
+ConfigHolder::init(const char *path)
+{
+  char default_config_file[1024];
+
+  if (path) {
+    if (path[0] != '/') {
+      sprintf(default_config_file, "%s/%s", TSConfigDirGet(), path);
+      config_path = TSstrdup(default_config_file);
+    } else {
+      config_path = TSstrdup(path);
+    }
+  } else {
+    /* Default config file of plugins/cacheurl.config */
+    sprintf(default_config_file, "%s/%s", TSConfigDirGet(), default_config_name);
+    config_path = TSstrdup(default_config_file);
+  }
+  TSDebug(pluginName, "calling load_config_file()");
+  load_config_file();
+  return this;
+}
+
+static int
+free_handler(TSCont cont, TSEvent event, void *edata)
+{
+  (void)event;
+  (void)edata;
+  PluginConfig *config;
+
+  TSDebug("free_handler", "Freeing old config");
+  config = (PluginConfig *)TSContDataGet(cont);
+  delete (config);
+  TSContDestroy(cont);
+  return 0;
+}
+
+int
+ConfigHolder::config_handler(TSCont cont, TSEvent event, void *edata)
+{
+  (void)event;
+  (void)edata;
+  ConfigHolder *ch;
+
+  ch = (ConfigHolder *)TSContDataGet(cont);
+  TSDebug(ch->getPluginName(), "In config Handler");
+  ch->load_config_file();
+  return 0;
+}
+
+bool
+ConfigHolder::addUpdateRegister()
+{
+  config_cont = TSContCreate(config_handler, TSMutexCreate());
+  TSContDataSet(config_cont, (void *)this);
+  TSMgmtUpdateRegister(config_cont, uniqueID);
+  return true;
+}
+
+bool
+ConfigHolder::removeUpdateRegister()
+{
+  TSMgmtUnRegister(uniqueID);
+  TSContDestroy(config_cont);
+  return true;
+}
diff --git a/plugins/header_rewrite/pluginconfig.h b/plugins/header_rewrite/pluginconfig.h
new file mode 100644
index 0000000..0f679d0
--- /dev/null
+++ b/plugins/header_rewrite/pluginconfig.h
@@ -0,0 +1,93 @@
+/** @file
+
+  A brief file description
+
+  @section license License
+
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+ */
+
+/*
+ * pluginconfig.h
+ *
+ *  Created on: Jul 15, 2014
+ *      Author: jlaue
+ */
+
+#define UID_LEN 32
+
+class PluginConfig
+{
+public:
+  PluginConfig(){};
+  virtual ~PluginConfig(){};
+
+  virtual bool
+  parse_config(const std::string path)
+  {
+    TSDebug("", "new_config parse failed: %s", path.c_str());
+    return 0;
+  }
+  virtual PluginConfig *
+  clone()
+  {
+    return 0;
+  }
+};
+
+class ConfigHolder
+{
+public:
+  ConfigHolder(PluginConfig *config, const char *defaultConfigName, const char *pluginName)
+    : config(config), log(0), config_path(0), last_load(0), default_config_name(defaultConfigName), pluginName(pluginName)
+  {
+    snprintf(uniqueID, UID_LEN, "%p", this);
+  }
+  ~ConfigHolder()
+  {
+    delete config;
+    if (config_path)
+      TSfree(config_path);
+    if (log)
+      TSTextLogObjectDestroy(log);
+  }
+  const char *
+  getPluginName()
+  {
+    return pluginName;
+  }
+  ConfigHolder *init(const char *path);
+  bool addUpdateRegister();
+  bool removeUpdateRegister();
+
+  static PluginConfig *get_config(TSCont cont);
+
+  PluginConfig *config;
+
+private:
+  TSTextLogObject log;
+  char *config_path;
+  volatile time_t last_load;
+  const char *default_config_name;
+  const char *pluginName;
+  char uniqueID[UID_LEN];
+  TSCont config_cont;
+
+  void load_config_file();
+
+  static int config_handler(TSCont cont, TSEvent event, void *edata);
+};
diff --git a/plugins/header_rewrite/resources.cc b/plugins/header_rewrite/resources.cc
index d934e4a..da1b262 100644
--- a/plugins/header_rewrite/resources.cc
+++ b/plugins/header_rewrite/resources.cc
@@ -40,6 +40,8 @@ Resources::gather(const ResourceIDs ids, TSHttpHookID hook)
   }
 
   switch (hook) {
+  case TS_HTTP_TXN_START_HOOK:
+    break;
   case TS_HTTP_READ_RESPONSE_HDR_HOOK:
     // Read response headers from server
     if (ids & RSRC_SERVER_RESPONSE_HEADERS) {
@@ -98,7 +100,8 @@ Resources::gather(const ResourceIDs ids, TSHttpHookID hook)
       hdr_loc = client_hdr_loc;
     }
     break;
-
+  case TS_HTTP_TXN_CLOSE_HOOK:
+    break;
 
   default:
     break;
diff --git a/plugins/header_rewrite/statement.cc b/plugins/header_rewrite/statement.cc
index 5ef247f..6892603 100644
--- a/plugins/header_rewrite/statement.cc
+++ b/plugins/header_rewrite/statement.cc
@@ -66,12 +66,14 @@ Statement::set_hook(TSHttpHookID hook)
 void
 Statement::initialize_hooks()
 {
+  add_allowed_hook(TS_HTTP_TXN_START_HOOK);
   add_allowed_hook(TS_HTTP_READ_RESPONSE_HDR_HOOK);
   add_allowed_hook(TS_HTTP_READ_REQUEST_PRE_REMAP_HOOK);
   add_allowed_hook(TS_HTTP_READ_REQUEST_HDR_HOOK);
   add_allowed_hook(TS_HTTP_SEND_REQUEST_HDR_HOOK);
   add_allowed_hook(TS_HTTP_SEND_RESPONSE_HDR_HOOK);
   add_allowed_hook(TS_REMAP_PSEUDO_HOOK);
+  add_allowed_hook(TS_HTTP_TXN_CLOSE_HOOK);
 }
 
 
diff --git a/proxy/InkAPI.cc b/proxy/InkAPI.cc
index 329d687..eb230fa 100644
--- a/proxy/InkAPI.cc
+++ b/proxy/InkAPI.cc
@@ -1274,28 +1274,49 @@ APIHooks::clear()
 ConfigUpdateCbTable::ConfigUpdateCbTable()
 {
   cb_table = ink_hash_table_create(InkHashTableKeyType_String);
+  mutex = new_ProxyMutex();
 }
 
 ConfigUpdateCbTable::~ConfigUpdateCbTable()
 {
   ink_assert(cb_table != NULL);
+  ink_assert(mutex != NULL);
 
   ink_hash_table_destroy(cb_table);
+  mutex->free();
 }
 
 void
 ConfigUpdateCbTable::insert(INKContInternal *contp, const char *name)
 {
   ink_assert(cb_table != NULL);
+  ink_assert(mutex != NULL);
 
-  if (contp && name)
+  if (contp && name) {
+    MUTEX_TAKE_LOCK(mutex, this_ethread());
     ink_hash_table_insert(cb_table, (InkHashTableKey)name, (InkHashTableValue)contp);
+    MUTEX_UNTAKE_LOCK(mutex, this_ethread());
+  }
+}
+
+void
+ConfigUpdateCbTable::remove(const char *name)
+{
+  ink_assert(cb_table != NULL);
+  ink_assert(mutex != NULL);
+
+  if (name) {
+    MUTEX_TAKE_LOCK(mutex, this_ethread());
+    ink_hash_table_delete(cb_table, (InkHashTableKey)name);
+    MUTEX_UNTAKE_LOCK(mutex, this_ethread());
+  }
 }
 
 void
 ConfigUpdateCbTable::invoke(const char *name)
 {
   ink_assert(cb_table != NULL);
+  ink_assert(mutex != NULL);
 
   InkHashTableIteratorState ht_iter;
   InkHashTableEntry *ht_entry;
@@ -1303,6 +1324,7 @@ ConfigUpdateCbTable::invoke(const char *name)
 
   if (name != NULL) {
     if (strcmp(name, "*") == 0) {
+      MUTEX_TAKE_LOCK(mutex, this_ethread());
       ht_entry = ink_hash_table_iterator_first(cb_table, &ht_iter);
       while (ht_entry != NULL) {
         contp = (INKContInternal *)ink_hash_table_entry_value(cb_table, ht_entry);
@@ -1310,13 +1332,16 @@ ConfigUpdateCbTable::invoke(const char *name)
         invoke(contp);
         ht_entry = ink_hash_table_iterator_next(cb_table, &ht_iter);
       }
+      MUTEX_UNTAKE_LOCK(mutex, this_ethread());
     } else {
+      MUTEX_TAKE_LOCK(mutex, this_ethread());
       ht_entry = ink_hash_table_lookup_entry(cb_table, (InkHashTableKey)name);
       if (ht_entry != NULL) {
         contp = (INKContInternal *)ink_hash_table_entry_value(cb_table, ht_entry);
         ink_assert(contp != NULL);
         invoke(contp);
       }
+      MUTEX_UNTAKE_LOCK(mutex, this_ethread());
     }
   }
 }
@@ -4159,6 +4184,14 @@ TSMgmtUpdateRegister(TSCont contp, const char *plugin_name)
   global_config_cbs->insert((INKContInternal *)contp, plugin_name);
 }
 
+void
+TSMgmtUnRegister(const char *plugin_name)
+{
+  sdk_assert(sdk_sanity_check_null_ptr((void *)plugin_name) == TS_SUCCESS);
+
+  global_config_cbs->remove(plugin_name);
+}
+
 TSReturnCode
 TSMgmtIntGet(const char *var_name, TSMgmtInt *result)
 {
@@ -6721,15 +6754,19 @@ TSCacheScan(TSCont contp, TSCacheKey key, int KB_per_second)
 int
 TSStatCreate(const char *the_name, TSRecordDataType the_type, TSStatPersistence persist, TSStatSync sync)
 {
-  int id = ink_atomic_increment(&api_rsb_index, 1);
   RecRawStatSyncCb syncer = RecRawStatSyncCount;
 
   // TODO: This only supports "int" data types at this point, since the "Raw" stats
   // interfaces only supports integers. Going forward, we could extend either the "Raw"
   // stats APIs, or make non-int use the direct (synchronous) stats APIs (slower).
-  if ((sdk_sanity_check_null_ptr((void *)the_name) != TS_SUCCESS) || (sdk_sanity_check_null_ptr((void *)api_rsb) != TS_SUCCESS) ||
-      (id >= api_rsb->max_stats))
+  if ((sdk_sanity_check_null_ptr((void *)the_name) != TS_SUCCESS) || (sdk_sanity_check_null_ptr((void *)api_rsb) != TS_SUCCESS)) {
+    return TS_ERROR;
+  }
+
+  int id = ink_atomic_increment(&api_rsb_index, 1);
+  if (id >= api_rsb->max_stats) {
     return TS_ERROR;
+  }
 
   switch (sync) {
   case TS_STAT_SYNC_SUM:
@@ -7888,6 +7925,38 @@ _conf_to_memberp(TSOverridableConfigKey conf, OverridableHttpConfigParams *overr
     typ = OVERRIDABLE_TYPE_STRING;
     ret = &overridableHttpConfig->global_user_agent_header;
     break;
+  case TS_CONFIG_HTTP_TRANSACTION_ACTIVE_TIMEOUT_IN:
+    typ = OVERRIDABLE_TYPE_INT;
+    ret = &overridableHttpConfig->transaction_active_timeout_in;
+    break;
+  case TS_CONFIG_HTTP_PER_PARENT_CONNECT_ATTEMPTS:
+    typ = OVERRIDABLE_TYPE_INT;
+    ret = &overridableHttpConfig->per_parent_connect_attempts;
+    break;
+  case TS_CONFIG_HTTP_PARENT_TOTAL_CONNECT_ATTEMPTS:
+    typ = OVERRIDABLE_TYPE_INT;
+    ret = &overridableHttpConfig->parent_connect_attempts;
+    break;
+  case TS_CONFIG_HTTP_SIMPLE_RETRY_ENABLED:
+    typ = OVERRIDABLE_TYPE_INT;
+    ret = &overridableHttpConfig->simple_retry_enabled;
+    break;
+  case TS_CONFIG_HTTP_SIMPLE_RETRY_RESPONSE_CODES:
+    ret = &overridableHttpConfig->simple_retry_response_codes_string;
+    typ = OVERRIDABLE_TYPE_STRING;
+    break;
+  case TS_CONFIG_HTTP_DEAD_SERVER_RETRY_ENABLED:
+    typ = OVERRIDABLE_TYPE_INT;
+    ret = &overridableHttpConfig->dead_server_retry_enabled;
+    break;
+  case TS_CONFIG_HTTP_DEAD_SERVER_RETRY_RESPONSE_CODES:
+    ret = &overridableHttpConfig->dead_server_retry_response_codes_string;
+    typ = OVERRIDABLE_TYPE_STRING;
+    break;
+  case TS_CONFIG_HTTP_URL_REMAP_REQUIRED:
+    ret = &overridableHttpConfig->url_remap_required;
+    typ = OVERRIDABLE_TYPE_BYTE;
+    break;
 
   // This helps avoiding compiler warnings, yet detect unhandled enum members.
   case TS_CONFIG_NULL:
@@ -8073,6 +8142,20 @@ TSHttpTxnConfigStringSet(TSHttpTxn txnp, TSOverridableConfigKey conf, const char
       s->t_state.txn_conf->global_user_agent_header_size = 0;
     }
     break;
+  case TS_CONFIG_HTTP_SIMPLE_RETRY_RESPONSE_CODES:
+    if (value && length > 0) {
+      s->t_state.txn_conf->simple_retry_response_codes_string = const_cast<char *>(value); // The "core" likes non-const char*
+    } else {
+      s->t_state.txn_conf->simple_retry_response_codes_string = NULL;
+    }
+    break;
+  case TS_CONFIG_HTTP_DEAD_SERVER_RETRY_RESPONSE_CODES:
+    if (value && length > 0) {
+      s->t_state.txn_conf->dead_server_retry_response_codes_string = const_cast<char *>(value); // The "core" likes non-const char*
+    } else {
+      s->t_state.txn_conf->dead_server_retry_response_codes_string = NULL;
+    }
+    break;
   default:
     return TS_ERROR;
     break;
@@ -8177,6 +8260,11 @@ TSHttpTxnConfigFind(const char *name, int length, TSOverridableConfigKey *conf,
 
   case 37:
     switch (name[length - 1]) {
+    case 'd':
+      if (!strncmp(name, "proxy.config.url_remap.remap_required", length)) {
+        cnf = TS_CONFIG_HTTP_URL_REMAP_REQUIRED;
+      }
+      break;
     case 'e':
       if (!strncmp(name, "proxy.config.http.cache.max_stale_age", length))
         cnf = TS_CONFIG_HTTP_CACHE_MAX_STALE_AGE;
@@ -8440,6 +8528,10 @@ TSHttpTxnConfigFind(const char *name, int length, TSOverridableConfigKey *conf,
       else if (!strncmp(name, "proxy.config.http.cache.guaranteed_max_lifetime", length))
         cnf = TS_CONFIG_HTTP_CACHE_GUARANTEED_MAX_LIFETIME;
       break;
+    case 'n':
+      if (!strncmp(name, "proxy.config.http.transaction_active_timeout_in", length))
+        cnf = TS_CONFIG_HTTP_TRANSACTION_ACTIVE_TIMEOUT_IN;
+      break;
     case 't':
       if (!strncmp(name, "proxy.config.http.post_connect_attempts_timeout", length))
         cnf = TS_CONFIG_HTTP_POST_CONNECT_ATTEMPTS_TIMEOUT;
@@ -8499,6 +8591,10 @@ TSHttpTxnConfigFind(const char *name, int length, TSOverridableConfigKey *conf,
       if (!strncmp(name, "proxy.config.http.cache.cache_urls_that_look_dynamic", length))
         cnf = TS_CONFIG_HTTP_CACHE_CACHE_URLS_THAT_LOOK_DYNAMIC;
       break;
+    case 'd':
+      if (!strncmp(name, "proxy.config.http.parent_origin.simple_retry_enabled", length))
+        cnf = TS_CONFIG_HTTP_SIMPLE_RETRY_ENABLED;
+      break;
     case 'n':
       if (!strncmp(name, "proxy.config.http.transaction_no_activity_timeout_in", length))
         cnf = TS_CONFIG_HTTP_TRANSACTION_NO_ACTIVITY_TIMEOUT_IN;
@@ -8512,6 +8608,10 @@ TSHttpTxnConfigFind(const char *name, int length, TSOverridableConfigKey *conf,
 
   case 53:
     switch (name[length - 1]) {
+    case 's':
+      if (!strncmp(name, "proxy.config.http.parent_proxy.total_connect_attempts", length))
+        cnf = TS_CONFIG_HTTP_PARENT_TOTAL_CONNECT_ATTEMPTS;
+      break;
     case 't':
       if (!strncmp(name, "proxy.config.http.transaction_no_activity_timeout_out", length))
         cnf = TS_CONFIG_HTTP_TRANSACTION_NO_ACTIVITY_TIMEOUT_OUT;
@@ -8525,9 +8625,37 @@ TSHttpTxnConfigFind(const char *name, int length, TSOverridableConfigKey *conf,
     }
     break;
 
+  case 57:
+    if (!strncmp(name, "proxy.config.http.parent_origin.dead_server_retry_enabled", length)) {
+      cnf = TS_CONFIG_HTTP_DEAD_SERVER_RETRY_ENABLED;
+    }
+    break;
+
   case 58:
-    if (!strncmp(name, "proxy.config.http.connect_attempts_max_retries_dead_server", length))
-      cnf = TS_CONFIG_HTTP_CONNECT_ATTEMPTS_MAX_RETRIES_DEAD_SERVER;
+    switch (name[length - 1]) {
+    case 'r':
+      if (!strncmp(name, "proxy.config.http.connect_attempts_max_retries_dead_server", length))
+        cnf = TS_CONFIG_HTTP_CONNECT_ATTEMPTS_MAX_RETRIES_DEAD_SERVER;
+      break;
+    case 's':
+      if (!strncmp(name, "proxy.config.http.parent_proxy.per_parent_connect_attempts", length))
+        cnf = TS_CONFIG_HTTP_PER_PARENT_CONNECT_ATTEMPTS;
+      break;
+    }
+    break;
+
+  case 59:
+    if (!strncmp(name, "proxy.config.http.parent_origin.simple_retry_response_codes", length)) {
+      cnf = TS_CONFIG_HTTP_SIMPLE_RETRY_RESPONSE_CODES;
+      typ = TS_RECORDDATATYPE_STRING;
+    }
+    break;
+
+  case 64:
+    if (!strncmp(name, "proxy.config.http.parent_origin.dead_server_retry_response_codes", length)) {
+      cnf = TS_CONFIG_HTTP_DEAD_SERVER_RETRY_RESPONSE_CODES;
+      typ = TS_RECORDDATATYPE_STRING;
+    }
     break;
   }
 
diff --git a/proxy/InkAPIInternal.h b/proxy/InkAPIInternal.h
index ede71f1..e1eb6d4 100644
--- a/proxy/InkAPIInternal.h
+++ b/proxy/InkAPIInternal.h
@@ -337,11 +337,13 @@ public:
   ~ConfigUpdateCbTable();
 
   void insert(INKContInternal *contp, const char *name);
+  void remove(const char *name);
   void invoke(const char *name);
   void invoke(INKContInternal *contp);
 
 private:
   InkHashTable *cb_table;
+  ProxyMutex *mutex;
 };
 
 void api_init();
diff --git a/proxy/InkAPITest.cc b/proxy/InkAPITest.cc
index 200759e..e0ecad1 100644
--- a/proxy/InkAPITest.cc
+++ b/proxy/InkAPITest.cc
@@ -7206,7 +7206,11 @@ const char *SDK_Overridable_Configs[TS_CONFIG_LAST_ENTRY] = {
   "proxy.config.ssl.hsts_max_age", "proxy.config.ssl.hsts_include_subdomains", "proxy.config.http.cache.open_read_retry_time",
   "proxy.config.http.cache.max_open_read_retries", "proxy.config.http.cache.range.write",
   "proxy.config.http.post.check.content_length.enabled", "proxy.config.http.global_user_agent_header",
-  "proxy.config.http.auth_server_session_private"};
+  "proxy.config.http.auth_server_session_private", "proxy.config.http.transaction_active_timeout_in",
+  "proxy.config.http.parent_proxy.per_parent_connect_attempts", "proxy.config.http.parent_proxy.total_connect_attempts",
+  "proxy.config.http.parent_origin.simple_retry_enabled", "proxy.config.http.parent_origin.simple_retry_response_codes",
+  "proxy.config.http.parent_origin.dead_server_retry_enabled", "proxy.config.http.parent_origin.dead_server_retry_response_codes",
+  "proxy.config.http.url_remap.remap_required"};
 
 REGRESSION_TEST(SDK_API_OVERRIDABLE_CONFIGS)(RegressionTest *test, int /* atype ATS_UNUSED */, int *pstatus)
 {
diff --git a/proxy/Main.cc b/proxy/Main.cc
index 6c17c99..424f1e8 100644
--- a/proxy/Main.cc
+++ b/proxy/Main.cc
@@ -1478,6 +1478,13 @@ main(int /* argc ATS_UNUSED */, const char **argv)
   // Restart syslog now that we have configuration info
   syslog_log_configure();
 
+  // init huge pages
+  int enabled;
+  REC_ReadConfigInteger(enabled, "proxy.config.allocator.hugepages");
+  ats_hugepage_init(enabled);
+  Debug("hugepages", "ats_pagesize reporting %zu", ats_pagesize());
+  Debug("hugepages", "ats_hugepage_size reporting %zu", ats_hugepage_size());
+
   if (!num_accept_threads)
     REC_ReadConfigInteger(num_accept_threads, "proxy.config.accept_threads");
 
diff --git a/proxy/ParentSelection.cc b/proxy/ParentSelection.cc
index cd30180..9342690 100644
--- a/proxy/ParentSelection.cc
+++ b/proxy/ParentSelection.cc
@@ -195,7 +195,7 @@ ParentConfigParams::parentExists(HttpRequestData *rdata)
 
   findParent(rdata, &junk);
 
-  if (junk.r == PARENT_SPECIFIED) {
+  if (junk.r == PARENT_SPECIFIED || junk.r == PARENT_ORIGIN) {
     return true;
   } else {
     return false;
@@ -280,6 +280,9 @@ ParentConfigParams::findParent(HttpRequestData *rdata, ParentResult *result)
     case PARENT_SPECIFIED:
       Debug("cdn", "PARENT_SPECIFIED");
       break;
+    case PARENT_ORIGIN:
+      Debug("cdn", "PARENT_ORIGIN");
+      break;
     default:
       // Handled here:
       // PARENT_AGENT
@@ -294,6 +297,7 @@ ParentConfigParams::findParent(HttpRequestData *rdata, ParentResult *result)
     case PARENT_DIRECT:
       Debug("parent_select", "Result for %s was %s", host, ParentResultStr[result->r]);
       break;
+    case PARENT_ORIGIN:
     case PARENT_SPECIFIED:
       Debug("parent_select", "Result for %s was parent %s:%d", host, result->hostname, result->port);
       break;
@@ -314,8 +318,8 @@ ParentConfigParams::recordRetrySuccess(ParentResult *result)
   //  Make sure that we are being called back with with a
   //   result structure with a parent that is being retried
   ink_release_assert(result->retry == true);
-  ink_assert(result->r == PARENT_SPECIFIED);
-  if (result->r != PARENT_SPECIFIED) {
+  ink_assert(result->r == PARENT_SPECIFIED || result->r == PARENT_ORIGIN);
+  if (result->r != PARENT_SPECIFIED && result->r != PARENT_ORIGIN) {
     return;
   }
   // If we were set through the API we currently have not failover
@@ -347,8 +351,8 @@ ParentConfigParams::markParentDown(ParentResult *result)
 
   //  Make sure that we are being called back with with a
   //   result structure with a parent
-  ink_assert(result->r == PARENT_SPECIFIED);
-  if (result->r != PARENT_SPECIFIED) {
+  ink_assert(result->r == PARENT_SPECIFIED || result->r == PARENT_ORIGIN);
+  if (result->r != PARENT_SPECIFIED && result->r != PARENT_ORIGIN) {
     return;
   }
   // If we were set through the API we currently have not failover
@@ -382,7 +386,7 @@ ParentConfigParams::markParentDown(ParentResult *result)
       new_fail_count = pRec->failCount = 1;
     }
 
-    Debug("parent_select", "Parent %s marked as down %s:%d", (result->retry) ? "retry" : "initially", pRec->hostname, pRec->port);
+    Note("Parent %s marked as down %s:%d", (result->retry) ? "retry" : "initially", pRec->hostname, pRec->port);
 
   } else {
     int old_count = ink_atomic_increment(&pRec->failCount, 1);
@@ -392,8 +396,9 @@ ParentConfigParams::markParentDown(ParentResult *result)
   }
 
   if (new_fail_count > 0 && new_fail_count == FailThreshold) {
-    Note("http parent proxy %s:%d marked down", pRec->hostname, pRec->port);
+    Note("Failure threshold met, http parent proxy %s:%d marked down", pRec->hostname, pRec->port);
     pRec->available = false;
+    Debug("parent_select", "Parent marked unavailable, pRec->available=%d", pRec->available);
   }
 }
 
@@ -404,8 +409,8 @@ ParentConfigParams::nextParent(HttpRequestData *rdata, ParentResult *result)
 
   //  Make sure that we are being called back with a
   //   result structure with a parent
-  ink_assert(result->r == PARENT_SPECIFIED);
-  if (result->r != PARENT_SPECIFIED) {
+  ink_assert(result->r == PARENT_SPECIFIED || result->r == PARENT_ORIGIN);
+  if (result->r != PARENT_SPECIFIED && result->r != PARENT_ORIGIN) {
     result->r = PARENT_FAIL;
     return;
   }
@@ -437,6 +442,9 @@ ParentConfigParams::nextParent(HttpRequestData *rdata, ParentResult *result)
   case PARENT_DIRECT:
     Debug("cdn", "PARENT_DIRECT");
     break;
+  case PARENT_ORIGIN:
+    Debug("cdn", "PARENT_ORIGIN");
+    break;
   case PARENT_SPECIFIED:
     Debug("cdn", "PARENT_SPECIFIED");
     break;
@@ -455,6 +463,7 @@ ParentConfigParams::nextParent(HttpRequestData *rdata, ParentResult *result)
     case PARENT_DIRECT:
       Debug("parent_select", "Retry result for %s was %s", host, ParentResultStr[result->r]);
       break;
+    case PARENT_ORIGIN:
     case PARENT_SPECIFIED:
       Debug("parent_select", "Retry result for %s was parent %s:%d", host, result->hostname, result->port);
       break;
@@ -470,6 +479,34 @@ ParentConfigParams::nextParent(HttpRequestData *rdata, ParentResult *result)
 //   End API functions
 //
 
+uint64_t
+ParentRecord::getPathHash(HttpRequestData *hrdata, ATSHash64 *h)
+{
+  const char *tmp = NULL;
+  int len;
+  URL *url = hrdata->hdr->url_get();
+
+  // Always hash on '/' because paths returned by ATS are always stripped of it
+  h->update("/", 1);
+
+  tmp = url->path_get(&len);
+  if (tmp) {
+    h->update(tmp, len);
+  }
+
+  if (!ignore_query) {
+    tmp = url->query_get(&len);
+    if (tmp) {
+      h->update("?", 1);
+      h->update(tmp, len);
+    }
+  }
+
+  h->final();
+
+  return h->get();
+}
+
 void
 ParentRecord::FindParent(bool first_call, ParentResult *result, RequestData *rdata, ParentConfigParams *config)
 {
@@ -478,29 +515,23 @@ ParentRecord::FindParent(bool first_call, ParentResult *result, RequestData *rda
   bool parentUp = false;
   bool parentRetry = false;
   bool bypass_ok = (go_direct == true && config->DNS_ParentOnly == 0);
-  char *url, *path = NULL;
+  uint64_t path_hash;
+
   ATSHash64Sip24 hash;
   pRecord *prtmp = NULL;
 
-  HttpRequestData *request_info = (HttpRequestData *)rdata;
+  HttpRequestData *request_info = static_cast<HttpRequestData *>(rdata);
 
   ink_assert(num_parents > 0 || go_direct == true);
 
-  if (first_call == true) {
+  if (first_call) {
     if (parents == NULL) {
       // We should only get into this state if
-      //   if we are supposed to go dirrect
+      //   if we are supposed to go direct
       ink_assert(go_direct == true);
       goto NO_PARENTS;
-    } else if (round_robin == true) {
-      cur_index = ink_atomic_increment((int32_t *)&rr_next, 1);
-      cur_index = result->start_parent = cur_index % num_parents;
     } else {
       switch (round_robin) {
-      case P_STRICT_ROUND_ROBIN:
-        cur_index = ink_atomic_increment((int32_t *)&rr_next, 1);
-        cur_index = cur_index % num_parents;
-        break;
       case P_HASH_ROUND_ROBIN:
         // INKqa12817 - make sure to convert to host byte order
         // Why was it important to do host order here?  And does this have any
@@ -514,24 +545,24 @@ ParentRecord::FindParent(bool first_call, ParentResult *result, RequestData *rda
         }
         break;
       case P_CONSISTENT_HASH:
-        url = rdata->get_string();
-        path = strstr(url + 7, "/");
-        if (path) {
-          prtmp = (pRecord *)chash->lookup(path, &(result->chashIter), NULL, (ATSHash64 *)&hash);
+        path_hash = getPathHash(request_info, (ATSHash64 *)&hash);
+        if (path_hash) {
+          prtmp = (pRecord *)chash->lookup_by_hashval(path_hash, &result->chashIter, &result->wrap_around);
           if (prtmp) {
             cur_index = prtmp->idx;
             result->foundParents[cur_index] = true;
             result->start_parent++;
+            break;
           } else {
-            Error("Consistent Hash loopup returned NULL");
-            cur_index = ink_atomic_increment((int32_t *)&rr_next, 1);
-            cur_index = cur_index % num_parents;
+            Error("Consistent Hash lookup returned NULL (first lookup)");
           }
         } else {
-          Error("Could not find path in URL: %s", url);
-          cur_index = ink_atomic_increment((int32_t *)&rr_next, 1);
-          cur_index = cur_index % num_parents;
+          Error("Could not find path");
         }
+      // Fall through to round robin
+      case P_STRICT_ROUND_ROBIN:
+        cur_index = ink_atomic_increment((int32_t *)&rr_next, 1);
+        cur_index = cur_index % num_parents;
         break;
       case P_NO_ROUND_ROBIN:
         cur_index = result->start_parent = 0;
@@ -542,22 +573,26 @@ ParentRecord::FindParent(bool first_call, ParentResult *result, RequestData *rda
     }
   } else {
     if (round_robin == P_CONSISTENT_HASH) {
+      Debug("parent_select", "result->start_parent=%d, num_parents=%d", result->start_parent, num_parents);
       if (result->start_parent == (unsigned int)num_parents) {
         result->wrap_around = true;
         result->start_parent = 0;
         memset(result->foundParents, 0, sizeof(result->foundParents));
-        url = rdata->get_string();
-        path = strstr(url + 7, "/");
       }
 
       do {
-        prtmp = (pRecord *)chash->lookup(path, &(result->chashIter), NULL, (ATSHash64 *)&hash);
-        path = NULL;
-      } while (result->foundParents[prtmp->idx]);
+        prtmp = (pRecord *)chash->lookup(NULL, 0, &result->chashIter, &result->wrap_around, &hash);
+      } while (prtmp && result->foundParents[prtmp->idx]);
 
-      cur_index = prtmp->idx;
-      result->foundParents[cur_index] = true;
-      result->start_parent++;
+      if (prtmp) {
+        cur_index = prtmp->idx;
+        result->foundParents[cur_index] = true;
+        result->start_parent++;
+      } else {
+        Error("Consistent Hash lookup returned NULL (subsequent lookup)");
+        cur_index = ink_atomic_increment((int32_t *)&rr_next, 1);
+        cur_index = cur_index % num_parents;
+      }
     } else {
       // Move to next parent due to failure
       cur_index = (result->last_parent + 1) % num_parents;
@@ -583,8 +618,8 @@ ParentRecord::FindParent(bool first_call, ParentResult *result, RequestData *rda
     // DNS ParentOnly inhibits bypassing the parent so always return that t
     if ((parents[cur_index].failedAt == 0) || (parents[cur_index].failCount < config->FailThreshold)) {
       Debug("parent_select", "config->FailThreshold = %d", config->FailThreshold);
-      Debug("parent_select", "Selecting a down parent due to little failCount"
-                             "(faileAt: %u failCount: %d)",
+      Debug("parent_select", "Selecting a parent due to little failCount"
+                             "(failedAt: %u failCount: %d)",
             (unsigned)parents[cur_index].failedAt, parents[cur_index].failCount);
       parentUp = true;
     } else {
@@ -596,14 +631,17 @@ ParentRecord::FindParent(bool first_call, ParentResult *result, RequestData *rda
         parentUp = true;
         parentRetry = true;
         Debug("parent_select", "Parent marked for retry %s:%d", parents[cur_index].hostname, parents[cur_index].port);
-
       } else {
         parentUp = false;
       }
     }
 
     if (parentUp == true) {
-      result->r = PARENT_SPECIFIED;
+      if (!this->parent_is_proxy) {
+        result->r = PARENT_ORIGIN;
+      } else {
+        result->r = PARENT_SPECIFIED;
+      }
       result->hostname = parents[cur_index].hostname;
       result->port = parents[cur_index].port;
       result->last_parent = cur_index;
@@ -619,18 +657,17 @@ ParentRecord::FindParent(bool first_call, ParentResult *result, RequestData *rda
         result->wrap_around = false;
         result->start_parent = 0;
         memset(result->foundParents, 0, sizeof(result->foundParents));
-        url = rdata->get_string();
-        path = strstr(url + 7, "/");
       }
 
       do {
-        prtmp = (pRecord *)chash->lookup(path, &(result->chashIter), NULL, (ATSHash64 *)&hash);
-        path = NULL;
-      } while (result->foundParents[prtmp->idx]);
+        prtmp = (pRecord *)chash->lookup(NULL, 0, &(result->chashIter), &result->wrap_around, (ATSHash64 *)&hash);
+      } while (prtmp && result->foundParents[prtmp->idx]);
 
-      cur_index = prtmp->idx;
-      result->foundParents[cur_index] = true;
-      result->start_parent++;
+      if (prtmp) {
+        cur_index = prtmp->idx;
+        result->foundParents[cur_index] = true;
+        result->start_parent++;
+      }
     } else {
       cur_index = (cur_index + 1) % num_parents;
     }
@@ -782,7 +819,9 @@ ParentRecord::DefaultInit(char *val)
 
   this->go_direct = true;
   this->round_robin = P_NO_ROUND_ROBIN;
+  this->ignore_query = false;
   this->scheme = NULL;
+  this->parent_is_proxy = true;
   errPtr = ProcessParents(val);
 
   if (errPtr != NULL) {
@@ -875,6 +914,19 @@ ParentRecord::Init(matcher_line *line_info)
         go_direct = true;
       }
       used = true;
+    } else if (strcasecmp(label, "qstring") == 0) {
+      // qstring=ignore | consider
+      if (strcasecmp(val, "ignore") == 0) {
+        this->ignore_query = true;
+      }
+      used = true;
+    } else if (strcasecmp(label, "parent_is_proxy") == 0) {
+      if (strcasecmp(val, "false") == 0) {
+        parent_is_proxy = false;
+      } else {
+        parent_is_proxy = true;
+      }
+      used = true;
     }
     // Report errors generated by ProcessParents();
     if (errPtr != NULL) {
@@ -944,6 +996,7 @@ ParentRecord::Print()
     printf(" %s:%d ", parents[i].hostname, parents[i].port);
   }
   printf(" rr=%s direct=%s\n", ParentRRStr[round_robin], (go_direct == true) ? "true" : "false");
+  printf(" parent_is_proxy=%s\n", ((parent_is_proxy == true) ? "true" : "false"));
 }
 
 // ParentRecord* createDefaultParent(char* val)
@@ -1384,6 +1437,11 @@ show_result(ParentResult *p)
     printf("hostname is %s\n", p->hostname);
     printf("port is %d\n", p->port);
     break;
+  case PARENT_ORIGIN:
+    printf("result is PARENT_ORIGIN\n");
+    printf("hostname is %s\n", p->hostname);
+    printf("port is %d\n", p->port);
+    break;
   case PARENT_FAIL:
     printf("result is PARENT_FAIL\n");
     break;
diff --git a/proxy/ParentSelection.h b/proxy/ParentSelection.h
index e3ac989..1907a42 100644
--- a/proxy/ParentSelection.h
+++ b/proxy/ParentSelection.h
@@ -56,6 +56,7 @@ enum ParentResultType {
   PARENT_SPECIFIED,
   PARENT_AGENT,
   PARENT_FAIL,
+  PARENT_ORIGIN,
 };
 
 typedef ControlMatcher<ParentRecord, ParentResult> P_table;
@@ -196,7 +197,10 @@ enum ParentRR_t {
 class ParentRecord : public ControlBase
 {
 public:
-  ParentRecord() : parents(NULL), num_parents(0), round_robin(P_NO_ROUND_ROBIN), rr_next(0), go_direct(true), chash(NULL) {}
+  ParentRecord()
+    : parents(NULL), num_parents(0), round_robin(P_NO_ROUND_ROBIN), rr_next(0), go_direct(true), parent_is_proxy(true), chash(NULL)
+  {
+  }
 
   ~ParentRecord();
 
@@ -204,6 +208,7 @@ public:
   bool DefaultInit(char *val);
   void UpdateMatch(ParentResult *result, RequestData *rdata);
   void FindParent(bool firstCall, ParentResult *result, RequestData *rdata, ParentConfigParams *config);
+  uint64_t getPathHash(HttpRequestData *hrdata, ATSHash64 *h);
   void Print();
   pRecord *parents;
   int num_parents;
@@ -213,14 +218,21 @@ public:
   {
     return go_direct;
   }
+  bool
+  isParentProxy() const
+  {
+    return parent_is_proxy;
+  }
 
   const char *scheme;
   // private:
   const char *ProcessParents(char *val);
   void buildConsistentHash(void);
   ParentRR_t round_robin;
+  bool ignore_query;
   volatile uint32_t rr_next;
   bool go_direct;
+  bool parent_is_proxy;
   ATSConsistentHash *chash;
 };
 
diff --git a/proxy/api/ts/ts.h b/proxy/api/ts/ts.h
index 60fb0db..4edc5a0 100644
--- a/proxy/api/ts/ts.h
+++ b/proxy/api/ts/ts.h
@@ -1185,6 +1185,7 @@ tsapi void *TSConfigDataGet(TSConfig configp);
 /* --------------------------------------------------------------------------
    Management */
 tsapi void TSMgmtUpdateRegister(TSCont contp, const char *plugin_name);
+tsapi void TSMgmtUnRegister(const char *plugin_name);
 tsapi TSReturnCode TSMgmtIntGet(const char *var_name, TSMgmtInt *result);
 tsapi TSReturnCode TSMgmtCounterGet(const char *var_name, TSMgmtCounter *result);
 tsapi TSReturnCode TSMgmtFloatGet(const char *var_name, TSMgmtFloat *result);
diff --git a/proxy/hdrs/HdrToken.cc b/proxy/hdrs/HdrToken.cc
index dfa0883..6f097aa 100644
--- a/proxy/hdrs/HdrToken.cc
+++ b/proxy/hdrs/HdrToken.cc
@@ -77,8 +77,8 @@ static const char *_hdrtoken_strs[] = {
   "Subject", // NNTP
   "Summary", // NNTP
   "Transfer-Encoding", "Upgrade", "User-Agent", "Vary", "Via", "Warning", "Www-Authenticate",
-  "Xref",      // NNTP
-  "@DataInfo", // Internal Hack
+  "Xref",          // NNTP
+  "@Ats-Internal", // Internal Hack
 
   // Accept-Encoding
   "compress", "deflate", "gzip", "identity",
@@ -227,7 +227,6 @@ static HdrTokenFieldInfo _hdrtoken_strs_field_initializers[] = {
   {"Warning", MIME_SLOTID_NONE, MIME_PRESENCE_WARNING, (HTIF_COMMAS | HTIF_MULTVALS)},
   {"Www-Authenticate", MIME_SLOTID_WWW_AUTHENTICATE, MIME_PRESENCE_WWW_AUTHENTICATE, HTIF_NONE},
   {"Xref", MIME_SLOTID_NONE, MIME_PRESENCE_XREF, HTIF_NONE},
-  {"@DataInfo", MIME_SLOTID_NONE, MIME_PRESENCE_INT_DATA_INFO, HTIF_NONE},
   {"X-ID", MIME_SLOTID_NONE, MIME_PRESENCE_NONE, (HTIF_COMMAS | HTIF_MULTVALS | HTIF_HOPBYHOP)},
   {"X-Forwarded-For", MIME_SLOTID_NONE, MIME_PRESENCE_NONE, (HTIF_COMMAS | HTIF_MULTVALS)},
   {"Sec-WebSocket-Key", MIME_SLOTID_NONE, MIME_PRESENCE_NONE, HTIF_NONE},
@@ -320,8 +319,8 @@ static const char *_hdrtoken_commonly_tokenized_strs[] = {
   "Subject", // NNTP
   "Summary", // NNTP
   "Transfer-Encoding", "Upgrade", "User-Agent", "Vary", "Via", "Warning", "Www-Authenticate",
-  "Xref",      // NNTP
-  "@DataInfo", // Internal Hack
+  "Xref",          // NNTP
+  "@Ats-Internal", // Internal Hack
 
   // Accept-Encoding
   "compress", "deflate", "gzip", "identity",
diff --git a/proxy/hdrs/MIME.cc b/proxy/hdrs/MIME.cc
index d60feda..b4378e6 100644
--- a/proxy/hdrs/MIME.cc
+++ b/proxy/hdrs/MIME.cc
@@ -145,7 +145,7 @@ const char *MIME_FIELD_VIA;
 const char *MIME_FIELD_WARNING;
 const char *MIME_FIELD_WWW_AUTHENTICATE;
 const char *MIME_FIELD_XREF;
-const char *MIME_FIELD_INT_DATA_INFO;
+const char *MIME_FIELD_ATS_INTERNAL;
 const char *MIME_FIELD_X_ID;
 const char *MIME_FIELD_X_FORWARDED_FOR;
 const char *MIME_FIELD_SEC_WEBSOCKET_KEY;
@@ -260,7 +260,7 @@ int MIME_LEN_VIA;
 int MIME_LEN_WARNING;
 int MIME_LEN_WWW_AUTHENTICATE;
 int MIME_LEN_XREF;
-int MIME_LEN_INT_DATA_INFO;
+int MIME_LEN_ATS_INTERNAL;
 int MIME_LEN_X_ID;
 int MIME_LEN_X_FORWARDED_FOR;
 int MIME_LEN_SEC_WEBSOCKET_KEY;
@@ -338,7 +338,7 @@ int MIME_WKSIDX_VIA;
 int MIME_WKSIDX_WARNING;
 int MIME_WKSIDX_WWW_AUTHENTICATE;
 int MIME_WKSIDX_XREF;
-int MIME_WKSIDX_INT_DATA_INFO;
+int MIME_WKSIDX_ATS_INTERNAL;
 int MIME_WKSIDX_X_ID;
 int MIME_WKSIDX_X_FORWARDED_FOR;
 int MIME_WKSIDX_SEC_WEBSOCKET_KEY;
@@ -712,7 +712,7 @@ mime_init()
     MIME_FIELD_WARNING = hdrtoken_string_to_wks("Warning");
     MIME_FIELD_WWW_AUTHENTICATE = hdrtoken_string_to_wks("Www-Authenticate");
     MIME_FIELD_XREF = hdrtoken_string_to_wks("Xref");
-    MIME_FIELD_INT_DATA_INFO = hdrtoken_string_to_wks("@DataInfo");
+    MIME_FIELD_ATS_INTERNAL = hdrtoken_string_to_wks("@Ats-Internal");
     MIME_FIELD_X_ID = hdrtoken_string_to_wks("X-ID");
     MIME_FIELD_X_FORWARDED_FOR = hdrtoken_string_to_wks("X-Forwarded-For");
 
@@ -793,7 +793,7 @@ mime_init()
     MIME_LEN_WARNING = hdrtoken_wks_to_length(MIME_FIELD_WARNING);
     MIME_LEN_WWW_AUTHENTICATE = hdrtoken_wks_to_length(MIME_FIELD_WWW_AUTHENTICATE);
     MIME_LEN_XREF = hdrtoken_wks_to_length(MIME_FIELD_XREF);
-    MIME_LEN_INT_DATA_INFO = hdrtoken_wks_to_length(MIME_FIELD_INT_DATA_INFO);
+    MIME_LEN_ATS_INTERNAL = hdrtoken_wks_to_length(MIME_FIELD_ATS_INTERNAL);
     MIME_LEN_X_ID = hdrtoken_wks_to_length(MIME_FIELD_X_ID);
     MIME_LEN_X_FORWARDED_FOR = hdrtoken_wks_to_length(MIME_FIELD_X_FORWARDED_FOR);
 
diff --git a/proxy/hdrs/MIME.h b/proxy/hdrs/MIME.h
index 13c64f5..628f013 100644
--- a/proxy/hdrs/MIME.h
+++ b/proxy/hdrs/MIME.h
@@ -382,7 +382,7 @@ extern const char *MIME_FIELD_VIA;
 extern const char *MIME_FIELD_WARNING;
 extern const char *MIME_FIELD_WWW_AUTHENTICATE;
 extern const char *MIME_FIELD_XREF;
-extern const char *MIME_FIELD_INT_DATA_INFO;
+extern const char *MIME_FIELD_ATS_INTERNAL;
 extern const char *MIME_FIELD_X_ID;
 extern const char *MIME_FIELD_X_FORWARDED_FOR;
 extern const char *MIME_FIELD_SEC_WEBSOCKET_KEY;
@@ -485,7 +485,7 @@ extern int MIME_LEN_VIA;
 extern int MIME_LEN_WARNING;
 extern int MIME_LEN_WWW_AUTHENTICATE;
 extern int MIME_LEN_XREF;
-extern int MIME_LEN_INT_DATA_INFO;
+extern int MIME_LEN_ATS_INTERNAL;
 extern int MIME_LEN_X_ID;
 extern int MIME_LEN_X_FORWARDED_FOR;
 
@@ -588,7 +588,7 @@ extern int MIME_WKSIDX_VIA;
 extern int MIME_WKSIDX_WARNING;
 extern int MIME_WKSIDX_WWW_AUTHENTICATE;
 extern int MIME_WKSIDX_XREF;
-extern int MIME_WKSIDX_INT_DATA_INFO;
+extern int MIME_WKSIDX_ATS_INTERNAL;
 extern int MIME_WKSIDX_X_ID;
 extern int MIME_WKSIDX_SEC_WEBSOCKET_KEY;
 extern int MIME_WKSIDX_SEC_WEBSOCKET_VERSION;
diff --git a/proxy/http/HttpConfig.cc b/proxy/http/HttpConfig.cc
index 2f7d66b..d063456 100644
--- a/proxy/http/HttpConfig.cc
+++ b/proxy/http/HttpConfig.cc
@@ -968,7 +968,7 @@ HttpConfig::startup()
                                     "proxy.config.http.transaction_no_activity_timeout_in");
   HttpEstablishStaticConfigLongLong(c.oride.transaction_no_activity_timeout_out,
                                     "proxy.config.http.transaction_no_activity_timeout_out");
-  HttpEstablishStaticConfigLongLong(c.transaction_active_timeout_in, "proxy.config.http.transaction_active_timeout_in");
+  HttpEstablishStaticConfigLongLong(c.oride.transaction_active_timeout_in, "proxy.config.http.transaction_active_timeout_in");
   HttpEstablishStaticConfigLongLong(c.oride.transaction_active_timeout_out, "proxy.config.http.transaction_active_timeout_out");
   HttpEstablishStaticConfigLongLong(c.accept_no_activity_timeout, "proxy.config.http.accept_no_activity_timeout");
 
@@ -982,8 +982,9 @@ HttpConfig::startup()
   HttpEstablishStaticConfigLongLong(c.oride.connect_attempts_rr_retries, "proxy.config.http.connect_attempts_rr_retries");
   HttpEstablishStaticConfigLongLong(c.oride.connect_attempts_timeout, "proxy.config.http.connect_attempts_timeout");
   HttpEstablishStaticConfigLongLong(c.oride.post_connect_attempts_timeout, "proxy.config.http.post_connect_attempts_timeout");
-  HttpEstablishStaticConfigLongLong(c.parent_connect_attempts, "proxy.config.http.parent_proxy.total_connect_attempts");
-  HttpEstablishStaticConfigLongLong(c.per_parent_connect_attempts, "proxy.config.http.parent_proxy.per_parent_connect_attempts");
+  HttpEstablishStaticConfigLongLong(c.oride.parent_connect_attempts, "proxy.config.http.parent_proxy.total_connect_attempts");
+  HttpEstablishStaticConfigLongLong(c.oride.per_parent_connect_attempts,
+                                    "proxy.config.http.parent_proxy.per_parent_connect_attempts");
   HttpEstablishStaticConfigLongLong(c.parent_connect_timeout, "proxy.config.http.parent_proxy.connect_attempts_timeout");
 
   HttpEstablishStaticConfigLongLong(c.oride.sock_recv_buffer_size_out, "proxy.config.net.sock_recv_buffer_size_out");
@@ -1065,6 +1066,7 @@ HttpConfig::startup()
 
   HttpEstablishStaticConfigByte(c.send_100_continue_response, "proxy.config.http.send_100_continue_response");
   HttpEstablishStaticConfigByte(c.send_408_post_timeout_response, "proxy.config.http.send_408_post_timeout_response");
+  HttpEstablishStaticConfigLongLong(c.cache_open_write_fail_action, "proxy.config.http.cache.open_write_fail_action");
   HttpEstablishStaticConfigByte(c.disallow_post_100_continue, "proxy.config.http.disallow_post_100_continue");
   HttpEstablishStaticConfigByte(c.parser_allow_non_http, "proxy.config.http.parse.allow_non_http");
 
@@ -1133,6 +1135,15 @@ HttpConfig::startup()
   HttpEstablishStaticConfigLongLong(c.autoconf_port, "proxy.config.admin.autoconf_port");
   HttpEstablishStaticConfigByte(c.autoconf_localhost_only, "proxy.config.admin.autoconf.localhost_only");
 
+  // parent origin.
+  HttpEstablishStaticConfigLongLong(c.oride.simple_retry_enabled, "proxy.config.http.parent_origin.simple_retry_enabled");
+  HttpEstablishStaticConfigStringAlloc(c.oride.simple_retry_response_codes_string,
+                                       "proxy.config.http.parent_origin.simple_retry_response_codes");
+  HttpEstablishStaticConfigLongLong(c.oride.dead_server_retry_enabled, "proxy.config.http.parent_origin.dead_server_retry_enabled");
+  HttpEstablishStaticConfigStringAlloc(c.oride.dead_server_retry_response_codes_string,
+                                       "proxy.config.http.parent_origin.dead_server_retry_response_codes");
+
+
   // Cluster time delta gets it own callback since it needs
   //  to use ink_atomic_swap
   c.cluster_time_delta = 0;
@@ -1233,7 +1244,7 @@ HttpConfig::reconfigure()
   params->oride.keep_alive_no_activity_timeout_out = m_master.oride.keep_alive_no_activity_timeout_out;
   params->oride.transaction_no_activity_timeout_in = m_master.oride.transaction_no_activity_timeout_in;
   params->oride.transaction_no_activity_timeout_out = m_master.oride.transaction_no_activity_timeout_out;
-  params->transaction_active_timeout_in = m_master.transaction_active_timeout_in;
+  params->oride.transaction_active_timeout_in = m_master.oride.transaction_active_timeout_in;
   params->oride.transaction_active_timeout_out = m_master.oride.transaction_active_timeout_out;
   params->accept_no_activity_timeout = m_master.accept_no_activity_timeout;
   params->oride.background_fill_active_timeout = m_master.oride.background_fill_active_timeout;
@@ -1244,8 +1255,8 @@ HttpConfig::reconfigure()
   params->oride.connect_attempts_rr_retries = m_master.oride.connect_attempts_rr_retries;
   params->oride.connect_attempts_timeout = m_master.oride.connect_attempts_timeout;
   params->oride.post_connect_attempts_timeout = m_master.oride.post_connect_attempts_timeout;
-  params->parent_connect_attempts = m_master.parent_connect_attempts;
-  params->per_parent_connect_attempts = m_master.per_parent_connect_attempts;
+  params->oride.parent_connect_attempts = m_master.oride.parent_connect_attempts;
+  params->oride.per_parent_connect_attempts = m_master.oride.per_parent_connect_attempts;
   params->parent_connect_timeout = m_master.parent_connect_timeout;
 
   params->oride.sock_recv_buffer_size_out = m_master.oride.sock_recv_buffer_size_out;
@@ -1324,6 +1335,7 @@ HttpConfig::reconfigure()
 
   params->send_100_continue_response = INT_TO_BOOL(m_master.send_100_continue_response);
   params->send_408_post_timeout_response = INT_TO_BOOL(m_master.send_408_post_timeout_response);
+  params->cache_open_write_fail_action = m_master.cache_open_write_fail_action;
   params->disallow_post_100_continue = INT_TO_BOOL(m_master.disallow_post_100_continue);
   params->parser_allow_non_http = INT_TO_BOOL(m_master.parser_allow_non_http);
 
@@ -1335,6 +1347,7 @@ HttpConfig::reconfigure()
 
   params->connect_ports_string = ats_strdup(m_master.connect_ports_string);
   params->connect_ports = parse_ports_list(params->connect_ports_string);
+  params->response_codes = new ResponseCodes();
 
   params->oride.request_hdr_max_size = m_master.oride.request_hdr_max_size;
   params->oride.response_hdr_max_size = m_master.oride.response_hdr_max_size;
@@ -1387,6 +1400,11 @@ HttpConfig::reconfigure()
   // Local Manager
   params->autoconf_port = m_master.autoconf_port;
   params->autoconf_localhost_only = m_master.autoconf_localhost_only;
+  params->oride.simple_retry_enabled = m_master.oride.simple_retry_enabled;
+  params->oride.dead_server_retry_enabled = m_master.oride.dead_server_retry_enabled;
+  params->oride.simple_retry_response_codes_string = m_master.oride.simple_retry_response_codes_string;
+  params->oride.dead_server_retry_response_codes_string = m_master.oride.dead_server_retry_response_codes_string;
+  params->oride.url_remap_required = m_master.oride.url_remap_required;
 
   m_id = configProcessor.set(m_id, params);
 
@@ -1496,6 +1514,27 @@ HttpConfig::parse_ports_list(char *ports_string)
   return (ports_list);
 }
 
+///////////////////////////////////////////////////////
+// ResponseCodes implementation.
+// ///////////////////////////////////////////////////
+bool
+ResponseCodes::contains(int code, MgmtString r_codes)
+{
+  char *c = r_codes, *p = NULL;
+
+  do {
+    if (atoi(c) == code) {
+      return true;
+    }
+    p = strchr(c, ',');
+    if (p != NULL) {
+      c = (p + 1);
+    }
+  } while (p != NULL);
+
+  return false;
+}
+
 ////////////////////////////////////////////////////////////////
 //
 //  HttpConfig::parse_url_expansions()
diff --git a/proxy/http/HttpConfig.h b/proxy/http/HttpConfig.h
index 0bab35f..099c215 100644
--- a/proxy/http/HttpConfig.h
+++ b/proxy/http/HttpConfig.h
@@ -331,6 +331,17 @@ struct HttpConfigPortRange {
   }
 };
 
+//////////////////////////////////////////////////////////////
+// Container for simple retry and dead server retry http
+// response codes.
+/////////////////////////////////////////////////////////////
+class ResponseCodes
+{
+public:
+  ResponseCodes(){};
+  bool contains(int, MgmtString);
+};
+
 /////////////////////////////////////////////////////////////
 // This is a little helper class, used by the HttpConfigParams
 // and State (txn) structure. It allows for certain configs
@@ -355,16 +366,17 @@ struct OverridableHttpConfigParams {
       cache_heuristic_min_lifetime(3600), cache_heuristic_max_lifetime(86400), cache_guaranteed_min_lifetime(0),
       cache_guaranteed_max_lifetime(31536000), cache_max_stale_age(604800), keep_alive_no_activity_timeout_in(115),
       keep_alive_no_activity_timeout_out(120), transaction_no_activity_timeout_in(30), transaction_no_activity_timeout_out(30),
-      transaction_active_timeout_out(0), origin_max_connections(0), connect_attempts_max_retries(0),
-      connect_attempts_max_retries_dead_server(3), connect_attempts_rr_retries(3), connect_attempts_timeout(30),
-      post_connect_attempts_timeout(1800), down_server_timeout(300), client_abort_threshold(10), freshness_fuzz_time(240),
-      freshness_fuzz_min_time(0), max_cache_open_read_retries(-1), cache_open_read_retry_time(10),
+      transaction_active_timeout_in(900), transaction_active_timeout_out(0), origin_max_connections(0),
+      connect_attempts_max_retries(0), connect_attempts_max_retries_dead_server(3), connect_attempts_rr_retries(3),
+      connect_attempts_timeout(30), post_connect_attempts_timeout(1800), down_server_timeout(300), client_abort_threshold(10),
+      freshness_fuzz_time(240), freshness_fuzz_min_time(0), max_cache_open_read_retries(-1), cache_open_read_retry_time(10),
       background_fill_active_timeout(60), http_chunking_size(4096), flow_high_water_mark(0), flow_low_water_mark(0),
-      default_buffer_size_index(8), default_buffer_water_mark(32768),
-
+      default_buffer_size_index(8), default_buffer_water_mark(32768), parent_connect_attempts(4), per_parent_connect_attempts(2),
+      simple_retry_enabled(0), dead_server_retry_enabled(0), url_remap_required(1),
       // Strings / floats must come last
       proxy_response_server_string(NULL), proxy_response_server_string_len(0), global_user_agent_header(NULL),
-      global_user_agent_header_size(0), cache_heuristic_lm_factor(0.10), freshness_fuzz_prob(0.005), background_fill_threshold(0.5)
+      global_user_agent_header_size(0), cache_heuristic_lm_factor(0.10), freshness_fuzz_prob(0.005), background_fill_threshold(0.5),
+      simple_retry_response_codes_string(NULL), dead_server_retry_response_codes_string(NULL)
   {
   }
 
@@ -502,6 +514,7 @@ struct OverridableHttpConfigParams {
   MgmtInt keep_alive_no_activity_timeout_out;
   MgmtInt transaction_no_activity_timeout_in;
   MgmtInt transaction_no_activity_timeout_out;
+  MgmtInt transaction_active_timeout_in;
   MgmtInt transaction_active_timeout_out;
   MgmtInt origin_max_connections;
 
@@ -533,6 +546,23 @@ struct OverridableHttpConfigParams {
   MgmtInt default_buffer_size_index;
   MgmtInt default_buffer_water_mark;
 
+  ////////////////////////////////////
+  // origin server connect attempts //
+  ////////////////////////////////////
+  MgmtInt parent_connect_attempts;
+  MgmtInt per_parent_connect_attempts;
+
+  ///////////////////////////////////////////////////
+  // parent origin server load balancing variables //
+  ///////////////////////////////////////////////////
+  MgmtInt simple_retry_enabled;
+  MgmtInt dead_server_retry_enabled;
+
+  //////////////////////////////////
+  // reverse proxy overridables   //
+  /////////////////////////////////
+  MgmtByte url_remap_required;
+
   // IMPORTANT: Here comes all strings / floats configs.
 
   ///////////////////////////////////////////////////////////////////
@@ -550,6 +580,8 @@ struct OverridableHttpConfigParams {
   MgmtFloat cache_heuristic_lm_factor;
   MgmtFloat freshness_fuzz_prob;
   MgmtFloat background_fill_threshold;
+  MgmtString simple_retry_response_codes_string;
+  MgmtString dead_server_retry_response_codes_string;
 };
 
 
@@ -615,14 +647,11 @@ public:
   // connection variables. timeouts are in seconds //
   ///////////////////////////////////////////////////
   MgmtByte session_auth_cache_keep_alive_enabled;
-  MgmtInt transaction_active_timeout_in;
   MgmtInt accept_no_activity_timeout;
 
   ////////////////////////////////////
-  // origin server connect attempts //
+  // origin server connect timeout  //
   ////////////////////////////////////
-  MgmtInt parent_connect_attempts;
-  MgmtInt per_parent_connect_attempts;
   MgmtInt parent_connect_timeout;
 
   ///////////////////////////////////////////////////////////////////
@@ -657,7 +686,11 @@ public:
   char *connect_ports_string;
   HttpConfigPortRange *connect_ports;
 
-  //////////
+  /////////////////////////////////////////////////////////
+  // simple retry and dead server retry response codes. //
+  ///////////////////////////////////////////////////////
+  ResponseCodes *response_codes;
+
   // Push //
   //////////
   MgmtByte push_method_enabled;
@@ -719,6 +752,7 @@ public:
 
   MgmtByte send_100_continue_response;
   MgmtByte send_408_post_timeout_response;
+  MgmtInt cache_open_write_fail_action;
   MgmtByte disallow_post_100_continue;
   MgmtByte parser_allow_non_http;
 
@@ -821,15 +855,15 @@ inline HttpConfigParams::HttpConfigParams()
     uncacheable_requests_bypass_parent(1), no_origin_server_dns(0), use_client_target_addr(0), use_client_source_port(0),
     proxy_request_via_string(NULL), proxy_request_via_string_len(0), proxy_response_via_string(NULL),
     proxy_response_via_string_len(0), url_expansions_string(NULL), url_expansions(NULL), num_url_expansions(0),
-    session_auth_cache_keep_alive_enabled(1), transaction_active_timeout_in(900), accept_no_activity_timeout(120),
-    parent_connect_attempts(4), per_parent_connect_attempts(2), parent_connect_timeout(30), anonymize_other_header_list(NULL),
-    enable_http_stats(1), icp_enabled(0), stale_icp_enabled(0), cache_vary_default_text(NULL), cache_vary_default_images(NULL),
-    cache_vary_default_other(NULL), max_cache_open_write_retries(1), cache_enable_default_vary_headers(0), cache_post_method(0),
-    connect_ports_string(NULL), connect_ports(NULL), push_method_enabled(0), referer_filter_enabled(0), referer_format_redirect(0),
-    reverse_proxy_enabled(0), url_remap_required(1), record_cop_page(0), errors_log_error_pages(1), enable_http_info(0),
-    cluster_time_delta(0), redirection_enabled(0), redirection_host_no_port(0), number_of_redirections(1), post_copy_size(2048),
-    ignore_accept_mismatch(0), ignore_accept_language_mismatch(0), ignore_accept_encoding_mismatch(0),
-    ignore_accept_charset_mismatch(0), send_100_continue_response(0), send_408_post_timeout_response(0),
+    session_auth_cache_keep_alive_enabled(1), accept_no_activity_timeout(120), parent_connect_timeout(30),
+    anonymize_other_header_list(NULL), enable_http_stats(1), icp_enabled(0), stale_icp_enabled(0), cache_vary_default_text(NULL),
+    cache_vary_default_images(NULL), cache_vary_default_other(NULL), max_cache_open_write_retries(1),
+    cache_enable_default_vary_headers(0), cache_post_method(0), connect_ports_string(NULL), connect_ports(NULL),
+    push_method_enabled(0), referer_filter_enabled(0), referer_format_redirect(0), reverse_proxy_enabled(0), url_remap_required(1),
+    record_cop_page(0), errors_log_error_pages(1), enable_http_info(0), cluster_time_delta(0), redirection_enabled(0),
+    redirection_host_no_port(0), number_of_redirections(1), post_copy_size(2048), ignore_accept_mismatch(0),
+    ignore_accept_language_mismatch(0), ignore_accept_encoding_mismatch(0), ignore_accept_charset_mismatch(0),
+    send_100_continue_response(0), send_408_post_timeout_response(0), cache_open_write_fail_action(0),
     disallow_post_100_continue(0), parser_allow_non_http(1), autoconf_port(0), autoconf_localhost_only(0)
 {
 }
diff --git a/proxy/http/HttpSM.cc b/proxy/http/HttpSM.cc
index 9a91206..2fc20b5 100644
--- a/proxy/http/HttpSM.cc
+++ b/proxy/http/HttpSM.cc
@@ -574,7 +574,6 @@ HttpSM::attach_client_session(HttpClientSession *client_vc, IOBufferReader *buff
   // set up timeouts     //
   /////////////////////////
   client_vc->get_netvc()->set_inactivity_timeout(HRTIME_SECONDS(HttpConfig::m_master.accept_no_activity_timeout));
-  client_vc->get_netvc()->set_active_timeout(HRTIME_SECONDS(HttpConfig::m_master.transaction_active_timeout_in));
 
   ++reentrancy_count;
   // Add our state sm to the sm list
@@ -596,6 +595,11 @@ HttpSM::setup_client_read_request_header()
 {
   ink_assert(ua_entry->vc_handler == &HttpSM::state_read_client_request_header);
 
+  /////////////////////////
+  // set up timeouts     //
+  /////////////////////////
+  ua_session->get_netvc()->set_active_timeout(HRTIME_SECONDS(t_state.txn_conf->transaction_active_timeout_in));
+
   ua_entry->read_vio = ua_session->do_io_read(this, INT64_MAX, ua_buffer_reader->mbuf);
   // The header may already be in the buffer if this
   //  a request from a keep-alive connection
@@ -2385,9 +2389,19 @@ HttpSM::state_cache_open_write(int event, void *data)
   case CACHE_EVENT_OPEN_WRITE_FAILED:
     // Failed on the write lock and retrying the vector
     //  for reading
-    t_state.cache_info.write_lock_state = HttpTransact::CACHE_WL_FAIL;
-    break;
-
+    if (t_state.http_config_param->cache_open_write_fail_action == HttpTransact::CACHE_OPEN_WRITE_FAIL_DEFAULT) {
+      t_state.cache_info.write_lock_state = HttpTransact::CACHE_WL_FAIL;
+      break;
+    } else {
+      t_state.cache_open_write_fail_action = t_state.http_config_param->cache_open_write_fail_action;
+      if (!t_state.cache_info.object_read) {
+        // cache miss, set wl_state to fail
+        t_state.cache_info.write_lock_state = HttpTransact::CACHE_WL_FAIL;
+        break;
+      }
+    }
+  // INTENTIONAL FALL THROUGH
+  // Allow for stale object to be served
   case CACHE_EVENT_OPEN_READ:
     // The write vector was locked and the cache_sm retried
     // and got the read vector again.
@@ -4245,7 +4259,7 @@ HttpSM::parse_range_and_compare(MIMEField *field, int64_t content_length)
     ranges[nr]._end = end;
     ++nr;
 
-    if (!cache_sm.cache_read_vc->is_pread_capable() && cache_config_read_while_writer == 2) {
+    if (!cache_sm.cache_read_vc->is_pread_capable()) {
       // write in progress, check if request range not in cache yet
       HTTPInfo::FragOffset *frag_offset_tbl = t_state.cache_info.object_read->get_frag_table();
       int frag_offset_cnt = t_state.cache_info.object_read->get_frag_offset_count();
@@ -4346,8 +4360,9 @@ HttpSM::do_range_setup_if_necessary()
       }
 
       // if only one range entry and pread is capable, no need transform range
-      if (t_state.num_range_fields == 1 && cache_sm.cache_read_vc->is_pread_capable()) {
+      if (t_state.num_range_fields == 1) {
         t_state.range_setup = HttpTransact::RANGE_NOT_TRANSFORM_REQUESTED;
+        Debug("http_range", "range in cache, accelerated range request.");
       } else if (api_hooks.get(TS_HTTP_RESPONSE_TRANSFORM_HOOK) == NULL) {
         Debug("http_trans", "Unable to accelerate range request, fallback to transform");
         content_type = t_state.cache_info.object_read->response_get()->value_get(MIME_FIELD_CONTENT_TYPE, MIME_LEN_CONTENT_TYPE,
@@ -6656,17 +6671,6 @@ HttpSM::update_stats()
     os_read_time = -1;
   }
 
-// TS-2032: This code is never used, but leaving it here in case we want to add these
-// to the metrics code.
-#if 0
-  ink_hrtime cache_lookup_time;
-  if (milestones.cache_open_read_end != 0 && milestones.cache_open_read_begin != 0) {
-    cache_lookup_time = milestones.cache_open_read_end - milestones.cache_open_read_begin;
-  } else {
-    cache_lookup_time = -1;
-  }
-#endif
-
   HttpTransact::update_size_and_time_stats(&t_state, total_time, ua_write_time, os_read_time, client_request_hdr_bytes,
                                            client_request_body_bytes, client_response_hdr_bytes, client_response_body_bytes,
                                            server_request_hdr_bytes, server_request_body_bytes, server_response_hdr_bytes,
diff --git a/proxy/http/HttpTransact.cc b/proxy/http/HttpTransact.cc
index 42ac8f7..b734a7d 100644
--- a/proxy/http/HttpTransact.cc
+++ b/proxy/http/HttpTransact.cc
@@ -209,6 +209,7 @@ find_server_and_update_current_info(HttpTransact::State *s)
   int host_len;
   const char *host = s->hdr_info.client_request.host_get(&host_len);
 
+  DebugTxn("http_trans", "starting find_server_adn_update_current_info()");
   if (ptr_len_cmp(host, host_len, local_host_ip_str, sizeof(local_host_ip_str) - 1) == 0) {
     // Do not forward requests to local_host onto a parent.
     // I just wanted to do this for cop heartbeats, someone else
@@ -230,8 +231,15 @@ find_server_and_update_current_info(HttpTransact::State *s)
     switch (s->parent_result.r) {
     case PARENT_UNDEFINED:
       s->parent_params->findParent(&s->request_data, &s->parent_result);
+      if (s->parent_result.rec != NULL) {
+        // check to see if the parent is an origin server.
+        if (!s->parent_result.rec->isParentProxy()) {
+          s->parent_result.r = PARENT_ORIGIN;
+        }
+      }
       break;
     case PARENT_SPECIFIED:
+    case PARENT_ORIGIN:
       s->parent_params->nextParent(&s->request_data, &s->parent_result);
 
       // Hack!
@@ -266,6 +274,7 @@ find_server_and_update_current_info(HttpTransact::State *s)
   }
 
   switch (s->parent_result.r) {
+  case PARENT_ORIGIN:
   case PARENT_SPECIFIED:
     s->parent_info.name = s->arena.str_store(s->parent_result.hostname, strlen(s->parent_result.hostname));
     s->parent_info.port = s->parent_result.port;
@@ -273,8 +282,8 @@ find_server_and_update_current_info(HttpTransact::State *s)
     update_dns_info(&s->dns_info, &s->current, 0, &s->arena);
     ink_assert(s->dns_info.looking_up == HttpTransact::PARENT_PROXY);
     s->next_hop_scheme = URL_WKSIDX_HTTP;
-
     return HttpTransact::PARENT_PROXY;
+
   case PARENT_FAIL:
     // No more parents - need to return an error message
     s->current.request_to = HttpTransact::HOST_NONE;
@@ -414,7 +423,7 @@ how_to_open_connection(HttpTransact::State *s)
     break;
   }
 
-  if (s->method == HTTP_WKSIDX_CONNECT && s->parent_result.r != PARENT_SPECIFIED) {
+  if (s->method == HTTP_WKSIDX_CONNECT && (s->parent_result.r != PARENT_SPECIFIED || s->parent_result.r != PARENT_ORIGIN)) {
     s->cdn_saved_next_action = HttpTransact::SM_ACTION_ORIGIN_SERVER_RAW_OPEN;
   } else {
     s->cdn_saved_next_action = HttpTransact::SM_ACTION_ORIGIN_SERVER_OPEN;
@@ -2773,7 +2782,8 @@ HttpTransact::build_response_from_cache(State *s, HTTPWarningCode warning_code)
   // the function match_response_to_request_conditionals() returns
   // the code of the cached response, which means that we should send
   // back the full document.
-  HTTPStatus client_response_code = HttpTransactCache::match_response_to_request_conditionals(client_request, cached_response);
+  HTTPStatus client_response_code =
+    HttpTransactCache::match_response_to_request_conditionals(client_request, cached_response, s->response_received_time);
 
   switch (client_response_code) {
   case HTTP_STATUS_NOT_MODIFIED:
@@ -2902,8 +2912,30 @@ HttpTransact::handle_cache_write_lock(State *s)
     // No write lock, ignore the cache and proxy only;
     // FIX: Should just serve from cache if this is a revalidate
     s->cache_info.action = CACHE_DO_NO_ACTION;
-    s->cache_info.write_status = CACHE_WRITE_LOCK_MISS;
-    remove_ims = true;
+    if (s->cache_open_write_fail_action & CACHE_OPEN_WRITE_FAIL_ERROR_ON_MISS) {
+      DebugTxn("http_error", "cache_open_write_fail_action, cache miss, return error");
+      s->cache_info.write_status = CACHE_WRITE_ERROR;
+      build_error_response(s, HTTP_STATUS_BAD_GATEWAY, "Connection Failed", "connect#failed_connect", NULL);
+      MIMEField *ats_field;
+      HTTPHdr *header = &(s->hdr_info.client_response);
+
+      if ((ats_field = header->field_find(MIME_FIELD_ATS_INTERNAL, MIME_LEN_ATS_INTERNAL)) == NULL) {
+        if (likely((ats_field = header->field_create(MIME_FIELD_ATS_INTERNAL, MIME_LEN_ATS_INTERNAL)) != NULL))
+          header->field_attach(ats_field);
+      }
+      if (likely(ats_field)) {
+        Debug("http_error", "Adding Ats-Internal-Messages: %d", CACHE_WL_FAIL);
+        header->field_value_set_int(ats_field, CACHE_WL_FAIL);
+      } else {
+        Debug("http_error", "failed to add Ats-Internal-Messages: %d", CACHE_WL_FAIL);
+      }
+
+      TRANSACT_RETURN(SM_ACTION_SEND_ERROR_CACHE_NOOP, NULL);
+      return;
+    } else {
+      s->cache_info.write_status = CACHE_WRITE_LOCK_MISS;
+      remove_ims = true;
+    }
     break;
   case CACHE_WL_READ_RETRY:
     //  Write failed but retried and got a vector to read
@@ -3473,23 +3505,49 @@ HttpTransact::handle_response_from_parent(State *s)
       return;
     }
 
-    if (s->current.attempts < s->http_config_param->parent_connect_attempts) {
+    // try a simple retry if we received a simple retryable response from the parent.
+    if (s->current.retry_type == SIMPLE_RETRY || s->current.retry_type == DEAD_SERVER_RETRY) {
+      if (s->current.retry_type == SIMPLE_RETRY) {
+        if (s->current.simple_retry_attempts >= s->parent_result.rec->num_parents - 1) {
+          DebugTxn("http_trans", "SIMPLE_RETRY: retried all parents, send error to client.\n");
+        } else {
+          s->current.simple_retry_attempts++;
+          DebugTxn("http_trans", "SIMPLE_RETRY: try another parent.\n");
+          next_lookup = find_server_and_update_current_info(s);
+        }
+      } else { // DEAD_SERVER_RETRY
+        if (s->current.dead_server_retry_attempts >= s->parent_result.rec->num_parents - 1) {
+          DebugTxn("http_trans", "DEAD_SERVER_RETRY: retried all parents, send error to client.\n");
+        } else {
+          s->current.dead_server_retry_attempts++;
+          DebugTxn("http_trans", "DEAD_SERVER_RETRY: marking parent down and trying another.\n");
+          s->parent_params->markParentDown(&s->parent_result);
+          next_lookup = find_server_and_update_current_info(s);
+        }
+      }
+    }
+    // parent_connect_attempts is set from proxy.config.http.parent_proxy.total_connect_attempts in
+    // records.config.
+    else if (s->current.attempts < s->txn_conf->parent_connect_attempts) {
       s->current.attempts++;
 
       // Are we done with this particular parent?
-      if ((s->current.attempts - 1) % s->http_config_param->per_parent_connect_attempts != 0) {
+      // per_parent_connect_attempts should be less than proxy.config.http.parent_proxy.total_connect_attempts
+      // so that a new parent is tried.
+      if ((s->current.attempts - 1) % s->txn_conf->per_parent_connect_attempts != 0) {
         // No we are not done with this parent so retry
         s->next_action = how_to_open_connection(s);
         DebugTxn("http_trans", "%s Retrying parent for attempt %d, max %" PRId64, "[handle_response_from_parent]",
-                 s->current.attempts, s->http_config_param->per_parent_connect_attempts);
+                 s->current.attempts, s->txn_conf->per_parent_connect_attempts);
         return;
       } else {
-        DebugTxn("http_trans", "%s %d per parent attempts exhausted", "[handle_response_from_parent]", s->current.attempts);
+        DebugTxn("http_trans", "%s %d per parent attempts exhausted, s->current.state: %d", "[handle_response_from_parent]",
+                 s->current.attempts, s->current.state);
 
         // Only mark the parent down if we failed to connect
         //  to the parent otherwise slow origin servers cause
         //  us to mark the parent down
-        if (s->current.state == CONNECTION_ERROR) {
+        if (s->current.state != ACTIVE_TIMEOUT && s->current.state != CONNECTION_ALIVE && s->current.state != CONNECTION_CLOSED) {
           s->parent_params->markParentDown(&s->parent_result);
         }
         // We are done so look for another parent if any
@@ -4064,8 +4122,8 @@ HttpTransact::handle_cache_operation_on_forward_server_response(State *s)
       client_response_code = base_response->status_get();
     } else if ((s->cache_info.action == CACHE_DO_DELETE) || ((s->cache_info.action == CACHE_DO_UPDATE) && !cacheable)) {
       if (is_request_conditional(&s->hdr_info.client_request)) {
-        client_response_code = HttpTransactCache::match_response_to_request_conditionals(&s->hdr_info.client_request,
-                                                                                         s->cache_info.object_read->response_get());
+        client_response_code = HttpTransactCache::match_response_to_request_conditionals(
+          &s->hdr_info.client_request, s->cache_info.object_read->response_get(), s->response_received_time);
       } else {
         client_response_code = HTTP_STATUS_OK;
       }
@@ -4098,7 +4156,7 @@ HttpTransact::handle_cache_operation_on_forward_server_response(State *s)
       if (is_request_conditional(&s->hdr_info.client_request)) {
         if (s->txn_conf->cache_when_to_revalidate != 4)
           client_response_code = HttpTransactCache::match_response_to_request_conditionals(
-            &s->hdr_info.client_request, s->cache_info.object_read->response_get());
+            &s->hdr_info.client_request, s->cache_info.object_read->response_get(), s->response_received_time);
         else
           client_response_code = server_response_code;
       } else {
@@ -4216,8 +4274,9 @@ HttpTransact::handle_cache_operation_on_forward_server_response(State *s)
       base_response->unset_cooked_cc_need_revalidate_once();
 
       if (is_request_conditional(&s->hdr_info.client_request) &&
-          HttpTransactCache::match_response_to_request_conditionals(
-            &s->hdr_info.client_request, s->cache_info.object_read->response_get()) == HTTP_STATUS_NOT_MODIFIED) {
+          HttpTransactCache::match_response_to_request_conditionals(&s->hdr_info.client_request,
+                                                                    s->cache_info.object_read->response_get(),
+                                                                    s->response_received_time) == HTTP_STATUS_NOT_MODIFIED) {
         s->next_action = SM_ACTION_INTERNAL_CACHE_UPDATE_HEADERS;
         client_response_code = HTTP_STATUS_NOT_MODIFIED;
       } else {
@@ -4330,8 +4389,8 @@ HttpTransact::handle_cache_operation_on_forward_server_response(State *s)
           resp->set_expires(exp_time);
         }
       } else if (is_request_conditional(&s->hdr_info.client_request) && server_response_code == HTTP_STATUS_OK) {
-        client_response_code =
-          HttpTransactCache::match_response_to_request_conditionals(&s->hdr_info.client_request, &s->hdr_info.server_response);
+        client_response_code = HttpTransactCache::match_response_to_request_conditionals(
+          &s->hdr_info.client_request, &s->hdr_info.server_response, s->response_received_time);
 
         DebugTxn("http_trans", "[hcoofsr] conditional request, 200 "
                                "response, send back 304 if possible [crc=%d]",
@@ -6351,6 +6410,8 @@ HttpTransact::is_request_retryable(State *s)
 bool
 HttpTransact::is_response_valid(State *s, HTTPHdr *incoming_response)
 {
+  int server_response = 0;
+
   if (s->current.state != CONNECTION_ALIVE) {
     ink_assert((s->current.state == CONNECTION_ERROR) || (s->current.state == OPEN_RAW_ERROR) ||
                (s->current.state == PARSE_ERROR) || (s->current.state == CONNECTION_CLOSED) ||
@@ -6361,6 +6422,40 @@ HttpTransact::is_response_valid(State *s, HTTPHdr *incoming_response)
     return false;
   }
 
+  // is this response is from a load balanced parent.
+  if (s->current.request_to == PARENT_PROXY && s->parent_result.r == PARENT_ORIGIN) {
+    server_response = http_hdr_status_get(s->hdr_info.server_response.m_http);
+    DebugTxn("http_trans", "[is_response_valid] server_response = %d\n", server_response);
+    // is a simple retry required.
+    if (s->txn_conf->simple_retry_enabled && (s->current.simple_retry_attempts < s->parent_result.rec->num_parents - 1) &&
+        s->http_config_param->response_codes->contains(server_response, s->txn_conf->simple_retry_response_codes_string)) {
+      DebugTxn("parent_select", "GOT A SIMPLE RETRY RESPONSE");
+      // initiate a retry if we have not already tried all parents, otherwise the response is sent to the client as is.
+      // see SIMPLE_RETRY in handle_response_from_parent().
+      if (s->current.simple_retry_attempts < s->parent_result.rec->num_parents) {
+        s->current.state = BAD_INCOMING_RESPONSE;
+        s->current.retry_type = SIMPLE_RETRY;
+      } else {
+        DebugTxn("http_trans", "SIMPLE_RETRY: retried all parents, send error to client.\n");
+      }
+    }
+    // is a dead server retry required.
+    else if (s->txn_conf->dead_server_retry_enabled &&
+             (s->current.dead_server_retry_attempts < s->parent_result.rec->num_parents - 1) &&
+             s->http_config_param->response_codes->contains(server_response,
+                                                            s->txn_conf->dead_server_retry_response_codes_string)) {
+      DebugTxn("parent_select", "GOT A DEAD_SERVER RETRY RESPONSE");
+      // initiate a dead server retry if we have not already tried all parents, otherwise the response is sent to the client as is.
+      // see DEAD_SERVER_RETRY in handle_response_from_parent().
+      if (s->current.dead_server_retry_attempts < s->parent_result.rec->num_parents) {
+        s->current.state = BAD_INCOMING_RESPONSE;
+        s->current.retry_type = DEAD_SERVER_RETRY;
+      } else {
+        DebugTxn("http_trans", "DEAD_SERVER_RETRY: retried all parents, send error to client.\n");
+      }
+    }
+  }
+
   s->hdr_info.response_error = check_response_validity(s, incoming_response);
 
   switch (s->hdr_info.response_error) {
@@ -7221,6 +7316,13 @@ HttpTransact::what_is_document_freshness(State *s, HTTPHdr *client_request, HTTP
   uint32_t cc_mask, cooked_cc_mask;
   uint32_t os_specifies_revalidate;
 
+  if (s->cache_open_write_fail_action & CACHE_OPEN_WRITE_FAIL_STALE_OR_REVALIDATE) {
+    if (is_stale_cache_response_returnable(s)) {
+      DebugTxn("http_match", "[what_is_document_freshness] cache_serve_stale_on_write_lock_fail, return FRESH");
+      return (FRESHNESS_FRESH);
+    }
+  }
+
   //////////////////////////////////////////////////////
   // If config file has a ttl-in-cache field set,     //
   // it has priority over any other http headers and  //
@@ -7705,6 +7807,13 @@ HttpTransact::build_request(State *s, HTTPHdr *base_request, HTTPHdr *outgoing_r
     // don't have a host anywhere.
     outgoing_request->set_url_target_from_host_field();
   }
+  // In this case, the parent is actually the origin.  We utilized parent selection
+  // to pick a load balanced origin server using round robin, or consistent hash.
+  else if (s->current.request_to == PARENT_PROXY && !s->parent_result.rec->isParentProxy() &&
+           outgoing_request->is_target_in_url()) {
+    DebugTxn("http_trans", "[build_request] removing target from URL for parent origin");
+    HttpTransactHeaders::remove_host_name_from_url(outgoing_request);
+  }
 
   // If the response is most likely not cacheable, eg, request with Authorization,
   // do we really want to remove conditional headers to get large 200 response?
diff --git a/proxy/http/HttpTransact.h b/proxy/http/HttpTransact.h
index e598951..eb56a56 100644
--- a/proxy/http/HttpTransact.h
+++ b/proxy/http/HttpTransact.h
@@ -301,6 +301,13 @@ public:
     TOTAL_CACHE_ACTION_TYPES
   };
 
+  enum CacheOpenWriteFailAction_t {
+    CACHE_OPEN_WRITE_FAIL_DEFAULT = 0,
+    CACHE_OPEN_WRITE_FAIL_ERROR_ON_MISS = 1,
+    CACHE_OPEN_WRITE_FAIL_STALE_OR_REVALIDATE = 2,
+    TOTAL_OPEN_WRITE_FAIL_ACTION_TYPES
+  };
+
   enum CacheWriteLock_t {
     CACHE_WL_INIT,
     CACHE_WL_SUCCESS,
@@ -343,6 +350,8 @@ public:
     HTTP_TRANSACT_MAGIC_SEPARATOR = 0x12345678
   };
 
+  enum ParentOriginRetry_t { UNDEFINED_RETRY, SIMPLE_RETRY, DEAD_SERVER_RETRY };
+
   enum LookingUp_t {
     ORIGIN_SERVER,
     UNDEFINED_LOOKUP,
@@ -698,9 +707,13 @@ public:
     ink_time_t now;
     ServerState_t state;
     int attempts;
+    int simple_retry_attempts;
+    int dead_server_retry_attempts;
+    ParentOriginRetry_t retry_type;
 
     _CurrentInfo()
-      : mode(UNDEFINED_MODE), request_to(UNDEFINED_LOOKUP), server(NULL), now(0), state(STATE_UNDEFINED), attempts(1){};
+      : mode(UNDEFINED_MODE), request_to(UNDEFINED_LOOKUP), server(NULL), now(0), state(STATE_UNDEFINED), attempts(1),
+        simple_retry_attempts(0), dead_server_retry_attempts(0), retry_type(UNDEFINED_RETRY){};
   } CurrentInfo;
 
   typedef struct _DNSLookupInfo {
@@ -796,6 +809,7 @@ public:
     DNSLookupInfo dns_info;
     RedirectInfo redirect_info;
     unsigned int updated_server_version;
+    unsigned int cache_open_write_fail_action;
     bool is_revalidation_necessary; // Added to check if revalidation is necessary - YTS Team, yamsat
     bool request_will_not_selfloop; // To determine if process done - YTS Team, yamsat
     ConnectionAttributes client_info;
@@ -960,8 +974,8 @@ public:
     // Constructor
     State()
       : m_magic(HTTP_TRANSACT_MAGIC_ALIVE), state_machine(NULL), http_config_param(NULL), force_dns(false),
-        updated_server_version(HostDBApplicationInfo::HTTP_VERSION_UNDEFINED), is_revalidation_necessary(false),
-        request_will_not_selfloop(false), // YTS Team, yamsat
+        updated_server_version(HostDBApplicationInfo::HTTP_VERSION_UNDEFINED), cache_open_write_fail_action(0),
+        is_revalidation_necessary(false), request_will_not_selfloop(false), // YTS Team, yamsat
         source(SOURCE_NONE), pre_transform_source(SOURCE_NONE), req_flavor(REQ_FLAVOR_FWDPROXY), pending_work(NULL),
         cdn_saved_next_action(SM_ACTION_UNDEFINED), cdn_saved_transact_return_point(NULL), cdn_remap_complete(false),
         first_dns_lookup(true), parent_params(NULL), cache_lookup_result(CACHE_LOOKUP_NONE), backdoor_request(false),
diff --git a/proxy/http/HttpTransactCache.cc b/proxy/http/HttpTransactCache.cc
index 7b3eebc..f3da2b1 100644
--- a/proxy/http/HttpTransactCache.cc
+++ b/proxy/http/HttpTransactCache.cc
@@ -1278,7 +1278,7 @@ HttpTransactCache::CalcVariability(CacheLookupHttpConfig *http_config_params, HT
 
 */
 HTTPStatus
-HttpTransactCache::match_response_to_request_conditionals(HTTPHdr *request, HTTPHdr *response)
+HttpTransactCache::match_response_to_request_conditionals(HTTPHdr *request, HTTPHdr *response, ink_time_t response_received_time)
 {
   HTTPStatus response_code = HTTP_STATUS_NONE;
 
@@ -1291,23 +1291,38 @@ HttpTransactCache::match_response_to_request_conditionals(HTTPHdr *request, HTTP
                           MIME_PRESENCE_IF_MATCH | MIME_PRESENCE_RANGE))) {
     return response->status_get();
   }
-  // return NOT_MODIFIED only if both If-modified-since and If-none-match fail
 
   // If-Modified-Since //
   if (request->presence(MIME_PRESENCE_IF_MODIFIED_SINCE)) {
-    // lm_value is zero if Last-modified not exists
-    ink_time_t lm_value = response->get_last_modified();
+    if (response->presence(MIME_PRESENCE_LAST_MODIFIED)) {
+      // lm_value is zero if Last-modified not exists
+      ink_time_t lm_value = response->get_last_modified();
+
+      // we won't return NOT_MODIFIED if Last-modified is too recent
+      if ((lm_value == 0) || (request->get_if_modified_since() < lm_value)) {
+        return response->status_get();
+      }
 
-    // we won't return NOT_MODIFIED if Last-modified not exists
-    if ((lm_value == 0) || (request->get_if_modified_since() < lm_value)) {
-      return response->status_get();
-    } else {
-      // we cannot return NOT_MODIFIED yet, need to check If-none-match
       response_code = HTTP_STATUS_NOT_MODIFIED;
+    } else if (response->presence(MIME_PRESENCE_DATE)) {
+      ink_time_t date_value = response->get_date();
 
-      if (!request->presence(MIME_PRESENCE_IF_NONE_MATCH)) {
-        return response_code;
+      if ((date_value == 0) || (request->get_if_modified_since() < date_value)) {
+        return response->status_get();
       }
+
+      response_code = HTTP_STATUS_NOT_MODIFIED;
+    } else {
+      if (request->get_if_modified_since() < response_received_time) {
+        return response->status_get();
+      }
+
+      response_code = HTTP_STATUS_NOT_MODIFIED;
+    }
+
+    // we cannot return NOT_MODIFIED yet, need to check If-none-match
+    if (!request->presence(MIME_PRESENCE_IF_NONE_MATCH)) {
+      return response_code;
     }
   }
 
diff --git a/proxy/http/HttpTransactCache.h b/proxy/http/HttpTransactCache.h
index 610f012..f269462 100644
--- a/proxy/http/HttpTransactCache.h
+++ b/proxy/http/HttpTransactCache.h
@@ -125,7 +125,8 @@ public:
                                        HTTPHdr *obj_origin_server_response                                 // in
                                        );
 
-  static HTTPStatus match_response_to_request_conditionals(HTTPHdr *ua_request, HTTPHdr *c_response);
+  static HTTPStatus match_response_to_request_conditionals(HTTPHdr *ua_request, HTTPHdr *c_response,
+                                                           ink_time_t response_received_time);
 };
 
 #endif
diff --git a/rc/trafficserver.in b/rc/trafficserver.in
index 16ced7c..994d48d 100644
--- a/rc/trafficserver.in
+++ b/rc/trafficserver.in
@@ -235,7 +235,7 @@ do_stop()
   #   1 if daemon was already stopped
   #   2 if daemon could not be stopped
   #   other if a failure occurred
-    start-stop-daemon --stop --quiet --retry=QUIT/30/KILL/5 --pidfile $TC_PIDFILE --name $TC_NAME
+    start-stop-daemon --stop --quiet --retry=TERM/30/KILL/5 --pidfile $TC_PIDFILE --name $TC_NAME
     RETVAL="$?"
     test "$RETVAL" != 0 && return $RETVAL
   # Wait for children to finish too if this is a daemon that forks
@@ -244,14 +244,14 @@ do_stop()
   # that waits for the process to drop all resources that could be
   # needed by services started subsequently.  A last resort is to
   # sleep for some time.
-    start-stop-daemon --stop --quiet --oknodo --retry=0/30/KILL/5 --exec $TC_DAEMON
+    start-stop-daemon --stop --quiet --oknodo --retry=TERM/30/KILL/5 --exec $TC_DAEMON
     RETVAL="$?"
     test "$RETVAL" != 0 && return $RETVAL
   # Need to stop the TM and TS also
-    start-stop-daemon --stop --quiet --oknodo --retry=QUIT/30/KILL/5 --pidfile $TM_PIDFILE --name $TM_NAME
+    start-stop-daemon --stop --quiet --oknodo --retry=TERM/30/KILL/5 --pidfile $TM_PIDFILE --name $TM_NAME
     RETVAL="$?"
     test "$RETVAL" != 0 && return $RETVAL
-    start-stop-daemon --stop --quiet --oknodo --retry=QUIT/30/KILL/5 --pidfile $TS_PIDFILE --name $TS_NAME
+    start-stop-daemon --stop --quiet --oknodo --retry=TERM/30/KILL/5 --pidfile $TS_PIDFILE --name $TS_NAME
     RETVAL="$?"
     test "$RETVAL" != 0 && return $RETVAL
   # Many daemons don't delete their pidfiles when they exit.
diff --git a/trafficserver.spec b/trafficserver.spec
new file mode 100644
index 0000000..9e74377
--- /dev/null
+++ b/trafficserver.spec
@@ -0,0 +1,122 @@
+%global tag %(git describe --long |      sed 's/^\\\(.*\\\)-\\\([0-9]\\\+\\\)-g\\\([0-9a-f]\\\+\\\)$/\\\1/' | sed 's/-/_/')
+%global distance %(git describe --long | sed 's/^\\\(.*\\\)-\\\([0-9]\\\+\\\)-g\\\([0-9a-f]\\\+\\\)$/\\\2/')
+%global commit %(git describe --long |   sed 's/^\\\(.*\\\)-\\\([0-9]\\\+\\\)-g\\\([0-9a-f]\\\+\\\)$/\\\3/')
+%global git_serial %(git rev-list HEAD | wc -l)
+%global install_prefix "/opt"
+%global api_stats "4096"
+
+Name:		trafficserver
+Version:	%{tag}
+Epoch:		%{git_serial}
+Release:	%{distance}.%{commit}%{?dist}
+Summary:	Apache Traffic Server
+#Packager:	Jeffrey_Elsloo at Cable dot Comcast dot com
+Vendor:		IPCDN
+Group:		Applications/Communications
+License:	Apache License, Version 2.0
+URL:		https://gitlab.sys.comcast.net/cdneng/apache/tree/master/trafficserver
+BuildRoot:	%(mktemp -ud %{_tmppath}/%{name}-%{version}-%{release}-XXXXXX)
+Requires:	tcl, hwloc, pcre, openssl, libcap
+BuildRequires:	autoconf, automake, libtool, gcc-c++, glibc-devel, openssl-devel, expat-devel, pcre, libcap-devel, pcre-devel, perl-ExtUtils-MakeMaker, tcl-devel, hwloc-devel
+
+%description
+Apache Traffic Server with Comcast modifications and environment specific modifications
+
+%prep
+rm -rf %{name}
+git clone git@github.comcast.com:cdneng/trafficserver.git %{name}
+%setup -D -n %{name} -T
+git checkout build-master
+git checkout %{commit} .
+autoreconf -vfi
+#id ats &>/dev/null || /usr/sbin/useradd -u 176 -r ats -s /sbin/nologin -d /
+
+%build
+./configure --prefix=%{install_prefix}/%{name} --with-user=ats --with-group=ats --with-build-number=%{release} --enable-experimental-plugins --with-max-api-stats=%{api_stats}
+make %{?_smp_mflags}
+
+%install
+make DESTDIR=$RPM_BUILD_ROOT install
+# WARNING!  Don't build a RPM on a 'real' (ats server) box
+# Totally ghetto, but ATS build scripts aren't RPM (DESTDIR=$RPM_BUILD_ROOT, etc) compliant
+# ..so why haven't we fixed them? VSSCDNENG-767
+
+mkdir -p $RPM_BUILD_ROOT/opt/trafficserver/etc/trafficserver/snapshots
+mkdir -p $RPM_BUILD_ROOT/etc/init.d
+cp $RPM_BUILD_DIR/%{name}/rc/trafficserver $RPM_BUILD_ROOT/etc/init.d/
+
+%clean
+rm -rf $RPM_BUILD_ROOT
+
+%pre
+id ats &>/dev/null || /usr/sbin/useradd -u 176 -r ats -s /sbin/nologin -d /
+
+%post
+chkconfig --add %{name}
+
+%preun
+/etc/init.d/%{name} stop
+
+# if 0 uninstall, if 1 upgrade
+if [ "$1" = "0" ]; then
+	chkconfig --del %{name}
+fi
+
+%postun
+# Helpful in understanding order of operations in relation to install/uninstall/upgrade:
+#     http://www.ibm.com/developerworks/library/l-rpm2/
+# if 0 uninstall, if 1 upgrade
+if [ "$1" = "0" ]; then
+	id ats &>/dev/null && /usr/sbin/userdel ats
+fi
+
+%files
+%defattr(-,root,root)
+%attr(755,-,-) /etc/init.d/trafficserver
+%dir /opt/trafficserver
+/opt/trafficserver/bin
+/opt/trafficserver/include
+/opt/trafficserver/lib
+/opt/trafficserver/lib64
+/opt/trafficserver/libexec
+/opt/trafficserver/share
+%dir /opt/trafficserver/var
+%attr(-,ats,ats) /opt/trafficserver/var/trafficserver
+%dir /opt/trafficserver/var/log
+%attr(-,ats,ats) /opt/trafficserver/var/log/trafficserver
+%dir /opt/trafficserver/etc
+%attr(-,ats,ats) %dir /opt/trafficserver/etc/trafficserver
+%attr(-,ats,ats) %dir /opt/trafficserver/etc/trafficserver/snapshots
+/opt/trafficserver/etc/trafficserver/body_factory
+/opt/trafficserver/etc/trafficserver/trafficserver-release
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/cache.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/cluster.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/congestion.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/hosting.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/icp.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/ip_allow.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/log_hosts.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/logs_xml.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/parent.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/plugin.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/records.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/remap.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/socks.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/splitdns.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/ssl_multicert.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/storage.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/update.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/vaddrs.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/volume.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/prefetch.config
+%config(noreplace) %attr(644,ats,ats) /opt/trafficserver/etc/trafficserver/stats.config.xml
+
+%changelog
+* Wed Aug 7 2013 Jeff Elsloo <jeffrey_elsloo(at)cable.comcast.com>
+- Modified to support building 3.3.x
+- Modified to support upgrades
+* Sun Aug 12 2012 John Benton <john_benton(at)cable.comcast.com>
+- Initial RPM build based on SVN version 2376
+- Rev for ATS 3.2.0 based on SVN version 2470
+- Rev for ATS 3.2.0 based on SVN version 2555
+- Rev for ATS 3.2.0 based on SVN version 4812
